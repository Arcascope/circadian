{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readers\n",
    "\n",
    "> Defines several methods for analyzing, plotting, and exporting wereable data, including a Pandas accessor for wereable dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "from fastcore.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "# Pandas Accessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "VALID_WEREABLE_STREAMS = ['steps', 'heartrate', 'wake', 'light_estimate', 'activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tavel\\AppData\\Local\\Temp\\ipykernel_2516\\1080286350.py:4: UserWarning: registration of accessor <class '__main__.WereableData'> under name 'wereable' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  class WereableData:\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@pd.api.extensions.register_dataframe_accessor(\"wereable\")\n",
    "class WereableData:\n",
    "    \"pd.DataFrame accessor implementing wereable-specific methods\"\n",
    "    def __init__(self, pandas_obj):\n",
    "        self._validate_columns(pandas_obj)\n",
    "        self._obj = pandas_obj\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_columns(obj):\n",
    "        if 'datetime' not in obj.columns:\n",
    "            if 'start' not in obj.columns and 'end' not in obj.columns:\n",
    "                raise AttributeError(\"DataFrame must have 'datetime' column or 'start' and 'end' columns\")\n",
    "\n",
    "        if not any([col in obj.columns for col in VALID_WEREABLE_STREAMS]):\n",
    "            raise AttributeError(f\"DataFrame must have at least one wereable data column from: {VALID_WEREABLE_STREAMS}.\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def _validate_metadata(metadata):\n",
    "        if metadata:\n",
    "            if not isinstance(metadata, dict):\n",
    "                raise AttributeError(\"Metadata must be a dictionary.\")\n",
    "            if not any([key in metadata.keys() for key in ['data_id', 'subject_id']]):\n",
    "                raise AttributeError(\"Metadata must have at least one of the following keys: data_id, subject_id.\")\n",
    "            if not all([isinstance(value, str) for value in metadata.values()]):\n",
    "                raise AttributeError(\"Metadata values must be strings.\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def rename_columns(df, \n",
    "                       inplace: bool = False\n",
    "                       ):\n",
    "        \"Standardize column names by making them lowercase and replacing spaces with underscores\"\n",
    "        columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
    "        if inplace:\n",
    "            df.columns = columns\n",
    "        else:\n",
    "            new_df = df.copy()\n",
    "            new_df.columns = columns\n",
    "            return new_df\n",
    "\n",
    "    def is_valid(self):\n",
    "        self._validate_columns(self._obj)\n",
    "        self._validate_metadata(self._obj.attrs)\n",
    "        return True\n",
    "\n",
    "    def add_metadata(self,\n",
    "                     metadata: Dict[str, str], # metadata containing data_id, subject_id, or other_info\n",
    "                     inplace: bool = False, # whether to return a new dataframe or modify the current one\n",
    "                     ):\n",
    "        self._validate_metadata(metadata)\n",
    "        if inplace:\n",
    "            for key, value in metadata.items():\n",
    "                self._obj.attrs[key] = value\n",
    "        else:\n",
    "            obj = self._obj.copy()\n",
    "            for key, value in metadata.items():\n",
    "                obj.attrs[key] = value\n",
    "            return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "# Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "def load_json(filepath: str, # path to file\n",
    "              metadata: Dict[str, str] = None, # metadata containing data_id, subject_id, or other_info\n",
    "              ) -> Dict[str, pd.DataFrame]: # dictionary of wereable dataframes, one key:value pair per wereable data stream\n",
    "    \"Create a dataframe from a json containing a single or multiple streams of wereable data\"\n",
    "    # validate inputs\n",
    "    if not isinstance(filepath, str):\n",
    "        raise AttributeError(\"Filepath must be a string.\")\n",
    "    if metadata is not None:\n",
    "        WereableData._validate_metadata(metadata)\n",
    "    # load json\n",
    "    jdict = json.load(open(filepath, 'r'))\n",
    "    # check that it contains valid keys\n",
    "    if not np.all([key in VALID_WEREABLE_STREAMS for key in jdict.keys()]):\n",
    "        raise AttributeError(\"Invalid keys in JSON file. At least one key must be steps, heartrate, wake, light_estimate, or activity.\")\n",
    "    # create a df for each wereable stream\n",
    "    df_dict = {}\n",
    "    for key in jdict.keys():\n",
    "        if key in VALID_WEREABLE_STREAMS:\n",
    "            df_dict[key] = pd.DataFrame.from_dict(jdict[key])\n",
    "        else:\n",
    "            print(f\"Excluded key: {key} because it's not a valid wereable stream column name.\")\n",
    "    for key in df_dict.keys():\n",
    "        df = df_dict[key]\n",
    "        if 'timestamp' in df.columns:\n",
    "            df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "        elif 'start' in df.columns and 'end' in df.columns:\n",
    "            df['start'] = pd.to_datetime(df['start'], unit='s')\n",
    "            df['end'] = pd.to_datetime(df['end'], unit='s')\n",
    "        if metadata is not None:\n",
    "            df.wereable.add_metadata(metadata, inplace=True)\n",
    "        else:\n",
    "            df.wereable.add_metadata({'data_id': 'unknown', 'subject_id': 'unknown'}, inplace=True)\n",
    "        df_dict[key] = df\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "def load_csv(filepath: str, # full path to csv file to be loaded\n",
    "             metadata: Dict[str, str] = None, # metadata containing data_id, subject_id, or other_info\n",
    "             timestamp_col: str = None, # name of the column to be used as timestamp. If None, it is assumed that a `datetime` column exists\n",
    "             *args, # arguments to pass to pd.read_csv\n",
    "             **kwargs, # keyword arguments to pass to pd.read_csv\n",
    "             ):\n",
    "    \"Create a dataframe from a csv containing wereable data\"\n",
    "    # validate inputs\n",
    "    if not isinstance(filepath, str):\n",
    "        raise AttributeError(\"Filepath must be a string.\")\n",
    "    if not isinstance(timestamp_col, str) and timestamp_col is not None:\n",
    "        raise AttributeError(\"Timestamp column must be a string.\")\n",
    "    if metadata is not None:\n",
    "        WereableData._validate_metadata(metadata)\n",
    "    # load csv\n",
    "    df = pd.read_csv(filepath, *args, **kwargs)\n",
    "    # create datetime column\n",
    "    if timestamp_col is not None:\n",
    "        df['datetime'] = pd.to_datetime(df[timestamp_col], unit='s')\n",
    "    if timestamp_col is None and 'datetime' not in df.columns:\n",
    "        raise AttributeError(\"CSV file must have a column named 'datetime' or a timestamp column must be provided.\")\n",
    "    # add metadata\n",
    "    if metadata is not None:\n",
    "        df.wereable.add_metadata(metadata, inplace=True)\n",
    "    else:\n",
    "        df.wereable.add_metadata({'data_id': 'unknown', 'subject_id': 'unknown'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "ACTIWATCH_COLUMN_RENAMING = {\n",
    "    'White Light': 'light_estimate',\n",
    "    'Sleep/Wake': 'wake',\n",
    "    'Activity': 'activity',\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "def load_actiwatch(filepath: str, # full path to csv file to be loaded\n",
    "                   metadata: Dict[str, str] = None, # metadata containing data_id, subject_id, or other_info\n",
    "                   *args, # arguments to pass to pd.read_csv\n",
    "                   **kwargs, # keyword arguments to pass to pd.read_csv\n",
    "                   ) -> pd.DataFrame: # dataframe with the wereable data\n",
    "    \"Create a dataframe from an actiwatch csv file\"\n",
    "    # validate inputs\n",
    "    if not isinstance(filepath, str):\n",
    "        raise AttributeError(\"Filepath must be a string.\")\n",
    "    if metadata is not None:\n",
    "        WereableData._validate_metadata(metadata)\n",
    "    # load csv\n",
    "    df = pd.read_csv(filepath, *args, **kwargs)\n",
    "    df['datetime'] = pd.to_datetime(df['Date']+\" \"+df['Time'])\n",
    "    # drop unnecessary columns\n",
    "    df.drop(columns=['Date', 'Time'], inplace=True)\n",
    "    # rename columns\n",
    "    df.rename(columns=ACTIWATCH_COLUMN_RENAMING, inplace=True)\n",
    "    # add metadata\n",
    "    if metadata is not None:\n",
    "        df.wereable.add_metadata(metadata, inplace=True)\n",
    "    else:\n",
    "        df.wereable.add_metadata({'data_id': 'unknown', 'subject_id': 'unknown'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "# Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "WEREABLE_RESAMPLE_METHOD = {\n",
    "    'steps': 'sum',\n",
    "    'wake': 'max',\n",
    "    'heartrate': 'mean',\n",
    "    'light_estimate': 'mean',\n",
    "    'activity': 'mean',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "def resample_df(df: pd.DataFrame, # dataframe to be resampled\n",
    "                name: str, # name of the wereable data to resample (one of steps, heartrate, wake, light_estimate, or activity)\n",
    "                freq: str, # frequency to resample to\n",
    "                agg_method: str, # aggregation method to use when resampling\n",
    "                initial_datetime: pd.Timestamp = None, # initial datetime to use when resampling. If None, the minimum datetime in the dataframe is used\n",
    "                final_datetime: pd.Timestamp = None, # final datetime to use when resampling. If None, the maximum datetime in the dataframe is used\n",
    "                ) -> pd.DataFrame: # resampled dataframe\n",
    "    \"Resample a wereable dataframe. If data is specified in intervals, returns the density of the quantity per minute.\"\n",
    "    # validate inputs\n",
    "    if not df.wereable.is_valid():\n",
    "        raise AttributeError(\"Dataframe must be a valid wereable dataframe.\")\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise AttributeError(\"Dataframe must be a pandas dataframe.\")\n",
    "    if not isinstance(freq, str):\n",
    "        raise AttributeError(\"Frequency must be a string.\")\n",
    "    if name is not None and name not in VALID_WEREABLE_STREAMS:\n",
    "        raise AttributeError(f\"Name must be one of: {VALID_WEREABLE_STREAMS}.\")\n",
    "    if name not in df.columns:\n",
    "        raise AttributeError(f\"Name must be one of: {df.columns}.\")\n",
    "    if agg_method not in ['sum', 'mean', 'max', 'min']:\n",
    "        raise AttributeError(\"Aggregation method must be one of: sum, mean, max, min.\")\n",
    "    if initial_datetime is not None and not isinstance(initial_datetime, pd.Timestamp):\n",
    "        raise AttributeError(\"Initial datetime must be a pandas timestamp.\")\n",
    "    if final_datetime is not None and not isinstance(final_datetime, pd.Timestamp):\n",
    "        raise AttributeError(\"Final datetime must be a pandas timestamp.\")\n",
    "    # resample\n",
    "    values = df[name]\n",
    "    if 'start' in df.columns and 'end' in df.columns:\n",
    "        # data is specified in intervals\n",
    "        starts = df.start\n",
    "        stops = df.end\n",
    "        if initial_datetime is None:\n",
    "            initial_datetime = starts.min()\n",
    "        if final_datetime is None:\n",
    "            final_datetime = stops.max()\n",
    "        new_datetime = pd.date_range(initial_datetime, final_datetime, freq=freq)\n",
    "        new_values = np.zeros(len(new_datetime))\n",
    "        for idx, datetime in enumerate(new_datetime):\n",
    "            next_datetime = datetime + pd.to_timedelta(freq)\n",
    "            mask = (starts <= next_datetime) & (stops > datetime)\n",
    "            if len(values[mask]) > 0:\n",
    "                # NOTE: returns the density of the quantity per minute\n",
    "                time_interval = (stops[mask] - starts[mask]).apply(lambda x: x.seconds / 60.0)\n",
    "                new_values[idx] = (values[mask] / time_interval).agg(agg_method)\n",
    "    else:\n",
    "        # data is specified per datetime\n",
    "        data_datetimes = df.datetime\n",
    "        if initial_datetime is None:\n",
    "            initial_datetime = data_datetimes.min()\n",
    "        if final_datetime is None:\n",
    "            final_datetime = data_datetimes.max()\n",
    "        new_datetime = pd.date_range(initial_datetime, final_datetime, freq=freq)\n",
    "        new_values = np.zeros(len(new_datetime))\n",
    "        for idx, datetime in enumerate(new_datetime):\n",
    "            next_datetime = datetime + pd.to_timedelta(freq)\n",
    "            mask = (data_datetimes <= next_datetime) & (data_datetimes >= datetime)\n",
    "            if len(values[mask]) > 0:\n",
    "                new_values[idx] = values[mask].agg(agg_method)\n",
    "\n",
    "    return pd.DataFrame({'datetime': new_datetime, name: new_values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "def combine_wereable_dataframes(df_dict: Dict[str, pd.DataFrame], # dictionary of wereable dataframes \n",
    "                                metadata: Dict[str, str] = None, # metadata for the combined dataframe\n",
    "                                resample_freq: str = '10min', # resampling frequency (e.g. '10min' for 10 minutes, see Pandas Offset aliases: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)\n",
    "                                ) -> pd.DataFrame: # combined wereable dataframe\n",
    "    \"Combine a dictionary of wereable dataframes into a single dataframe with resampling\"\n",
    "    df_list = []\n",
    "    # find common initial and final datetimes\n",
    "    initial_datetimes = []\n",
    "    final_datetimes = []\n",
    "    for name in df_dict.keys():\n",
    "        df = df_dict[name]\n",
    "        df.wereable.is_valid()\n",
    "        if 'start' in df.columns:\n",
    "            initial_datetimes.append(df.start.min())\n",
    "            final_datetimes.append(df.end.max())\n",
    "        else:\n",
    "            initial_datetimes.append(df.datetime.min())\n",
    "            final_datetimes.append(df.datetime.max())\n",
    "    initial_datetime = min(initial_datetimes)\n",
    "    final_datetime = max(final_datetimes)\n",
    "    # resample each df\n",
    "    for name in df_dict.keys():\n",
    "        df = df_dict[name]\n",
    "        new_df = resample_df(df, name, resample_freq, \n",
    "                             WEREABLE_RESAMPLE_METHOD[name],\n",
    "                             initial_datetime=initial_datetime,\n",
    "                             final_datetime=final_datetime)\n",
    "        df_list.append(new_df)\n",
    "    # merge all dfs by datetime\n",
    "    df = df_list[0]\n",
    "    for i in range(1, len(df_list)):\n",
    "        df = df.merge(df_list[i], on='datetime', how='outer')\n",
    "    # sort by datetime\n",
    "    df.sort_values(by='datetime', inplace=True)\n",
    "    # add metadata\n",
    "    if metadata is not None:\n",
    "        df.wereable.add_metadata(metadata, inplace=True)\n",
    "    else:\n",
    "        df.wereable.add_metadata({'data_id': 'combined_dataframe'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
