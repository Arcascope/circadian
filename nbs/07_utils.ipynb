{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities \n",
    "\n",
    "> This module adds some nice utilities functions for circadian data science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from numba import jit\n",
    "from scipy import interpolate\n",
    "import torch \n",
    "import json\n",
    "import pytz\n",
    "import datetime\n",
    "import copy\n",
    "import scipy as sp\n",
    "from scipy.integrate import solve_ivp\n",
    "from math import *\n",
    "import pylab as plt\n",
    "import gzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, datetime.datetime):\n",
    "            return obj.isoformat()\n",
    "        return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "def simple_norm_stepshr_sleep_classifier(t):\n",
    "        t[0,:] = torch.tanh((t[0,:] - 10.0)/ 100.0)\n",
    "        t[1, torch.nonzero(t[1,:])] = torch.tanh((t[1,torch.nonzero(t[1,:])] - 60.0) / 30.0)\n",
    "        return t \n",
    "\n",
    "def phase_ic_guess(time_of_day: float) -> float:\n",
    "    time_of_day = np.fmod(time_of_day, 24.0)\n",
    "\n",
    "    # Wake at 8 am after 8 hours of sleep\n",
    "    # State at 00:00\n",
    "    psi = 1.65238233\n",
    "\n",
    "    # Convert to radians, add to phase\n",
    "    psi += time_of_day * np.pi / 12\n",
    "    return psi\n",
    "\n",
    "def abs_hour_diff(x, y):\n",
    "    \"\"\"\n",
    "    function abs_hour_diff(x,y)\n",
    "\n",
    "    Find the difference in hours between\n",
    "    two clock times (wrapped)\n",
    "    \"\"\"\n",
    "    a1 = min(x, y)\n",
    "    a2 = max(x, y)\n",
    "    s1 = a2-a1\n",
    "    s2 = 24.0+a1-a2\n",
    "    return(min(s1, s2))\n",
    "\n",
    "\n",
    "def cut_phases_12(p):\n",
    "    \"\"\"\n",
    "    Function to make the branch cut for the DLMO times be at 12 instead of 24.\n",
    "    This is better because lots of DLMOs are near midnight, but many fewer are near\n",
    "    noon.\n",
    "\n",
    "        cut_phases_12(timept)\n",
    "    \"\"\"\n",
    "\n",
    "    while (p < 0.0):\n",
    "        p += 24.0\n",
    "\n",
    "    p = np.fmod(p, 24.0)\n",
    "\n",
    "    if p > 12:\n",
    "        return p-24.0\n",
    "    else:\n",
    "        return p\n",
    "\n",
    "\n",
    "def convert_binary(x, breakpoint: float = 0.50):\n",
    "    x[x <= breakpoint] = 0.0\n",
    "    x[x > breakpoint] = 1.0\n",
    "    return x\n",
    "\n",
    "\n",
    "def cal_days_diff(a, b):\n",
    "    \"\"\"Get the calander days between two time dates\"\"\"\n",
    "    A = a.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    B = b.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    return (A - B).days\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def interpolateLinear(t, xvals, yvals):\n",
    "    \"\"\"Implement a faster method to get linear interprolations of the light functions\"\"\"\n",
    "\n",
    "    if (t >= xvals[-1]):\n",
    "        return (0.0)\n",
    "    if (t <= xvals[0]):\n",
    "        t += 24.0\n",
    "\n",
    "    i = np.searchsorted(xvals, t) - 1\n",
    "    ans = (yvals[i + 1] - yvals[i]) / \\\n",
    "          ((xvals[i + 1] - xvals[i]) * (t - xvals[i])) + yvals[i]\n",
    "    return (ans)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def interpolateLinearExt(t, xvals, yvals):\n",
    "    \"\"\"Implement a faster method to get linear interprolations of the light functions, exclude non-full days\"\"\"\n",
    "    i = np.searchsorted(xvals, t) - 1\n",
    "    ans = (yvals[i + 1] - yvals[i]) / \\\n",
    "          ((xvals[i + 1] - xvals[i]) * (t - xvals[i])) + yvals[i]\n",
    "    return (ans)\n",
    "\n",
    "\n",
    "def parse_dt(date, time):\n",
    "    strDate = date + ' ' + time\n",
    "    return pd.to_datetime(strDate, format='%m/%d/%Y %I:%M %p')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circular Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def circular_mean(series):\n",
    "    Z=complex(0,0)\n",
    "    series=np.array(series)\n",
    "    for i in range(len(series)):\n",
    "        Z+=np.exp(series[i]*complex(0,1))\n",
    "\n",
    "    Z=Z/float(len(series))\n",
    "\n",
    "    ans=np.angle(Z)\n",
    "    if (ans<0.0):\n",
    "        ans+=2*sp.pi\n",
    "    return(ans)\n",
    "\n",
    "def phase_coherence(series):\n",
    "    Z=complex(0,0)\n",
    "    series=np.array(series)\n",
    "    for i in range(len(series)):\n",
    "        Z+=np.exp(series[i]*complex(0,1))\n",
    "\n",
    "    Z=Z/float(len(series))\n",
    "\n",
    "    ans=np.absolute(Z)\n",
    "    return(ans)\n",
    "\n",
    "def phase_coherence_clock(series):\n",
    "    angles=np.pi/12.0*series\n",
    "    return(phase_coherence(angles))\n",
    "\n",
    "def angle_difference(c1, c2) -> float:\n",
    "    \"\"\"Find the angle between two angles given in radians\n",
    "    angle_difference(c1, c2)\n",
    "    c1-c2\n",
    "    \"\"\"\n",
    "\n",
    "    return(np.angle(np.exp(complex(0,1)*(c1-c2))))\n",
    "\n",
    "\n",
    "def subtract_clock_times(c1, c2):\n",
    "    \"\"\"Find the hour differences between two clock times new\"\"\"\n",
    "    a1=sp.pi/12.0*c1\n",
    "    a2=sp.pi/12.0*c2\n",
    "    adiff=angle_difference(a1, a2)\n",
    "    return(12.0/sp.pi*adiff)\n",
    "\n",
    "\n",
    "def circular_av_clock(series):\n",
    "    \"\"\"Find the average time given a list of clock times\"\"\"\n",
    "    angles=sp.pi/12.0*series\n",
    "    ans_angle=circular_mean(angles)\n",
    "    #back to clock time\n",
    "    return(ans_angle*12.0/sp.pi)\n",
    "    \n",
    "\n",
    "def circular_scatter(ax, angles, clock_times=False, radius=1.0, color='blue'):\n",
    "    \"\"\"Adds a polar scatter plot of clock times to an axes with polar axis i.e.\n",
    "        ax = plt.subplot(111, polar=True)\n",
    "        Will also plot the circular mean angle and the phase coherence\n",
    "    \"\"\"\n",
    "    \n",
    "    angles=np.array(angles)\n",
    "    radii=radius*np.ones(len(angles))\n",
    "\n",
    "\n",
    "    if clock_times:\n",
    "        angles=angles*sp.pi/12.0\n",
    "\n",
    "    ax.scatter(angles, radii, color=color)\n",
    "    ax.set_theta_zero_location(\"N\")\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_thetagrids(list(range(0,360,45)), list(range(0,24,3)))\n",
    "    ax.set_rmax(1.2)\n",
    "    ax.set_rticks([0.0,0.2,0.6,0.8,1.0])\n",
    "    ax.annotate(\"\", xytext=(0.0,0.0), xy=(circular_mean(angles),phase_coherence(angles)),arrowprops=dict(facecolor=color))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data related utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def times_to_angle(time_vector: np.ndarray):\n",
    "    \"\"\"\n",
    "        Take an array of times and return R, psi \n",
    "        giving the mean angle (psi) and amplitude (R)\n",
    "    \"\"\"\n",
    "    rad_vector = np.fmod(time_vector, 24.0) * np.pi/12.0\n",
    "    Z = np.sum(np.exp(rad_vector*1j))/len(rad_vector)\n",
    "    return(np.abs(Z), np.angle(Z))\n",
    "\n",
    "\n",
    "def timezone_mapper(dt_object: datetime, timezone: str = 'America/Detroit'):\n",
    "    \"\"\"\n",
    "        Take in local time as datetime object and give back UTC with \n",
    "        day lights savings accounted for as a timestamp\n",
    "    \"\"\"\n",
    "\n",
    "    local_timezone = pytz.timezone(timezone)\n",
    "    return local_timezone.localize(dt_object).timestamp()\n",
    "\n",
    "\n",
    "def split_missing_data(date_time, ts, y, hr=None, break_threshold=96.0):\n",
    "\n",
    "    # Find idx at start and end of long periods of zeros\n",
    "\n",
    "    idx_start = None\n",
    "    idx_end = None\n",
    "    in_region = False\n",
    "    crop_regions = []\n",
    "\n",
    "    for (k, t) in enumerate(ts):\n",
    "        if y[k] <= 0.0 and not in_region:\n",
    "            idx_start = k\n",
    "            in_region = True\n",
    "        if y[k] > 0.0 and in_region:\n",
    "            idx_end = k-1\n",
    "            in_region = False\n",
    "            if ts[idx_end]-ts[idx_start] >= break_threshold:\n",
    "                crop_regions += [idx_start, idx_end]\n",
    "    ts_split = np.split(ts, crop_regions)\n",
    "    y_split = np.split(y, crop_regions)\n",
    "\n",
    "    if hr is not None:\n",
    "        hr_split = np.split(hr, crop_regions)\n",
    "\n",
    "    print(f\"Splitting data into {len(y_split)} regions\")\n",
    "\n",
    "    if hr is not None:\n",
    "        return np.split(date_time, crop_regions), ts_split, y_split, hr_split\n",
    "    else:\n",
    "        return np.split(date_time, crop_regions), ts_split, y_split\n",
    "\n",
    "\n",
    "def split_drop_data(date_time, ts, steps, hr, wake, break_threshold=96.0, min_length: float = 30.0):\n",
    "    \"\"\"\n",
    "        Used to split long JSON into contin data steaks of at \n",
    "        least X=30 days.\n",
    "\n",
    "        Uses that missing data will be zeros for steps and hr  and \n",
    "        0.5 for the wake data. \n",
    "\n",
    "        min_length is in days\n",
    "    \"\"\"\n",
    "\n",
    "    idx_start = None\n",
    "    idx_end = None\n",
    "    in_region = False\n",
    "    crop_regions = []\n",
    "\n",
    "    for (k, t) in enumerate(ts):\n",
    "        if (steps[k] <= 0.0 or hr[k] <= 0 or wake[k] == 0.50) and not in_region:\n",
    "            idx_start = k\n",
    "            in_region = True\n",
    "        if steps[k] > 0.0 and hr[k] > 0 and wake[k] != 0.50 and in_region:\n",
    "            idx_end = k-1\n",
    "            in_region = False\n",
    "            if ts[idx_end]-ts[idx_start] >= break_threshold:\n",
    "                crop_regions += [idx_start, idx_end]\n",
    "\n",
    "    ts_split = np.split(ts, crop_regions)\n",
    "    steps_split = np.split(steps, crop_regions)\n",
    "    hr_split = np.split(hr, crop_regions)\n",
    "    wake_split = np.split(wake, crop_regions)\n",
    "    date_time = np.split(date_time, crop_regions)\n",
    "\n",
    "    # Find idxs for regions which are longer than min_length\n",
    "\n",
    "    idx_long = [k for (k, val) in enumerate(ts_split)\n",
    "                if (val[-1]-val[0])/24.0 >= min_length]\n",
    "\n",
    "    if len(idx_long) > 0:\n",
    "        return ([date_time[i] for i in idx_long], [ts_split[idx] for idx in idx_long], [steps_split[i] for i in idx_long],\n",
    "                [hr_split[i] for i in idx_long], [wake_split[i] for i in idx_long])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can be used to redact the dates from a json file, this is to protect the user privacy. The start of the timestamps will\n",
    "be set back to the unix epoch time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def redact_dates(infile: str, # the input file in json format\n",
    "                 outfile: str, # the output file in json format with dates redacted, for user privacy\n",
    "                 gzip_opt: bool = False # if the input file is gzipped, if the extension is .gz, this is set to True\n",
    "                 ) -> None:\n",
    "    gzip_opt = gzip_opt if gzip_opt else infile.endswith(\".gz\")\n",
    "    fileobj = gzip.open(infile, 'r') if gzip_opt else open(infile, 'r')\n",
    "    data = json.load(fileobj)\n",
    "    \n",
    "    first_time = data['steps'][0]['start']\n",
    "    for i in range(len(data['steps'])):\n",
    "        data['steps'][i]['start'] -= first_time\n",
    "        data['steps'][i]['end'] -= first_time \n",
    "    for i in range(len(data['heartrate'])):\n",
    "        data['heartrate'][i]['timestamp'] -= first_time\n",
    "    for i in range(len(data['wake'])):\n",
    "        data['wake'][i]['start'] -= first_time\n",
    "        data['wake'][i]['end'] -= first_time\n",
    "        \n",
    "    json.dump(data, open(outfile, 'w'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
