[
  {
    "objectID": "examples/skeldon23_sleep_model.html",
    "href": "examples/skeldon23_sleep_model.html",
    "title": "Combining sleep and circadian models",
    "section": "",
    "text": "Circadian rhythms govern our daily patterns of rest and wakefulness and determine when we fall asleep and wake up. However, models such as Forger99 or Hannay19 don’t predict sleep timing or duration. A family of models known as two-process models address this by coupling circadian rhythms with sleep pressure modeling. Here, we explore the two-process model in Skeldon et al. 2023 which combines Forger99’s circadian rhythm with a sleep homeostat that accumulates sleep pressure during wakefulness and dissipates during sleep. The model receives a light schedule as an input and is able to produce realistic sleep timings and durations. It is implemented in circadian.models as Skeldon23.\n\nRegular schedule\nIn order to obtain a prediction for sleep/wake onset, we need to provide the model with a light schedule. Following the original article, we’ll use a smooth light function defined in the following way:\n\ndef smooth_light(t):\n    rise = np.tanh(0.6 * (t - 8.0))\n    fall = np.tanh(0.6 * (t - 17.0))\n    y = (700.0 / 2.0) * (rise - fall) + 40.0\n    return y\n\nThen, we can define the schedule, equilibrate the model, and simulate:\n\nschedule = LightSchedule(smooth_light, period=24.0)\ndt = 0.01 # hours\ndays = 5\ntime = np.arange(8.0, 24 * days + 8.0, dt)\nlight = schedule(time)\nmodel = Skeldon23()\n# equilibrate model\ninitial_condition = model.equilibrate(time, light, num_loops=20)\n# simulate model\ntrajectory = model(time, initial_condition=initial_condition, input=light)\nsleep = model.sleep_state\nreceived_light = model.received_light\n\nNote that the model output constists of:\n\nA trajectory containing the information of the model’s four state variables (\\(x\\), \\(x_c\\), \\(n\\), and \\(H\\)) over time. Here we have favored Forger99’s notation of variables whereas the original article uses \\(x\\), \\(y\\), \\(n\\), and \\(H\\) respectively.\nA sleep array containing the sleep state for each timepoint. This is a binary array with 1 indicating sleep and 0 indicating wake.\nA received_light array encoding the light input to the circadian model for each timepoint. This light input is different from the provided light array only in those timepoints where the sleep state is 1 (i.e. asleep).\n\nWe can then visualize the predicted sleep windows\n\n\n\n\n\n\n\n\n\nand the circadian state from the \\(x\\) variable\n\n\n\n\n\n\n\n\n\nLight, being the primary input to the circadian model, drives the circadian state through the forcing term \\(B(t)\\):\n\n\n\n\n\n\n\n\n\nIn turn, the circadian state modulates sleep. Skeldon et al. define a function \\(C(t)\\) that determines the propensity of an individual to go to sleep or wake up.\n\n\n\n\n\n\n\n\n\n\\(C(t)\\) determines when the sleep pressure \\(H(t)\\) has accumulated sufficiently to trigger sleep (at threshold \\(H^+\\)) and when it has dissipated sufficiently to allow wake (at threshold \\(H^-\\)).\n\n\n\n\n\n\n\n\n\nTherefore, given any light schedule and initial conditions we can predict not only the phase of the circadian rhythm but also the timing and duration of sleep. In this simulation we obtain an average sleep timing and duration of\n\n# sleep start\nsleep_start_idxs = np.where(np.diff(sleep) == 1)[0]\nsleep_start_times = np.mod(time[sleep_start_idxs], 24.0)\navg_sleep_start = circmean(sleep_start_times, high=24.0)\n# sleep end\nsleep_end_idxs = np.where(np.diff(sleep) == -1)[0]\nsleep_end_times = np.mod(time[sleep_end_idxs], 24.0)\navg_sleep_end = circmean(sleep_end_times, high=24.0)\n# sleep duration\nsleep_end_idxs = np.where(np.diff(sleep) == -1)[0]\nsleep_duration = time[sleep_end_idxs] - time[sleep_start_idxs]\n\nAverage sleep start: 23.79 h, Average sleep end: 7.09 h, Average sleep duration: 7.30 h\n\n\n\n\nShift work schedule\nThe model allows us to explore how much sleep would a shift worker get in a typical light schedule. Applying the same pipeline as above but using LightSchedule.ShiftWork we obtain the following results:\nschedule = LightSchedule.ShiftWork()\ndt = 0.01 # hours\ndays = 7\ntime = np.arange(0, 24 * days, dt)\nlight = schedule(time)\nmodel = Skeldon23()\n# equilibrate model\ninitial_condition = model.equilibrate(time, light)\n# simulate model\ntrajectory = model(time, initial_condition=initial_condition, input=light)\nsleep = model.sleep_state\nreceived_light = model.received_light\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# sleep start\nsleep_start_idxs = np.where(np.diff(sleep) == 1)[0]\nsleep_start_times = np.mod(time[sleep_start_idxs], 24.0)\navg_sleep_start = circmean(sleep_start_times, high=24.0)\n# sleep end\nsleep_end_idxs = np.where(np.diff(sleep) == -1)[0]\nsleep_end_times = np.mod(time[sleep_end_idxs], 24.0)\navg_sleep_end = circmean(sleep_end_times, high=24.0)\n# sleep duration\nsleep_end_idxs = np.where(np.diff(sleep) == -1)[0]\nsleep_duration = time[sleep_end_idxs] - time[sleep_start_idxs]\n\nAverage sleep start: 13.41 h, Average sleep end: 20.73 h, Average sleep duration: 7.32 h\n\n\nEven though the sleep duration is not so different from the regular schedule, the sleep timing clashes with the shift in light exposure during days off (days 5 and 6). The model keeps the rhythm of previous shift work days, making it hard to switch to a regular schedule on days off.\n\n\nPredicted sleep as a function of circadian period \\(\\tau_c\\)\nIn the original article, Skeldon et al. explore how different parameters affect sleep duration, mid-sleep timing, and circadian state minimum. Using circadian we can do a similar exploration, analyzing how the intrinsic period \\(\\tau_c\\) modulates these quantities under two different light schedules, one with low baseline intensity (10 lux) and one with high baseline intensity (100 lux).\n\ndef low_baseline_schedule(t):\n    rise = np.tanh(t - 7.0)\n    fall = np.tanh(t - 18.0)\n    y = ((10000.0 - 10.0) / 2.0) * (rise - fall) + 10.0\n    return y\n\ndef high_baseline_schedule(t):\n    rise = np.tanh(t - 7.0)\n    fall = np.tanh(t - 18.0)\n    y = ((10000.0 - 100.0) / 2.0) * (rise - fall) + 100.0\n    return y\n\nlight_schedules = {\n    'low_baseline': LightSchedule(low_baseline_schedule, period=24),\n    'high_baseline': LightSchedule(high_baseline_schedule, period=24)\n}\n\n\n\n\n\n\n\n\n\n\nFor each value of intrinsic period we equilibrate the system for 60 days and then store 5 days of simulated data:\n\nresults = {\n    'low_baseline': {\n        'trajectories': [],\n        'sleep': [],\n        'sleep_duration': [],\n        'mid_sleep_time': [],\n        'circadian_minimum_time': []\n    },\n    'high_baseline': {\n        'trajectories': [],\n        'sleep': [],\n        'sleep_duration': [],\n        'mid_sleep_time': [],\n        'circadian_minimum_time': []\n    }\n}\n\ndt = 0.05 # hours\ndays = 5\ntime = np.arange(0, 24 * days, dt)\nintrinsic_periods = np.linspace(23.6, 24.25, 20)\n\nfor schedule_name in light_schedules:\n    schedule = light_schedules[schedule_name]\n    light = schedule(time)\n    for tauc in intrinsic_periods:\n        model = Skeldon23(params={'tauc': tauc})\n        # equilibrate model\n        initial_condition = model.equilibrate(time, light, num_loops=12)\n        # simulate model\n        trajectory = model(time, initial_condition, light)\n        # calculate sleep metrics\n        sleep = model.sleep_state\n        mid_sleep_time, sleep_duration = sleep_midpoint_and_duration(time, sleep)\n        circadian_minimum = np.mean(np.mod(model.cbt(), 24))\n        # store results\n        results[schedule_name]['trajectories'].append(trajectory)\n        results[schedule_name]['sleep'].append(sleep)\n        results[schedule_name]['sleep_duration'].append(sleep_duration)\n        results[schedule_name]['mid_sleep_time'].append(mid_sleep_time)\n        results[schedule_name]['circadian_minimum_time'].append(circadian_minimum)\n\nWe can visualize the effect of the intrinsic period on the predicted sleep windows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nas well as its effect on the circadian rhythm:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe high baseline simulations seem to affect both sleep and circadian state the most.\nThe high baseline schedule seems to have a greater effect on sleep and circadian state than the low baseline schedule. On our main simulation loop, we used the function sleep_midpoint_and_duration from the module circadian.utils to quantify these effects. Their plots are shown below and confirm this observation in agreement with the results from Skeldon et al. 2023:",
    "crumbs": [
      "Examples",
      "Combining sleep and circadian models"
    ]
  },
  {
    "objectID": "examples/effect_of_pulses.html",
    "href": "examples/effect_of_pulses.html",
    "title": "Circadian rhythm disruptions",
    "section": "",
    "text": "Light exposure is one of the main factors affecting circadian rhythms. Here we use the circadian package to explore the effects of light pulses at different times of the day. We will explore this effect using four different circadian models Forger99, Jewett99, Hannay19, and Hannay19TP and compare the results among them.\n\nEntraining models to a regular light schedule\nFirst, we entrain each model to a regular light schedule to have a baseline to compare to. In circadian we do this by\n\ndt = 0.1 # hours\ndays = 20\ntime = np.arange(0, 24 * days, dt)\nregular_lux = 500\nschedule = LightSchedule.Regular(regular_lux, lights_on=8, lights_off=24)\nlight_input = schedule(time)\nmodel_list = [Forger99(), Jewett99(), Hannay19(), Hannay19TP()]\nequilibrium_states = []\n\nfor model in model_list:\n    time_eq = np.arange(0, 24 * days, dt)\n    final_state = model.equilibrate(time_eq, light_input, num_loops=2)\n    equilibrium_states.append(final_state)\n\n\n\nPulse during the day\nNext, we can explore how models respond to lights pulse during the bright hours of the day. We can use the LightSchedule.from_pulse function to add pulses at different times\n\ndays = 3\ntime = np.arange(0, 24 * days, dt)\npulse_num = 6\npulse_lux = 1e4\npulse_duration = 1 # hour\nstart_values = np.linspace(32, 47, pulse_num)\n\nsimulation_result = {}\n\nfor idx,model in enumerate(model_list):\n    simulation_result[str(model)] = {}\n    for pulse_start in start_values:\n        schedule = LightSchedule.Regular(regular_lux, lights_on=8, lights_off=24)\n        schedule += LightSchedule.from_pulse(pulse_lux, pulse_start, pulse_duration)\n        light_input = schedule(time)\n        trajectory = model(time, equilibrium_states[idx], light_input)\n        simulation_result[str(model)][str(pulse_start)] = {\n            'light': light_input,\n            'trajectory': trajectory\n        }\n\n\nForger99Jewett99Hannay19Hannay19TP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe see that light pulses during bright hours don’t have a major effect on circadian rhythms. However, this is not the case for light pulses during darkness.\n\n\nPulse at night\nUsing the same code as above but with different pulse start values\n\nstart_values = np.linspace(24, 31, pulse_num)\n\ngives us the following\n\nForger99Jewett99Hannay19Hannay19TP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModels are more sensitive to pulses during the dark hours of the day, the sinusoidal signal changes abruptly when the pulse is applied. This reflects an important property of circadian rhythms: their sensitivity to light is dependent on the current phase of the clock. We can calculate how much the phase of the clock changes after a pulse by constructing a phase response curve (PRC).\n\n\nBuilding phase response curves\nTo build a phase response curve we need to calculate how much the phase of the clock changed after the pulse ended with respect to an unperturbed clock. We can do this the following way\n\nfrom circadian.utils import phase_difference\n\n\nmodel = Forger99()\n\ndays = 3\ntime = np.arange(0, 24 * days, dt)\npulse_lux = 1e4\npulse_start = 25 # hours\npulse_duration = 1 # hour\n\nregular_schedule = LightSchedule.Regular(regular_lux, lights_on=8, lights_off=24)\npulse = LightSchedule.from_pulse(pulse_lux, pulse_start, pulse_duration)\npulse_schedule = regular_schedule + pulse\n\nregular_light = regular_schedule(time)\npulse_light = pulse_schedule(time)\n\nregular_trajectory = model(time, equilibrium_states[0], regular_light)\npulse_trajectory = model(time, equilibrium_states[0], pulse_light)\n\npulse_end = pulse_start + pulse_duration\n\nregular_phase = model.phase(regular_trajectory, pulse_end)\npulse_phase = model.phase(pulse_trajectory, pulse_end)\n\nphase_diff = phase_difference(regular_phase, pulse_phase)\n\nPhase difference: -0.16 radians\n\n\nThis negative value means that the pulse delays the clock. We can visualize this by comparing the state of the clock before and after the pulse\n\n\n\n\n\n\n\n\n\nHere we can also observe that the amplitude of the clock is reduced after the pulse. To calculate this we do the following\n\nfrom circadian.utils import amplitude_percent_change\n\n\nregular_amplitude = model.amplitude(regular_trajectory, pulse_end)\npulse_amplitude = model.amplitude(pulse_trajectory, pulse_end)\n\namplitude_change = amplitude_percent_change(regular_amplitude, pulse_amplitude)\n\nAmplitude change: -12.40%\n\n\nSo the pulse both delays the clock and reduces its amplitude. We can now calculate the phase response curve by repeating this process for different pulse times. We will also store the amplitude change information for the following section.\n\ndays = 2.5\ndt = 0.02 # hours. We need a smaller dt to get a smooth phase response curve\ntime = np.arange(0, 24 * days, dt)\npulse_num = 150\npulse_lux = 1e4\npulse_duration = 1 # hour\nstart_values = np.linspace(24, 48, pulse_num)\n\n\nfor idx,model in enumerate(model_list):\n    simulation_result[str(model)] = {\n        'cbtmin': np.NaN,\n        'phase_response': [],\n        'amplitude_response': [],\n    }\n    # create the reference trajectory\n    regular_schedule = LightSchedule.Regular(regular_lux, lights_on=8, lights_off=24)\n    regular_light = regular_schedule(time)\n    regular_trajectory = model(time, equilibrium_states[idx], regular_light)\n\n    # calculate cbt to use as pulse start time reference\n    cbtmin = model.cbt(regular_trajectory)[1]\n    simulation_result[str(model)]['cbtmin'] = cbtmin\n\n    for pulse_start in start_values:\n        schedule = LightSchedule.Regular(regular_lux, lights_on=8, lights_off=24)\n        schedule += LightSchedule.from_pulse(pulse_lux, pulse_start, pulse_duration)\n        light_input = schedule(time)\n        pulse_trajectory = model(time, equilibrium_states[idx], light_input)\n\n        pulse_end = pulse_start + pulse_duration\n\n        regular_phase = model.phase(regular_trajectory, pulse_end)\n        pulse_phase = model.phase(pulse_trajectory, pulse_end)\n        phase_diff = phase_difference(regular_phase, pulse_phase)\n        simulation_result[str(model)]['phase_response'].append(phase_diff)\n\n        regular_amplitude = model.amplitude(regular_trajectory, pulse_end)\n        pulse_amplitude = model.amplitude(pulse_trajectory, pulse_end)\n        amplitude_change = amplitude_percent_change(regular_amplitude, pulse_amplitude)\n        simulation_result[str(model)]['amplitude_response'].append(amplitude_change)\n\n# convert phase differences from radians to hours\nperiod = 24.2 # hours\nfor model in model_list:\n    phase_response = simulation_result[str(model)]['phase_response']\n    phase_response = np.array(phase_response) * period / (2 * np.pi)\n    simulation_result[str(model)]['phase_response'] = phase_response\n\n\n\n\n\n\n\n\n\n\nThis is the phase response curve for four different models. On the y-axis we have how much the phase of the circadian clock changes when the pulse ends. Positive values mean the clock is advanced with respect to an unperturbed case. On the x-axis we have the pulse end time relative to the core body temperature minimum (CBTmin). When the pulse ends close to CBTmin (x-axis value of 0) the phase of the clock is maximally advanced. On the contrary, when the pulse ends five hours before CBTmin, the clock is delayed the most. The overall shape of the response is similar between models.\n\n\nBuilding amplitude response curves\nOur previous simulation shows that not only the phase of the clock changes after a pulse, but also its amplitude. We already calculated the amplitude change in the previous section so we can plot the result\n\n\n\n\n\n\n\n\n\nThe models still have a similar response: all of them show a decrease in amplitude four hours before CBTmin. However, the magnitude of change in amplitude varies between them. For a more detailed discussion we refer the reader to Hannay et al. (2019).",
    "crumbs": [
      "Examples",
      "Circadian rhythm disruptions"
    ]
  },
  {
    "objectID": "api/models.html",
    "href": "api/models.html",
    "title": "Models",
    "section": "",
    "text": "The circadian.models module contains the essential tools for simulating circadian rhythms. The base class DynamicalTrajectory handles differential equation solutions, while the CircadianModel class handles the implementation of the models themselves. The first part of the documentation focuses on how to simulate circadian rhythms while the second part describes each model briefly. For a description of each implementation see the API Documentation.",
    "crumbs": [
      "API",
      "Models"
    ]
  },
  {
    "objectID": "api/models.html#custom-parameters-and-initial-conditions",
    "href": "api/models.html#custom-parameters-and-initial-conditions",
    "title": "Models",
    "section": "Custom parameters and initial conditions",
    "text": "Custom parameters and initial conditions\nIn the example above, we are not defining initial conditions nor parameters. This is because each model in the library has a default set of parameters and initial conditions. Initial conditions and parameters used in the simulation can be accessed by\n\nmodel.initial_condition\n\narray([-0.0843259 , -1.09607546,  0.45584306])\n\n\n\nmodel.parameters\n\n{'taux': 24.2,\n 'mu': 0.23,\n 'G': 33.75,\n 'alpha_0': 0.05,\n 'beta': 0.0075,\n 'p': 0.5,\n 'I0': 9500.0,\n 'k': 0.55,\n 'cbt_to_dlmo': 7.0}\n\n\nWe can run simulations with custom parameters and initial conditions by\n\nsimulation_days = 5\ndt = 0.5 # hours\ntime = np.arange(0, 24 * simulation_days, dt)\n\nlight_schedule = LightSchedule.Regular()\nlight_input = light_schedule(time)\n\ncustom_parameters = {\n    'taux': 14.0, 'mu': 0.3, 'G': 34.0, 'alpha_0': 0.07,\n    'delta': 0.0095, 'p': 0.7, 'I0': 9300.0, 'kparam': 0.75,\n    'cbt_to_dlmo': 7.0}\ncustom_initial_condition = np.array([0.5, 0.1, 0.1])\n\nmodel = Forger99(custom_parameters)\ntrajectory = model(time, custom_initial_condition, light_input)\n\n\nplt.plot(time/24.0, trajectory.states[:,0], label='x')\nplt.xlabel('Time (days)')\nplt.ylabel('State')\nplt.show()\n\n\n\n\n\n\n\n\nWhen defining custom parameters we can specify only a subset and the rest will maintain their default values (or any previously defined values).\n\nsimulation_days = 5\ndt = 0.5 # hours\ntime = np.arange(0, 24 * simulation_days, dt)\n\nlight_schedule = LightSchedule.Regular()\nlight_input = light_schedule(time)\n\nmodel = Forger99({'taux': 48.0})\ntrajectory = model(time,  input=light_input)",
    "crumbs": [
      "API",
      "Models"
    ]
  },
  {
    "objectID": "api/models.html#simulating-from-multiple-initial-conditions",
    "href": "api/models.html#simulating-from-multiple-initial-conditions",
    "title": "Models",
    "section": "Simulating from multiple initial conditions",
    "text": "Simulating from multiple initial conditions\nModels accept arrays of initial conditions allowing to simulate from multiple initial conditions at once. For example, to simulate the Forger99 model from 100 different initial conditions we can do\n\nsimulation_days = 10\ndt = 0.5 # hours\ntime = np.arange(0, 24 * simulation_days, dt)\n\nlight_schedule = LightSchedule.Regular()\nlight_input = light_schedule(time)\n\nx_values = np.linspace(-1.0, 1.0, 10)\nxc_values = np.linspace(-1.0, 1.0, 10)\nx_xc_stack = np.dstack(np.meshgrid(x_values, xc_values)).reshape(-1, 2)\nmultiple_initial_conditions = np.hstack((x_xc_stack, np.zeros((x_xc_stack.shape[0], 1))))\nmultiple_initial_conditions = multiple_initial_conditions.T\n\nmodel = Forger99()\ntrajectory = model(time, multiple_initial_conditions, light_input)\n\nNote that we have to format the initial conditions as a numpy array of dimensions (3, n) where n is the total number of initial conditions and 3 is the number of states in the model.\nThe resulting trajectory contains all the solutions in the same order as the initial conditions\n\ntrajectory.states.shape\n\n(480, 3, 100)\n\n\nWe can plot the solution for each initial condition by\n\nfor idx in range(trajectory.states.shape[2]):\n    plt.plot(time/24.0, trajectory.states[:,0,idx], \n             color='b', alpha=0.1)\nplt.xlabel('Time (days)')\nplt.ylabel('State')\nplt.show()\n\n\n\n\n\n\n\n\nThis is the recommended method to simulate multiple initial conditions–by passing a numpy array to the model. Our implementation takes advantage of numpy’s vectorization to speed up the calculation. If we simulate each initial condition individually, the simulation will be slower.",
    "crumbs": [
      "API",
      "Models"
    ]
  },
  {
    "objectID": "api/models.html#estimation-of-circadian-phase-markers",
    "href": "api/models.html#estimation-of-circadian-phase-markers",
    "title": "Models",
    "section": "Estimation of circadian phase markers",
    "text": "Estimation of circadian phase markers\nModels support the estimation of Dim Light Melatonin Onset (DLMO) and Core Body Temperature Minimum (CBTmin) directly from the solution\n\nsimulation_days = 5\ndt = 0.5 # hours\ntime = np.arange(0, 24 * simulation_days, dt)\n\nlight_schedule = LightSchedule.Regular()\nlight_input = light_schedule(time)\n\nmodel = Forger99()\ntrajectory = model(time, input=light_input)\n\ncbt_times = model.cbt()\ndlmo_times = model.dlmos()",
    "crumbs": [
      "API",
      "Models"
    ]
  },
  {
    "objectID": "api/models.html#amplitude-and-phase-calculation",
    "href": "api/models.html#amplitude-and-phase-calculation",
    "title": "Models",
    "section": "Amplitude and phase calculation",
    "text": "Amplitude and phase calculation\nModels also support the calculation of amplitude and phase at any desired timepoint\n\nsimulation_days = 5\ndt = 0.5 # hours\ntime = np.arange(0, 24 * simulation_days, dt)\n\nlight_schedule = LightSchedule.Regular()\nlight_input = light_schedule(time)\n\nmodel = Forger99()\ntrajectory = model(time, input=light_input)\n\nt_final = time[-1]\nfinal_phase = model.phase(time=t_final)\nfinal_amplitude = model.amplitude(time=t_final)\n\nFinal phase: 1.8767451135044504\nFinal amplitude: 1.0730477511869494",
    "crumbs": [
      "API",
      "Models"
    ]
  },
  {
    "objectID": "api/models.html#forger99",
    "href": "api/models.html#forger99",
    "title": "Models",
    "section": "Forger99",
    "text": "Forger99\nThe Forger99 model is taken from Forger, Jewett, and Kronauer’s 1999 article which defines a simplification of previous iterations of the van der Pol based oscillator models published in the 1990s. It is one of the most popular models in the circadian literature. The implementation in this package uses the parameters taken from Serkh and Forger 2014 rather than the parameters from the original paper.\nThe model states are defined by three dynamic variables: \\(x\\), \\(x_c\\), and \\(n\\). These states are related to circadian rhythms by defining the core body temperature minimum (a biomarker for circadian state) to be the minimum of the \\(x\\) variable.\nThe differential equations governing the evolution of the Forger99 model are:\n\\(\\frac{dx}{dt} = \\frac{\\pi}{12}(x_c + B)\\)\n\\(\\frac{dx_c}{dt} = \\frac{\\pi}{12}\\left\\{\\mu \\left( x_c - \\frac{4x_{c}^3}{3} \\right) - x \\left[ \\left( \\frac{24}{0.99669 \\tau_x} \\right)^2 + kB \\right] \\right\\}\\)\n\\(\\frac{dn}{dt} = 60[\\alpha(I)(1-n)-\\beta n]\\)\nwhere\n\\(\\alpha(I) = \\alpha_0\\left( \\frac{I^p}{I_0^p}\\right)\\)\n\\(B = G(1-n)\\alpha(I)(1-0.4x)(1-0.4x_c)\\)\nThe default parameters for this model are:\n\nmodel = Forger99()\nmodel.parameters\n\n{'taux': 24.2,\n 'mu': 0.23,\n 'G': 33.75,\n 'alpha_0': 0.05,\n 'beta': 0.0075,\n 'p': 0.5,\n 'I0': 9500.0,\n 'k': 0.55,\n 'cbt_to_dlmo': 7.0}\n\n\nThe cbt_to_dlmo parameter is used to convert the core body temperature minimum to DLMO. The default behavior is DLMO ocurring 7 hours before CBTmin.",
    "crumbs": [
      "API",
      "Models"
    ]
  },
  {
    "objectID": "api/models.html#jewett99",
    "href": "api/models.html#jewett99",
    "title": "Models",
    "section": "Jewett99",
    "text": "Jewett99\nThe Jewett99 model is taken from Jewett, Forger, and Kronauer’s 1999 article which defines several refinements to a van der Pol oscillator model developed by Kronauer previously. One of the main features of this model are the high-order terms in the differential equations which allow for a more accurate representation of the circadian system than previous models.\nSimilarly to Forger99 the model states are defined by three dynamic variables: \\(x\\), \\(x_c\\), and \\(n\\). The variable \\(x\\) is related to the core body temperature and \\(n\\) to the processed light input.\nThe differential equations governing the evolution of the Jewett99 model are:\n\\(\\frac{dx}{dt} = \\frac{\\pi}{12} \\left[x_c + \\mu \\left(\\frac{x}{3} + \\frac{4x^3}{3} - \\frac{256 x^7}{105}\\right) + B\\right]\\)\n\\(\\frac{dx_c}{dt} = \\frac{\\pi}{12} \\left\\{ q B x_c - \\left[ \\left( \\frac{24}{0.99729 \\tau_{x}} \\right)^2 + k B \\right] x \\right\\}\\)\n\\(\\frac{dn}{dt} = 60[\\alpha(I)(1-n)-\\beta n]\\)\nwhere\n\\(\\alpha(I) = \\alpha_0\\left( \\frac{I^p}{I_0^p}\\right)\\)\n\\(B = G(1-n)\\alpha(I)(1-0.4x)(1-0.4x_c)\\)\nThe default parameters for this model are:\n\nmodel = Jewett99()\nmodel.parameters\n\n{'taux': 24.2,\n 'mu': 0.13,\n 'G': 19.875,\n 'beta': 0.013,\n 'k': 0.55,\n 'q': 0.3333333333333333,\n 'I0': 9500,\n 'p': 0.6,\n 'alpha_0': 0.16,\n 'phi_ref': 0.8,\n 'cbt_to_dlmo': 7.0}\n\n\nThe cbt_to_dlmo and phi_ref parameters are used to calculate the core body temperature minimum and convert it to DLMO. The CBTmin is calculated as the minimum of the \\(x\\) variable plus a shift of \\(\\phi_{\\text{ref}}=0.8\\) hours. The DLMO is calculated as CBTmin minus 7.0 hours.",
    "crumbs": [
      "API",
      "Models"
    ]
  },
  {
    "objectID": "api/models.html#hannay19",
    "href": "api/models.html#hannay19",
    "title": "Models",
    "section": "Hannay19",
    "text": "Hannay19\nThe Hannay19 model is taken from Hannay, Booth, and Forger’s 2019 article. This model isn’t based on a van der Pol oscillator and instead it is systematically derived from a high-dimensional model for each clock neuron using the \\(m^2\\) ansatz (Hannay et al. 2018). The Hannay19 implementation corresponds to the single population model within the article.\nThe model describes the circadian state using polar coordinates and features a slight modification fo the light processing function found in van der Pol type models. Thus, the model states are defined by: \\(R\\), \\(\\psi\\), and \\(n\\).\nThe differential equations governing the evolution of the Hannay19 model are:\n\\(\\frac{dR}{dt} = - (D + \\gamma)R + \\frac{K}{2}cos(\\beta)R(1-R^4) + L_R(R, \\psi)\\)\n\\(\\frac{d\\psi}{dt} = \\omega_0 + \\frac{K}{2}sin(\\beta)(1+R^4) + L_{\\psi}(R,\\psi)\\)\n\\(\\frac{dn}{dt} = 60\\left[\\alpha(I)(1-n)-\\delta n \\right]\\)\nwhere\n\\(L_R(R,\\psi) = \\frac{A_1}{2}B(t)(1-R^4)cos(\\psi + \\beta_{L1}) + \\frac{A_2}{2}B(t)R(1-R^8)cos(2\\psi + \\beta_{L2})\\)\n\\(L_{\\psi}(R, \\psi) = \\sigma B(t) - \\frac{A_1}{2}B(t)\\left(\\frac{1}{R} + R^3 \\right)\\sin(\\psi + \\beta_{L1}) - \\frac{A_2}{2}B(t)(1+R^8)\\sin(2\\psi + \\beta_{L2})\\)\n\\(\\alpha(I) = \\frac{\\alpha_0 I^p}{I^p + I_0}\\)\n\\(B(t) = G(1-n)\\alpha(L)\\)\nThe default parameters for this model are:\n\nmodel = Hannay19()\nmodel.parameters\n\n{'tau': 23.84,\n 'K': 0.06358,\n 'gamma': 0.024,\n 'Beta1': -0.09318,\n 'A1': 0.3855,\n 'A2': 0.1977,\n 'BetaL1': -0.0026,\n 'BetaL2': -0.957756,\n 'sigma': 0.0400692,\n 'G': 33.75,\n 'alpha_0': 0.05,\n 'delta': 0.0075,\n 'p': 1.5,\n 'I0': 9325.0,\n 'cbt_to_dlmo': 7.0}\n\n\nThe cbt_to_dlmo parameter is used to convert the core body temperature minimum to DLMO. The default behavior is DLMO ocurring 7 hours before CBTmin.",
    "crumbs": [
      "API",
      "Models"
    ]
  },
  {
    "objectID": "api/models.html#hannay19tp",
    "href": "api/models.html#hannay19tp",
    "title": "Models",
    "section": "Hannay19TP",
    "text": "Hannay19TP\nThe Hannay19TP model comes from the same article as Hannay19 but stems from two populations of clock neurons rather than one. These two populations are the dorsal and ventral ones which define the model states to be: \\(R_v\\), \\(R_d\\), \\(\\psi_v\\), \\(\\psi_d\\), and \\(n\\).\nThe differential equations governing the evolution of the Hannay19TP model are:\n\\(\\frac{dR_v}{dt} = -\\gamma R_v + \\frac{K_{vv}}{2} R_v (1 - R_{v}^4) + \\frac{K_{dv}}{2}R_d (1 - R_{v}^4)\\cos(\\psi_d - \\psi_v) + L_R(R_v, \\psi_v)\\)\n\\(\\frac{dR_d}{dt} = -\\gamma R_d + \\frac{K_{dd}}{2} R_d (1 - R_{d}^4) + \\frac{K_{vd}}{2} R_v (1 - R_{d}^4)\\cos(\\psi_d - \\psi_v)\\)\n\\(\\frac{d\\psi_v}{dt} = \\omega_v + \\frac{K_{dv}}{2} R_d \\left( \\frac{1}{R_v} + R_{v}^3\\right)\\sin(\\psi_d - \\psi_v) + L_\\psi(R_v, \\psi_v)\\)\n\\(\\frac{d\\psi_d}{dt} = \\omega_d - \\frac{K_{vd}}{2} R_v \\left( \\frac{1}{R_d} + R_{d}^3\\right)\\sin(\\psi_d - \\psi_v)\\)\n\\(\\frac{dn}{dt} = 60\\left[\\alpha(I)(1-n)-\\delta n \\right]\\)\nwhere\n\\(L_R(R_v,\\psi_v) = \\frac{A_1}{2}B(t)(1-R_v^4)cos(\\psi_v + \\beta_{L1}) + \\frac{A_2}{2}B(t)R_v(1-R_v^8)cos(2\\psi_v + \\beta_{L2})\\)\n\\(L_{\\psi}(R_v, \\psi_v) = \\sigma B(t) - \\frac{A_1}{2}B(t)\\left(\\frac{1}{R_v} + R_v^3 \\right)\\sin(\\psi_v + \\beta_{L1}) - \\frac{A_2}{2}B(t)(1+R_v^8)\\sin(2\\psi_v + \\beta_{L2})\\)\n\\(\\alpha(I) = \\frac{\\alpha_0 I^p}{I^p + I_0}\\)\n\\(B(t) = G(1-n)\\alpha(L)\\)\nThe default parameters for this model are:\n\nmodel = Hannay19TP()\nmodel.parameters\n\n{'tauV': 24.25,\n 'tauD': 24.0,\n 'Kvv': 0.05,\n 'Kdd': 0.04,\n 'Kvd': 0.05,\n 'Kdv': 0.01,\n 'gamma': 0.024,\n 'A1': 0.440068,\n 'A2': 0.159136,\n 'BetaL': 0.06452,\n 'BetaL2': -1.38935,\n 'sigma': 0.0477375,\n 'G': 33.75,\n 'alpha_0': 0.05,\n 'delta': 0.0075,\n 'p': 1.5,\n 'I0': 9325.0,\n 'cbt_to_dlmo': 7.0}\n\n\nThe cbt_to_dlmo parameter is used to convert the core body temperature minimum to DLMO. The default behavior is DLMO ocurring 7 hours before CBTmin.",
    "crumbs": [
      "API",
      "Models"
    ]
  },
  {
    "objectID": "api/models.html#hilaire07",
    "href": "api/models.html#hilaire07",
    "title": "Models",
    "section": "Hilaire07",
    "text": "Hilaire07\nThe Hilaire07 model is taken from Hilaire et al. 2007 which extends the Jewett99 model to include a non-photic input. The model states are defined by three dynamic variables: \\(x\\), \\(x_c\\), and \\(n\\) whereas the inputs are light and sleep/wake state. The variable \\(x\\) is related to the core body temperature and \\(n\\) to the processed light input.\nThe differential equations governing the evolution of the Hilaire07 model are:\n\\(\\frac{dx}{dt} = \\frac{\\pi}{12} \\left[x_c + \\mu \\left(\\frac{x}{3} + \\frac{4x^3}{3} - \\frac{256 x^7}{105}\\right) + B + N_{s}\\right]\\)\n\\(\\frac{dx_c}{dt} = \\frac{\\pi}{12} \\left\\{ q B x_c - \\left[ \\left( \\frac{24}{0.99729 \\tau_{x}} \\right)^2 + k B \\right] x \\right\\}\\)\n\\(\\frac{dn}{dt} = 60[\\alpha(I)(1-n)-\\beta n]\\)\nwhere\n\\(\\alpha(I) = \\alpha_0\\left( \\frac{I^p}{I_0^p}\\right) \\left( \\frac{I}{I + 100} \\right)\\)\n\\(B = G(1-n)\\alpha(I)(1-0.4x)(1-0.4x_c)\\)\n\\(N_{s} = \\hat{N}_{s} \\left[1 - \\tanh(10x) \\right]\\)\n\\(\\hat{N}_{s} = \\left\\{\\begin{matrix}\n\\frac{\\rho}{3} & \\text{if} \\ \\ \\ \\psi_{cx} \\in (16.5, 21.0) \\\\\n(\\frac{1}{3} - \\sigma) \\rho & \\text{otherwise}\n\\end{matrix}\\right.\\)\n\\(\\psi_{cx} = \\left[ (t \\mod 24) - 24\\frac{\\phi_{xcx} + \\phi_{ref}}{2\\pi} \\right]\\mod 24\\)\n\\(\\sigma = \\left\\{\\begin{matrix}\n1 & \\text{if asleep} \\\\\n0 & \\text{if awake}\n\\end{matrix}\\right.\\)\nNote that both \\(I\\) and \\(\\sigma\\) are inputs to the model\nThe default parameters for this model are:\n\nmodel = Hilaire07()\nmodel.parameters\n\n{'taux': 24.2,\n 'G': 37.0,\n 'k': 0.55,\n 'mu': 0.13,\n 'beta': 0.007,\n 'q': 0.3333333333333333,\n 'rho': 0.032,\n 'I0': 9500.0,\n 'p': 0.5,\n 'a0': 0.1,\n 'phi_xcx': -2.98,\n 'phi_ref': 0.97,\n 'cbt_to_dlmo': 7.0}\n\n\nThe cbt_to_dlmo and phi_ref parameters are used to calculate the core body temperature minimum and convert it to DLMO. The CBTmin is calculated as the minimum of the \\(x\\) variable plus a shift of \\(\\phi_{\\text{ref}}=0.97\\) hours. The DLMO is calculated as CBTmin minus 7.0 hours.",
    "crumbs": [
      "API",
      "Models"
    ]
  },
  {
    "objectID": "api/models.html#skeldon23",
    "href": "api/models.html#skeldon23",
    "title": "Models",
    "section": "Skeldon23",
    "text": "Skeldon23\nThe Skeldon23 model is based on Skeldon et al. 2023 which combines a sleep pressure model with Forger99 to estimate realistic sleep/wake patterns. The model states are defined by four dynamic variables: \\(x\\), \\(x_c\\), \\(n\\), and \\(H\\). The variable \\(x\\) is related to the core body temperature, \\(n\\) to the processed light input, and \\(H\\) to the sleep pressure signal. Note that in our implementation we have favored Forger99’s notation of variables. In the original article, Skeldon et al. use variables \\(x\\) and \\(y\\) to indicate \\(x_c\\) and \\(x\\) respectively. Additionally, in this implementation, we have rescaled parameters to be defined in terms of hours rather than seconds. In addition to providing the states over time, the model also predicts sleep/wake patterns for each timepoint.\nThe differential equations governing the evolution of the Skeldon23 model are:\n\\(\\frac{dx}{dt} = \\frac{1}{\\kappa} \\left(x_c + B \\right)\\)\n\\(\\frac{dx_c}{dt} = \\frac{1}{\\kappa}\\left\\{\\gamma \\left( x_c - \\frac{4x_{c}^3}{3} \\right) - x \\left[ \\left( \\frac{24}{f \\tau_x} \\right)^2 + kB \\right] \\right\\}\\)\n\\(\\frac{dn}{dt} = 60[\\alpha(\\tilde{I})(1-n)-\\beta n]\\)\n$ = $\nwhere\n\\(S = \\left\\{\\begin{matrix}\n1 & \\text{if asleep} \\\\\n0 & \\text{if awake}\n\\end{matrix}\\right.\\)\n\\(\\tilde{I} = (1 - S) I\\)\n\\(\\alpha(\\tilde{I}) = \\alpha_0\\left( \\frac{\\tilde{I}}{I_0}\\right)^p\\)\n\\(B = G(1-n)\\alpha(\\tilde{I})(1-bx)(1-bx_c)\\)\nthe variable \\(S\\) switches automatically based on the sleep pressure signal \\(H\\) and the circadian input to the sleep model \\(C\\):\n\\(C(t) = c_{20} + \\alpha_{21}x_{c} + \\alpha_{22}x + \\beta_{21}x_{c}^2 + \\beta_{22}x_{c}x + \\beta_{23}x^2\\)\nThe change from wake to sleep occurs when \\(H\\) reaches\n\\(H^{+}(t) = \\overline{H}_{0} + \\frac{\\Delta}{2} + c_{a} C(t)\\)\nand the change from sleep to wake occurs when \\(H\\) reaches\n\\(H^{-}(t) = \\overline{H}_{0} - \\frac{\\Delta}{2} + c_{a} C(t)\\)\nThe default parameters for this model are:\n\nmodel = Skeldon23()\nmodel.parameters\n\n{'mu': 17.78,\n 'chi': 45.0,\n 'H0': 13.0,\n 'Delta': 1.0,\n 'ca': 1.72,\n 'tauc': 24.2,\n 'f': 0.99669,\n 'G': 19.9,\n 'p': 0.6,\n 'k': 0.55,\n 'b': 0.4,\n 'gamma': 0.23,\n 'alpha_0': 0.16,\n 'beta': 0.013,\n 'I0': 9500.0,\n 'kappa': 3.819718634205488,\n 'c20': 0.7896,\n 'alpha21': -0.3912,\n 'alpha22': 0.7583,\n 'beta21': -0.4442,\n 'beta22': 0.025,\n 'beta23': -0.9647,\n 'S0': 0.0,\n 'cbt_to_dlmo': 7.0,\n 'forced_wakeup_light_threshold': None}\n\n\nThe cbt_to_dlmo parameter is used to convert the core body temperature minimum to DLMO. The default behavior is DLMO ocurring 7 hours before CBTmin.",
    "crumbs": [
      "API",
      "Models"
    ]
  },
  {
    "objectID": "api/plots.html",
    "href": "api/plots.html",
    "title": "Plots",
    "section": "",
    "text": "Actogram\n\nslam_shift = LightSchedule.SlamShift() \ntime = np.arange(0, 20*24.0, 0.10)\nlight_values = slam_shift(time) \n\nact = Actogram(time, light_vals=light_values, smooth=False)\n\nspm = Hannay19()\ntrajectory = spm(time, np.array([1.0, np.pi, 0.0]), light_values)\ndlmo = spm.dlmos()\n\nact.plot_phasemarker(dlmo, color='blue')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nMAE\n\ndlmo_experimental = np.linspace(-12, 12., 30) \ndlmo_predicted = dlmo_experimental + np.random.normal(0, 2, len(dlmo_experimental))\n\nplot_mae(dlmo_experimental, dlmo_predicted)\n\nThe MAE is: 4.893222072754772\nWithin one hour 7/30\n[-3.47328784e+00  2.29203680e+01  2.14370972e+01  2.05151476e+01\n -8.28809784e-01  3.29152432e+00 -1.03521731e+00 -1.21786907e+00\n  6.01046181e-01 -8.64421152e-01  2.32069554e+00 -1.20140297e+00\n  1.11533503e+00 -1.35758354e+00 -1.13861312e+00  1.62675565e+00\n  1.03264169e+00  1.65883693e+00  1.66964836e+00 -2.41250659e+00\n  3.98410068e-01  2.24680534e+00  4.61070620e-01 -1.11127185e-02\n  8.78906427e-02  1.18376113e+00  1.25223210e+00 -2.07873084e+01\n -2.31041479e+01 -5.54511532e+00]\n\n\n\n\n\n\n\n\n\n\n\nTorus\n\nphi1 = 12.0 + 5.0*np.random.randn(100) \nphi2 = phi1 + 5.0*np.random.randn(100)\n\nplot_torus(phi1, phi2, scaled_by=24.0, color='darkgreen')\nplt.title(\"Example torus plot\")\nplt.xlabel(\"$\\phi_1$\") \nplt.ylabel(\"$\\phi_2$\");\n\n\n\n\n\n\n\n\n\n\nStroboscopic\n\nslam_shift = LightSchedule.SlamShift(shift=12.0, lux=500.0, before_days=2) \ntime = np.arange(0.0, 15*24.0, 0.10)\nlight_values = slam_shift(time)\n# Run this for a range of period parameters \nbatch_dim = 50\nhmodel = Hannay19({'tau': np.linspace(23.5, 24.5, batch_dim)}) \n\ninitial_state = np.array([1.0, np.pi, 0.0]) + np.zeros((batch_dim, 3))\ninitial_state = initial_state.T\ntrajectory = hmodel(time, initial_state, light_values)\n\nax = plt.gca()\ncmap = plt.get_cmap('jet')\nfor idx in range(trajectory.batch_size):\n    Stroboscopic(ax, \n                 time, \n                 trajectory.states[:, 0, idx], \n                 trajectory.states[:, 1, idx], \n                 period=24.0, \n                 lw=0.50,\n                 color=cmap(idx/batch_dim));\nplt.title(\"Stroboscopic plot of the Hannay et al. 2019 model\");",
    "crumbs": [
      "API",
      "Plots"
    ]
  },
  {
    "objectID": "api/lights.html",
    "href": "api/lights.html",
    "title": "Lights",
    "section": "",
    "text": "source",
    "crumbs": [
      "API",
      "Lights"
    ]
  },
  {
    "objectID": "api/lights.html#regular-light",
    "href": "api/lights.html#regular-light",
    "title": "Lights",
    "section": "Regular light",
    "text": "Regular light\nLightSchedule.Regular is a typical light schedule that repeats every 24 hours. The default schedule is 16 hours of light and 8 hours of darkness, but this can be changed by passing lights_on and lights_off to the constructor.\n\nregular_light = LightSchedule.Regular()\nax = regular_light.plot(0.0, 24*7.0)\nax.set_xlabel('Time (hours)');\nax.set_ylabel('Light (lux)');\nax.figure.set_size_inches(16, 4);\n# add a vertical line to the start of each day in dashed gray\nfor day in range(8):\n    ax.axvline(day*24.0, color='gray', linestyle='--');\nax.set_xticks(np.arange(0, 24.0*8.0, 12));\nax.set_xlim(0.0, 24.0*7.0);",
    "crumbs": [
      "API",
      "Lights"
    ]
  },
  {
    "objectID": "api/lights.html#shift-worker",
    "href": "api/lights.html#shift-worker",
    "title": "Lights",
    "section": "Shift worker",
    "text": "Shift worker\nLightSchedule.ShiftWork approximates what a typical light schedule looks for some shift workers. The schedule is periodic over a whole work week (determined by the sum of days_on and days_off) and implements transitions between workdays and days off. The default schedule is:\n\nshift_schedule = LightSchedule.ShiftWork()\nax = shift_schedule.plot(0.0, 24.0*8.0)\nax.set_xlabel('Time (hours)');\nax.set_ylabel('Light (lux)');\nax.figure.set_size_inches(16, 4);\n# add a vertical line to the start of each day in dashed gray\nfor day in range(8):\n    ax.axvline(day*24.0, color='gray', linestyle='--');\nax.set_xticks(np.arange(0, 24.0*8.0, 12));\ndays_on = 5\ndays_off = 2\nlights_off_workday = 9.0\nlights_on_workday = 17.0\ntime_last_workday = lights_off_workday + 24*(days_on-1)\ntime_last_day_off = lights_on_workday + 24.0*(days_on + days_off - 1)\ntime_first_workday = time_last_day_off + lights_on_workday\n# set background color to light red for the workdays\nax.axvspan(0.0, time_last_workday, facecolor='r', alpha=0.1, label='Workdays');\nax.axvspan(time_last_day_off, time_first_workday, facecolor='r', alpha=0.1);\n# set background color to light green for days off\nax.axvspan(time_last_workday, time_last_day_off, facecolor='g', alpha=0.1, label='Days off');\n# set limits to be a week\nax.set_xlim(0.0, 24.0*7.0);\n# place legend at the top of the plot\nax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=2);\n\n/tmp/ipykernel_94570/315566313.py:38: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  float(test_output)",
    "crumbs": [
      "API",
      "Lights"
    ]
  },
  {
    "objectID": "api/lights.html#slam-shift",
    "href": "api/lights.html#slam-shift",
    "title": "Lights",
    "section": "Slam shift",
    "text": "Slam shift\nLightSchedule.SlamShift approximates the light schedule that slam shift workers experience when changing shifts. The schedule starts with before_days where the worker is on a regular schedule and then shifts to a new schedule by shift hours. Before the shift happens, there’s a transition via sleep banking. The default schedule is:\n\nslam_shift = LightSchedule.SlamShift()\nax = slam_shift.plot(0.0, 24.0*12.0)\nax.set_xlabel('Time (hours)');\nax.set_ylabel('Light (lux)');\nax.figure.set_size_inches(16, 4);\n# add a vertical line to the start of each day in dashed gray\nfor day in range(13):\n    ax.axvline(day*24.0, color='gray', linestyle='--');\nax.set_xticks(np.arange(0, 24.0*12.0, 12));\n# set background color to light red for the days before the shift\nax.axvspan(0.0, 24.0*5, facecolor='r', alpha=0.1, label='Before shift');\n# set background color to light green for days after the shift\nax.axvspan(24.0*5, 24.0*12.0, facecolor='g', alpha=0.1, label='After shift');\n# place legend at the top of the plot\nax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=2);\nax.set_xlim(0.0, 24.0*12.0);",
    "crumbs": [
      "API",
      "Lights"
    ]
  },
  {
    "objectID": "api/lights.html#social-jet-lag",
    "href": "api/lights.html#social-jet-lag",
    "title": "Lights",
    "section": "Social jet lag",
    "text": "Social jet lag\nLightSchedule.SocialJetlag implements a light schedule where the person stays up late on weekends while maintaining a regular schedule during the week. The schedule is periodic over the sum of num_regular_days and num_jetlag_days.\n\nsocial_jetlag = LightSchedule.SocialJetlag()\nax = social_jetlag.plot(0.0, 24.0*8.0)\nax.set_xlabel('Time (hours)');\nax.set_ylabel('Light (lux)');\nax.figure.set_size_inches(16, 4);\n# add a vertical line to the start of each day in dashed gray\nfor day in range(9):\n    ax.axvline(day*24.0, color='gray', linestyle='--');\nax.set_xticks(np.arange(0, 24.0*8.0, 12));\n# set background color to light red for the regular days\nax.axvspan(0.0, 24.0*5, facecolor='r', alpha=0.1, label='Regular days');\nax.axvspan(24.0*7, 24.0*8.0, facecolor='r', alpha=0.1);\n# set background color to light green for days with jetlag\nax.axvspan(24.0*5, 24.0*7.0, facecolor='g', alpha=0.1, label='Social Jetlag days');\n# place legend at the top of the plot\nax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=2);\nax.set_xlim(0.0, 24.0*8.0);\n\n/tmp/ipykernel_94570/315566313.py:38: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  float(test_output)",
    "crumbs": [
      "API",
      "Lights"
    ]
  },
  {
    "objectID": "api/lights.html#light-protocol-from-st.-hilaire-et-al.-2012",
    "href": "api/lights.html#light-protocol-from-st.-hilaire-et-al.-2012",
    "title": "Lights",
    "section": "Light protocol from St. Hilaire et al. 2012",
    "text": "Light protocol from St. Hilaire et al. 2012\nLightSchedule.Hilaire12 implements the light protocol used in Hilaire et al. 2012. The schedule consists of: - A first baseline day with 24 hours of regular_lux=90 lux - A second baseline day with 16 hours of regular_lux=90 lux and 8 hours of darkness - A third day with 16 hours of light and 8 hours of darkness. The 16 hours of light are divided into 8 hours of regular_lux=90 lux and 8 hours of constant_routine_lux=3 lux. - 8 hours of darkness - A constant routine region of first_constant_routine_duration hours with constant_routine_lux=3 lux - 8 hours of darkness - 16 hours of constant_routine_lux=3 lux with a pulse of pulse_lux=8000 lux and pulse_duration hours at the middle of the light period (the pulse’s center is aligned with the center of the light period) - 8 hours of darkness - second_constant_routine_duration hours of constant_routine_lux=3 lux\nThe only required parameters are first_constant_routine_duration and second_constant_routine_duration which help time the pulse of light relative to the circadian phase. The other parameters have default values following the original paper.\n\nhilaire_schedule = LightSchedule.Hilaire12(30, 48)\ntime = np.linspace(0, 200, 2000)\nlight_values = hilaire_schedule(time)\n\nplt.plot(time, light_values)\nplt.ylabel('Light (lux)')\nplt.xlabel('Time (hours)')\nplt.yscale('log')\n\nax = plt.gca()\nax.figure.set_size_inches(12, 4);\nax.axvspan(0.0, 24*3, facecolor='r', alpha=0.3, label='Baseline days');\nax.axvline(24.0, color='gray', linestyle='--');\nax.axvline(48.0, color='gray', linestyle='--');\nax.axvline(72.0, color='gray', linestyle='--');\nax.axvspan(24*3 + 8, 24*3 + 8 + 30, facecolor='g', alpha=0.3, label='First constant routine (CR1)');\nax.axvspan(24*3 + 8 + 30 + 8 + 7.5,\n           24*3 + 8 + 30 + 8 + 8.5, facecolor='y', alpha=0.3, label='Pulse');\nax.axvspan(24*3 + 8 + 30 + 8 + 16 + 8, \n           24*3 + 8 + 30 + 8 + 16 + 8 + 48, facecolor='tab:purple', alpha=0.3, label='Second constant routine (CR2)');\nax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=4);\nax.set_xlim(0.0, 24*3 + 8 + 30 + 8 + 16 + 8 + 48);\nplt.show()",
    "crumbs": [
      "API",
      "Lights"
    ]
  },
  {
    "objectID": "api/lights.html#light-protocol-from-chang-et-al.-2014",
    "href": "api/lights.html#light-protocol-from-chang-et-al.-2014",
    "title": "Lights",
    "section": "Light protocol from Chang et al. 2014",
    "text": "Light protocol from Chang et al. 2014\nLightSchedule.Chang14 implements the light protocol used in Chang et al. 2014. In this study, authors explore the effect of light-emitting eBooks on sleep. The schedule spans a total of 14 days. Each week has the same schedule except for the type of light received on reading sessions: - A first day with no reading and dim light between noon and 10pm - A second day with dim light for 6 hours after wake up time (6am), and a reading session on dim light 4 hours before bed (10pm bedtime). The light received from the reading devices is controlled by ereader_lux and book_lux. Which condition happens on the first week is set by first_reading_condition. - Four days of reading consisting of typical_indoor_lux between 6am and 6pm followed by a reading session under dim_lux plus the light received from reading devices\n\nchang_schedule = LightSchedule.Chang14()\ntime = np.linspace(0, 24 * 14, 100 * 14)\nlight_values = chang_schedule(time)\n\nplt.plot(time, light_values)\nplt.ylabel('Light (lux)')\nplt.xlabel('Time (hours)')\n\nax = plt.gca()\nax.figure.set_size_inches(12, 4)\n\n# axvline every 24 hours\nfor i in range(15):\n    ax.axvline(i * 24, color='gray', linestyle='--')\n# ebook\nfor i in range(5):\n    ax.axvspan(24 * (i + 1) + 18, 24 * (i + 1) + 18 + 4, facecolor='r', alpha=0.3)\n# book\nfor i in range(5):\n    ax.axvspan(24 * (i + 7) + 18, 24 * (i + 7) + 18 + 4, facecolor='g', alpha=0.3)\n# Constant procedure\n# Create legend for book and ebook\nax.axvspan(0, 0, facecolor='r', alpha=0.3, label='eReader')\nax.axvspan(0, 0, facecolor='g', alpha=0.3, label='Book')\nax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=2)\n\nplt.show()",
    "crumbs": [
      "API",
      "Lights"
    ]
  },
  {
    "objectID": "test/test_readers.html",
    "href": "test/test_readers.html",
    "title": "Testing for the readers module",
    "section": "",
    "text": "import pandas as pd\nfrom fastcore.test import *\nfrom circadian.readers import *\n\n\nPandas Accessor\n\n# test WereableData's column validation\ndf_only_datetime = pd.DataFrame({'datetime': pd.date_range('2020-01-01', periods=10)})\ntest_fail(lambda: WearableData._validate_columns(df_only_datetime),\n          contains=\"DataFrame must have at least one wearable data column from: ['steps',\")\ndf_only_wearable = pd.DataFrame({'steps': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})\ntest_fail(lambda: WearableData._validate_columns(df_only_wearable),\n          contains=\"DataFrame must have 'datetime' column\")\n# test WearableData's metadata validation\ntest_fail(lambda: WearableData._validate_metadata({'data_id': 1, 'subject_id': 'test'}),\n          contains=\"Metadata values must be strings\")\ntest_fail(lambda: WearableData._validate_metadata({'test': 'test'}),\n          contains=\"Metadata must have at least one of the following keys: data_id, subject_id\")\n# test column renaming\ndf = pd.DataFrame({'DateTime': pd.date_range('2020-01-01', periods=10),\n                     'Steps': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]})\nWearableData.rename_columns(df, inplace=True)\ntest_eq(df.columns.tolist(), ['datetime', 'steps'])\nnew_df = WearableData.rename_columns(df)\ntest_eq(new_df.columns.tolist(), ['datetime', 'steps'])\n# test is_valid\ndf = pd.DataFrame({'datetime': pd.date_range('2020-01-01', periods=10),\n                   'steps': [0, 10, 0, 0, 0, 0, 20, 28, 0, 0],\n                   'heartrate': [120, 90, 100, 80, 120, 100, 140, 130, 120, 110]})\ntest_eq(df.wearable.is_valid(), True)\ndf = pd.DataFrame({'Datetime': pd.date_range('2020-01-01', periods=10),\n                   'Steps': [0, 10, 0, 0, 0, 0, 20, 28, 0, 0],\n                   'Heartrate': [120, 90, 100, 80, 120, 100, 140, 130, 120, 110]})\ntest_fail(lambda: df.wearable.is_valid(),\n          contains=\"DataFrame must have 'datetime'\")\n# test add_metadata\ndf = pd.DataFrame({'datetime': pd.date_range('2020-01-01', '2020-01-02', periods=10),\n                   'steps': [0, 10, 0, 0, 0, 0, 20, 28, 0, 0],\n                   'heartrate': [120, 90, 100, 80, 120, 100, 140, 130, 120, 110]})\ndf.wearable.add_metadata({'data_id': 'test', 'subject_id': 'test'}, inplace=True)\ntest_eq(df.attrs['data_id'], 'test')\ntest_eq(df.attrs['subject_id'], 'test')\n\n\n\nLoad files\n\n# tests for load_json\n# test error handling\ntest_fail(lambda: load_json(1), contains=\"Filepath must be a string.\")\ndata_path = '../../circadian/sample_data/sample_data.json'\ntest_fail(lambda: load_json(data_path, metadata={'data_id': 1, 'subject_id': 'test'}),\n            contains=\"Metadata values must be strings.\")\n# TODO: test when all keys are not valid\n# TODO: test that excluded message is printed\n# test loading a json\ndf_dict = load_json(data_path)\ndf_dict = load_json(data_path, metadata={'data_id': 'sample_data', 'subject_id': 'sample_subject'})\n# test that metadata was added\ntest_eq(df_dict['steps'].attrs['data_id'], 'sample_data')\ntest_eq(df_dict['steps'].attrs['subject_id'], 'sample_subject')\n# test that datetime column was added\ntest_eq('datetime' in df_dict['heartrate'].columns, True)\ntest_eq('start' in df_dict['steps'].columns, True)\n\n\n# test loading a csv\ndata_path = '../../circadian/sample_data/hr_data.csv'\ndf = load_csv(data_path, timestamp_col='timestamp')\ndf = load_csv(data_path, \n              metadata={'data_id': 'sample_data', 'subject_id': 'sample_subject'},\n              timestamp_col='timestamp')\n# test loading a csv with no datetime column\ntest_fail(lambda: load_csv(data_path), \n          contains=\"CSV file must have a column named 'datetime' or\")\ntest_fail(lambda: load_csv(data_path, metadata={'data_id': '1', 'subject_id': 'sample_subject'}),\n          contains=\"CSV file must have a column named 'datetime' or\")\n# test input validation\ntest_fail(lambda: load_csv(1),\n          contains=\"Filepath must be a string.\")\ntest_fail(lambda: load_csv(data_path, timestamp_col=1),\n          contains=\"Timestamp column must be a string.\")\ntest_fail(lambda: load_csv(data_path, metadata=1),\n          contains=\"Metadata must be a dictionary.\")\n\n\n# test loading an actiwatch csv\ndata_path = '../../circadian/sample_data/sample_actiwatch.csv'\ndf = load_actiwatch(data_path)\n# test input validation\ntest_fail(lambda: load_actiwatch(1),\n          contains=\"Filepath must be a string.\")\ntest_fail(lambda: load_actiwatch(data_path, metadata=1),\n          contains=\"Metadata must be a dictionary.\")\n\n\n\nResampling\n\n# test resampling wearable dataframes\n# intervals smaller than frequency, no overlapping intervals\ndf = pd.DataFrame({\n    'start': [\n        pd.Timestamp('2023-01-01 00:00:00'), pd.Timestamp('2023-01-01 22:00:00'),\n        pd.Timestamp('2023-01-02 10:00:00'),\n        pd.Timestamp('2023-01-02 22:00:00'), pd.Timestamp('2023-01-03 20:00:00'),\n    ],\n    'end': [\n        pd.Timestamp('2023-01-01 01:10:00'), pd.Timestamp('2023-01-02 02:00:00'),\n        pd.Timestamp('2023-01-02 10:15:00'),\n        pd.Timestamp('2023-01-03 08:00:00'), pd.Timestamp('2023-01-03 23:00:00'),\n    ],\n    'steps': [\n        10, 10,\n        10,\n        10, 10,\n    ],\n})\nname = 'steps'\nmethod = 'sum'\nfrequency = '1D'\nground_truth = pd.DataFrame({\n    'datetime': [\n        pd.Timestamp('2023-01-01 00:00:00'),\n        pd.Timestamp('2023-01-02 00:00:00'),\n        pd.Timestamp('2023-01-03 00:00:00'),\n    ],\n    'steps': [\n        15.0,\n        17.0,\n        18.0,\n    ],\n})\nnew_df = resample_df(df, name, frequency, method)\ntest_eq(new_df, ground_truth)\n# per datetime data\ndf = pd.DataFrame({\n    'datetime': [\n        pd.to_datetime('2020-01-01 00:00:00'),\n        pd.to_datetime('2020-01-01 00:15:00'),\n        pd.to_datetime('2020-01-01 00:22:00'),\n        pd.to_datetime('2020-01-01 00:40:00'),\n        pd.to_datetime('2020-01-01 01:02:00'),\n    ],\n    'heartrate': [90, 110, 80, 90, 100],\n})\ntwenty_min_groud_truth = pd.DataFrame({\n    'datetime': [\n        pd.to_datetime('2020-01-01 00:00:00'),\n        pd.to_datetime('2020-01-01 00:20:00'),\n        pd.to_datetime('2020-01-01 00:40:00'),\n        pd.to_datetime('2020-01-01 01:00:00'),\n    ],\n    'heartrate': [100.0, 85.0, 90.0, 100.0],\n})\nname = 'heartrate'\nmethod = 'mean'\n# 20 min freq\nfreq = '20min'\nnew_df = resample_df(df, name, freq, method)\ntime_diff = (new_df.datetime - new_df.datetime.shift()).unique()\ntime_diff = time_diff[~pd.isnull(time_diff)][0]\ntest_eq(time_diff.seconds / 60.0, 20.0)\ntest_eq(new_df, twenty_min_groud_truth)\n\n\n\nCombine\n\n# test combining wearable dataframes\nsteps_df = pd.DataFrame({\n    'start': [\n        pd.to_datetime('2020-01-01 00:01:00'),\n        pd.to_datetime('2020-01-01 00:11:00'),\n        pd.to_datetime('2020-01-01 00:15:00'),\n        pd.to_datetime('2020-01-01 00:20:00'),\n        pd.to_datetime('2020-01-01 00:50:00'),\n    ],\n    'end': [\n        pd.to_datetime('2020-01-01 00:11:00'),\n        pd.to_datetime('2020-01-01 00:15:00'),\n        pd.to_datetime('2020-01-01 00:25:00'),\n        pd.to_datetime('2020-01-01 00:30:00'),\n        pd.to_datetime('2020-01-01 01:00:00'),\n    ],\n    'steps': [9, 18, 15, 30, 10],\n})\nheartrate_df = pd.DataFrame({\n    'datetime': [\n        pd.to_datetime('2020-01-01 00:09:00'),\n        pd.to_datetime('2020-01-01 00:15:00'),\n        pd.to_datetime('2020-01-01 00:22:00'),\n        pd.to_datetime('2020-01-01 00:40:00'),\n        pd.to_datetime('2020-01-01 00:58:00'),\n    ],\n    'heartrate': [90, 110, 80, 90, 100],\n})\ndf_dict = {\n    'steps': steps_df,\n    'heartrate': heartrate_df,\n}\nresample_freq = '10min'\ndf = combine_wearable_dataframes(df_dict, resample_freq)\nground_truth = pd.DataFrame({\n    'datetime': [\n        pd.to_datetime('2020-01-01 00:01:00'),\n        pd.to_datetime('2020-01-01 00:11:00'),\n        pd.to_datetime('2020-01-01 00:21:00'),\n        pd.to_datetime('2020-01-01 00:31:00'),\n        pd.to_datetime('2020-01-01 00:41:00'),\n        pd.to_datetime('2020-01-01 00:51:00'),\n    ],\n    'steps': [9.0, 30.0, 33.0, 0.0, 1.0, 9.0],\n    'heartrate': [90.0, 110.0, 80.0, 90.0, 0.0, 100.0]\n})\ntest_eq(df, ground_truth)"
  },
  {
    "objectID": "test/test_models.html",
    "href": "test/test_models.html",
    "title": "Testing for the models module",
    "section": "",
    "text": "import numpy as np\nfrom fastcore.test import *\nfrom circadian.models import *\nfrom scipy.signal import find_peaks\nfrom circadian.lights import LightSchedule\n\n\nDinamicalTrajectory\n\n# test DynamicalTrajectory's constructor\ntotal_timepoints = 1000\nvariables = 2\ntime = np.linspace(0, 10, total_timepoints)\nstates = np.zeros((total_timepoints, variables))\nstates[:, 0] = np.sin(time)\nstates[:, 1] = np.cos(time)\ntraj = DynamicalTrajectory(time, states)\n# test attributes\ntest_eq(traj.num_states, variables)\ntest_eq(traj.batch_size, 1)\ntest_eq(traj.time, time)\ntest_eq(traj.states, states)\n# test batch handling\nbatches = 5\nbatch_states = np.zeros((total_timepoints, variables, batches))\nbatch_states[:, 0, :] = np.sin(time)[:, None]\nbatch_states[:, 1, :] = np.cos(time)[:, None]\nbatch_traj = DynamicalTrajectory(time, batch_states)\ntest_eq(batch_traj.num_states, variables)\ntest_eq(batch_traj.batch_size, batches)\ntest_eq(batch_traj.time, time)\ntest_eq(batch_traj.states, batch_states)\n# test error handling\ntest_fail(lambda: DynamicalTrajectory(1, np.array([1, 2])), contains=\"time must be a numpy array\")\ntest_fail(lambda: DynamicalTrajectory(np.array([[1, 2], [1, 2]]), np.array([1, 2]) ), contains=\"time must be a 1D array\")\ntest_fail(lambda: DynamicalTrajectory(np.array([\"1\", \"2\"]), np.array([1, 2])), contains=\"time must be numeric\")\ntest_fail(lambda: DynamicalTrajectory(np.array([2, 1]), np.array([1, 2])), contains=\"time must be monotonically increasing\")\ntest_fail(lambda: DynamicalTrajectory(np.array([1, 2]), 1), contains=\"states must be a numpy array\")\ntest_fail(lambda: DynamicalTrajectory(np.array([1, 2]), np.array(1)), contains=\"states must have at least 1 dimension\")\ntest_fail(lambda: DynamicalTrajectory(np.array([1, 2]), np.zeros((1,1,1,1))), contains=\"states must have at most 3 dimensions\")\ntest_fail(lambda: DynamicalTrajectory(np.array([1, 2, 3]), np.array([1, 2])), contains=\"states must have the same length as time\")\ntest_fail(lambda: DynamicalTrajectory(np.array([1, 2]), np.array([1, 2, 3])), contains=\"states must have the same length as time\")\ntest_fail(lambda: DynamicalTrajectory(np.array([1, 2]), np.array([\"1\", \"2\"])), contains=\"states must be numeric\")\n\n\n# test DynamicalTrajectory's __call__\ntotal_timepoints = 1000\nvariables = 2\ntime = np.linspace(0, 10, total_timepoints)\nstates = np.zeros((total_timepoints, variables))\nstates[:, 0] = np.sin(time)\nstates[:, 1] = np.cos(time)\ntraj = DynamicalTrajectory(time, states)\ninterpolation_error = np.abs(np.sum(traj(5.0) - (np.sin(5.0), np.cos(5.0))))\ntest_eq(interpolation_error &lt; 1e-4, True)\n# handle batch\nbatches = 5\nbatch_states = np.zeros((total_timepoints, variables, batches))\nbatch_states[:, 0, :] = np.sin(time)[:, None]\nbatch_states[:, 1, :] = np.cos(time)[:, None]\nbatch_traj = DynamicalTrajectory(time, batch_states)\ninterpolation_error = np.abs(np.sum((batch_traj(0.5)[0] - np.sin(0.5)) + (batch_traj(0.5)[1] - np.cos(0.5))))\ntest_eq(interpolation_error &lt; 1e-4, True)\n# test error handling\ntest_fail(lambda: traj(\"1\"), contains=\"timepoint must be int or float\")\ntest_fail(lambda: traj(11), contains=\"timepoint must be within the time range\")\n\n\n# test DynamicalTrajectory's __getitem__\ntotal_timepoints = 1000\nvariables = 2\ntime = np.linspace(0, np.pi, total_timepoints)\nstates = np.zeros((total_timepoints, variables))\nstates[:, 0] = np.sin(time)\nstates[:, 1] = np.cos(time)\ntraj = DynamicalTrajectory(time, states)\ntest_eq(traj[0], (0.0, np.array([0.0, 1.0])))\nstates = traj[-1][1]\ndifference = np.abs(np.sum(states - (np.sin(np.pi), np.cos(np.pi))))\ntest_eq(difference &lt; 1e-4, True)\n# handle batch\nbatches = 5\nbatch_states = np.zeros((total_timepoints, variables, batches))\nbatch_states[:, 0, :] = np.sin(time)[:, None]\nbatch_states[:, 1, :] = np.cos(time)[:, None]\nbatch_traj = DynamicalTrajectory(time, batch_states)\ntest_eq(batch_traj[0][0], 0.0)\ntest_eq(np.all(batch_traj[0][1][0]==np.zeros(batches)), True)\ntest_eq(np.all(batch_traj[0][1][1]==np.ones(batches)), True)\n# test error handling\ntest_fail(lambda: traj[\"1\"], contains=\"idx must be int\")\ntest_fail(lambda: traj[-2], contains=\"idx must be within 0 and\")\ntest_fail(lambda: traj[1000], contains=\"idx must be within 0 and\")\n\n\n# test DynamicalTrajectory's __len__\ntotal_timepoints = 1000\nvariables = 2\ntime = np.linspace(0, np.pi, total_timepoints)\nstates = np.zeros((total_timepoints, variables))\nstates[:, 0] = np.sin(time)\nstates[:, 1] = np.cos(time)\ntraj = DynamicalTrajectory(time, states)\ntest_eq(len(traj), total_timepoints)\n# handle batch\nbatches = 5\nbatch_states = np.zeros((total_timepoints, variables, batches))\nbatch_states[:, 0, :] = np.sin(time)[:, None]\nbatch_states[:, 1, :] = np.cos(time)[:, None]\nbatch_traj = DynamicalTrajectory(time, batch_states)\ntest_eq(len(batch_traj), total_timepoints)\n\n\n# test DynamicalTrajectory's get_batch\ntotal_timepoints = 1000\nvariables = 2\ntime = np.linspace(0, np.pi, total_timepoints)\nstates = np.zeros((total_timepoints, variables))\nstates[:, 0] = np.sin(time)\nstates[:, 1] = np.cos(time)\ntraj = DynamicalTrajectory(time, states)\ntest_eq(traj.get_batch(0).batch_size, 1)\ntest_eq(traj.get_batch(0).num_states, variables)\ntest_eq(traj.get_batch(0).time, time)\ntest_eq(traj.get_batch(0).states, states)\ntest_eq(traj.get_batch(0).states.ndim, 2)\ntest_eq(traj.get_batch(0).states.shape, (total_timepoints, variables))\n# handle batch\nbatches = 5\nbatch_states = np.zeros((total_timepoints, variables, batches))\nbatch_states[:, 0, :] = np.sin(time)[:, None]\nbatch_states[:, 1, :] = np.cos(time)[:, None]\nbatch_traj = DynamicalTrajectory(time, batch_states)\ntest_eq(batch_traj.get_batch(0).batch_size, 1)\ntest_eq(batch_traj.get_batch(0).num_states, variables)\ntest_eq(batch_traj.get_batch(0).time, time)\ntest_eq(batch_traj.get_batch(0).states, batch_states[:, :, 0])\ntest_eq(batch_traj.get_batch(0).states.ndim, 2)\ntest_eq(batch_traj.get_batch(0).states.shape, (total_timepoints, variables))\ntest_eq(batch_traj.get_batch(4).batch_size, 1)\ntest_eq(batch_traj.get_batch(4).num_states, variables)\ntest_eq(batch_traj.get_batch(4).time, time)\ntest_eq(batch_traj.get_batch(4).states, batch_states[:, :, 0])\ntest_eq(batch_traj.get_batch(4).states.ndim, 2)\ntest_eq(batch_traj.get_batch(4).states.shape, (total_timepoints, variables))\ntest_eq(batch_traj.get_batch(-1).states, batch_traj.get_batch(4).states)\n# test error handling\ntest_fail(lambda: traj.get_batch(\"1\"), contains=\"batch_idx must be int\")\ntest_fail(lambda: traj.get_batch(5), contains=\"batch_idx must be within -1 and\")\ntest_fail(lambda: traj.get_batch(-2), contains=\"batch_idx must be within -1 and\")\n\n\n\nCircadianModel\n\nfrom circadian.models import _initial_condition_input_checking, _wake_input_checking\nfrom circadian.models import _model_input_checking, _light_input_checking\n\n\n# test input checking with NaNs\ninitial_condition_nan = np.array([np.nan, 0.0, 0.0])\ntest_fail(lambda: _initial_condition_input_checking(\n    initial_condition_nan,\n    3\n), contains=\"initial_condition must not contain NaNs\")\ninput_nan = np.array([[np.nan, 0.0, 0.0]])\ntest_fail(lambda: _model_input_checking(\n    input_nan,\n    3,\n    [1]\n))\nlight_nan = np.array([np.nan, 0.0, 0.0])\ntest_fail(lambda: _light_input_checking(light_nan), contains=\"light must not contain NaNs\")\nwake_nan = np.array([np.nan, 0.0, 0.0])\ntest_fail(lambda: _wake_input_checking(wake_nan), contains=\"wake must not contain NaNs\")\n\n\n# test CircadianModel's constructor\ndefault_params = {\"a\": 1, \"b\": 2}\nnum_states = 3\nnum_inputs = 2\ndefault_initial_condition = np.array([1, 2, 3])\nmodel = CircadianModel(default_params, num_states, num_inputs, default_initial_condition)\n# test attributes\ntest_eq(model._default_params, default_params)\ntest_eq(model._num_states, num_states)\ntest_eq(model._num_inputs, num_inputs)\ntest_eq(model._default_initial_condition, default_initial_condition)\ntest_eq(model.parameters, default_params)\ntest_eq(model.initial_condition, default_initial_condition)\ntest_eq(model.a, 1)\ntest_eq(model.b, 2)\ntest_eq(model.trajectory, None)\n# test error handling\ntest_fail(lambda: CircadianModel(1, num_states, num_inputs, default_initial_condition), contains=\"parameters must be a dictionary\")\ntest_fail(lambda: CircadianModel({}, num_states, num_inputs, default_initial_condition), contains=\"parameters must not be empty\")\ntest_fail(lambda: CircadianModel({1: 1, 2:2}, num_states, num_inputs, default_initial_condition), contains=\"keys of parameters must be strings\")\ntest_fail(lambda: CircadianModel({\"a\": \"1\", \"b\":2}, num_states, num_inputs, default_initial_condition), contains=\"values of parameters must be numeric\")\ntest_fail(lambda: CircadianModel(default_params, \"1\", num_inputs, default_initial_condition), contains=\"num_states must be an integer\")\ntest_fail(lambda: CircadianModel(default_params, -1, num_inputs, default_initial_condition), contains=\"num_states must be positive\")\ntest_fail(lambda: CircadianModel(default_params, num_states, \"1\", default_initial_condition), contains=\"num_inputs must be an integer\")\ntest_fail(lambda: CircadianModel(default_params, num_states, -1, default_initial_condition), contains=\"num_inputs must be positive\")\ntest_fail(lambda: CircadianModel(default_params, num_states, num_inputs, \"1\"), contains=\"initial_condition must be a numpy array\")\ntest_fail(lambda: CircadianModel(default_params, num_states, num_inputs, np.array([\"1\", \"2\", \"3\"])), contains=\"initial_condition must be numeric\")\ntest_fail(lambda: CircadianModel(default_params, num_states, num_inputs, np.array([1, 2, 3, 4])), contains=\"initial_condition must have length\")\n\n\n# test CircadianModel's step_rk4\ndefault_params = {\"a\": 1, \"b\": 2}\nnum_states = 3\nnum_inputs = 2\ndefault_initial_condition = np.array([1, 2, 3])\nmodel = CircadianModel(default_params, num_states, num_inputs, default_initial_condition)\nmodel.derv = lambda t, state, input: np.ones_like(state)\nt = 0.0\nlight_input = 1.0\ndt = 0.1\ntest_eq(np.all(model.step_rk4(t, default_initial_condition, light_input, dt) == np.array([1.1, 2.1, 3.1])), True)\n\n\n# test integrate\ndefault_params = {\"a\": 1, \"b\": 2}\nnum_states = 3\nnum_inputs = 2\ndefault_initial_condition = np.array([1, 2, 3])\nmodel = CircadianModel(default_params, num_states, num_inputs, default_initial_condition)\ntime = np.linspace(0, 10, 1000)\nlight_input = np.ones((len(time), num_inputs))\nmodel.derv = lambda t, state, input: np.ones_like(state)\nmodel.integrate(time, default_initial_condition, light_input)\ntest_eq(model.trajectory.num_states, num_states)\ntest_eq(model.trajectory.batch_size, 1)\ntest_eq(model.trajectory.time, time)\nstate_0_error = np.abs(np.sum(model.trajectory.states[:, 0] - time - 1))\nstate_1_error = np.abs(np.sum(model.trajectory.states[:, 1] - time - 2))\nstate_2_error = np.abs(np.sum(model.trajectory.states[:, 2] - time - 3))\ntest_eq(state_0_error &lt; 1e-10, True)\ntest_eq(state_1_error &lt; 1e-10, True)\ntest_eq(state_2_error &lt; 1e-10, True)\n# handle batches\nbatches = 5\nbatch_initial_conditions = np.zeros((num_states, batches))\nbatch_initial_conditions[:, 1] = 1\nbatch_initial_conditions[:, 2] = 2\nbatch_initial_conditions[:, 3] = 3\nbatch_initial_conditions[:, 4] = 4\nmodel.integrate(time, batch_initial_conditions, light_input)\nfor batch in range(batches):\n    batch_trajectory = model.trajectory.get_batch(batch)\n    test_eq(batch_trajectory.num_states, num_states)\n    test_eq(batch_trajectory.time, time)\n    state_0_error = np.abs(np.sum(batch_trajectory.states[:, 0] - time - batch))\n    state_1_error = np.abs(np.sum(batch_trajectory.states[:, 1] - time - batch))\n    state_2_error = np.abs(np.sum(batch_trajectory.states[:, 2] - time - batch))\n    test_eq(state_0_error &lt; 1e-10, True)\n    test_eq(state_1_error &lt; 1e-10, True)\n    test_eq(state_2_error &lt; 1e-10, True)\n# test error handling\ntest_fail(lambda: model.integrate(1, default_initial_condition, light_input), contains=\"time must be a numpy array\")\ntest_fail(lambda: model.integrate(np.array([[1, 2], [1, 2]]), default_initial_condition, light_input), contains=\"time must be a 1D array\")\ntest_fail(lambda: model.integrate(np.array([\"1\", \"2\"]), default_initial_condition, light_input), contains=\"time must be numeric\")\ntest_fail(lambda: model.integrate(np.array([2, 1]), default_initial_condition, light_input), contains=\"time must be monotonically increasing\")\ntest_fail(lambda: model.integrate(time, 1, light_input), contains=\"initial_condition must be a numpy array\")\ntest_fail(lambda: model.integrate(time, np.array([\"1\", \"2\", \"3\"]), light_input), contains=\"initial_condition must be numeric\")\ntest_fail(lambda: model.integrate(time, np.array([1, 2]), light_input), contains=\"initial_condition must have length\")\ntest_fail(lambda: model.integrate(time, np.array([1, 2]), light_input[:-3]), contains=\"input's first dimension must have length\")\ntest_fail(lambda: model.integrate(time, default_initial_condition, 1), contains=\"input must be a numpy array\")\ntest_fail(lambda: model.integrate(time, default_initial_condition, np.array([\"1\", \"2\"])), contains=\"input must be numeric\")\ntest_fail(lambda: model.integrate(time, default_initial_condition), contains=\"a model input must be provided via the input argument\")\n\n\n# test CircadianModel's __call__\ndefault_params = {\"a\": 1, \"b\": 2}\nnum_states = 3\nnum_inputs = 2\ndefault_initial_condition = np.array([1, 2, 3])\nmodel = CircadianModel(default_params, num_states, num_inputs, default_initial_condition)\ntime = np.linspace(0, 10, 1000)\nlight_input = np.ones((len(time), num_inputs))\nmodel.derv = lambda t, state, input: np.ones_like(state)\nmodel(time, default_initial_condition, light_input)\ntest_eq(model.trajectory.num_states, num_states)\ntest_eq(model.trajectory.batch_size, 1)\ntest_eq(model.trajectory.time, time)\nstate_0_error = np.abs(np.sum(model.trajectory.states[:, 0] - time - 1))\nstate_1_error = np.abs(np.sum(model.trajectory.states[:, 1] - time - 2))\nstate_2_error = np.abs(np.sum(model.trajectory.states[:, 2] - time - 3))\ntest_eq(state_0_error &lt; 1e-10, True)\ntest_eq(state_1_error &lt; 1e-10, True)\ntest_eq(state_2_error &lt; 1e-10, True)\n# handle batches\nbatches = 5\nbatch_initial_conditions = np.zeros((num_states, batches))\nbatch_initial_conditions[:, 1] = 1\nbatch_initial_conditions[:, 2] = 2\nbatch_initial_conditions[:, 3] = 3\nbatch_initial_conditions[:, 4] = 4\nmodel(time, batch_initial_conditions, light_input)\nfor batch in range(batches):\n    batch_trajectory = model.trajectory.get_batch(batch)\n    test_eq(batch_trajectory.num_states, num_states)\n    test_eq(batch_trajectory.time, time)\n    state_0_error = np.abs(np.sum(batch_trajectory.states[:, 0] - time - batch))\n    state_1_error = np.abs(np.sum(batch_trajectory.states[:, 1] - time - batch))\n    state_2_error = np.abs(np.sum(batch_trajectory.states[:, 2] - time - batch))\n    test_eq(state_0_error &lt; 1e-10, True)\n    test_eq(state_1_error &lt; 1e-10, True)\n    test_eq(state_2_error &lt; 1e-10, True)\n# test error handling\ntest_fail(lambda: model(1, default_initial_condition, light_input), contains=\"time must be a numpy array\")\ntest_fail(lambda: model(np.array([[1, 2], [1, 2]]), default_initial_condition, light_input), contains=\"time must be a 1D array\")\ntest_fail(lambda: model(np.array([\"1\", \"2\"]), default_initial_condition, light_input), contains=\"time must be numeric\")\ntest_fail(lambda: model(np.array([2, 1]), default_initial_condition, light_input), contains=\"time must be monotonically increasing\")\ntest_fail(lambda: model(time, 1, light_input), contains=\"initial_condition must be a numpy array\")\ntest_fail(lambda: model(time, np.array([\"1\", \"2\", \"3\"]), light_input), contains=\"initial_condition must be numeric\")\ntest_fail(lambda: model(time, np.array([1, 2]), light_input), contains=\"initial_condition must have length\")\ntest_fail(lambda: model(time, default_initial_condition, 1), contains=\"input must be a numpy array\")\ntest_fail(lambda: model(time, default_initial_condition, light_input[:-3]), contains=\"input's first dimension must have length\")\ntest_fail(lambda: model(time, default_initial_condition, np.array([\"1\", \"2\"])), contains=\"input must be numeric\")\ntest_fail(lambda: model(time, default_initial_condition), contains=\"a model input must be provided via the input argument\")\n\n\n# test CircadianModel's get_parameters_array\ndefault_params = {\"a\": 1, \"b\": 2}\nnum_states = 3\nnum_inputs = 1\ndefault_initial_conditions = np.array([1, 2, 3])\nmodel = CircadianModel(default_params, num_states, num_inputs, default_initial_conditions)\ntest_eq(model.get_parameters_array(), np.array([1, 2]))\n\n\n# test CircadianModel's equilibrate\ndefault_params = {\"a\": 1, \"b\": 2}\nnum_states = 3\nnum_inputs = 2\ndefault_initial_condition = np.array([1, 2, 3])\nmodel = CircadianModel(default_params, num_states, num_inputs, default_initial_condition)\nmodel.derv = lambda t, state, input: np.ones_like(state)\nmodel.dlmos = lambda: np.array([1, 2, 3])\ntime = np.linspace(0, 10, 1000)\nlight_input = np.ones((len(time), num_inputs))\nmodel(time, default_initial_condition, light_input)\nloops = 2\nnew_initial_condition = model.equilibrate(time, light_input, loops)\ntest_eq(new_initial_condition.shape, default_initial_condition.shape)\nground_truth = default_initial_condition + loops * time[-1]\ntest_eq(np.all(np.isclose(ground_truth, new_initial_condition)), True)\n# test error handling\ntest_fail(lambda: model.equilibrate(1, light_input, loops), contains=\"time must be a numpy array\")\ntest_fail(lambda: model.equilibrate(np.array([[1, 2], [1, 2]]), light_input, loops), contains=\"time must be a 1D array\")\ntest_fail(lambda: model.equilibrate(np.array([\"1\", \"2\"]), light_input, loops), contains=\"time must be numeric\")\ntest_fail(lambda: model.equilibrate(np.array([2, 1]), light_input, loops), contains=\"time must be monotonically increasing\")\ntest_fail(lambda: model.equilibrate(time, 1, loops), contains=\"input must be a numpy array\")\ntest_fail(lambda: model.equilibrate(time, np.array([[1, 2], [1, 2]]), loops), contains=\"input's first dimension must have length\")\ntest_fail(lambda: model.equilibrate(time, np.array([\"1\", \"2\"]), loops), contains=\"input must be numeric\")\ntest_fail(lambda: model.equilibrate(time, light_input, \"1\"), contains=\"num_loops must be an integer\")\ntest_fail(lambda: model.equilibrate(time, light_input, -1), contains=\"num_loops must be positive\")\n# test equilibration warning\nmodel.dlmos = lambda: np.array(np.random.rand(3))\ntest_warns(lambda: model.equilibrate(time, light_input, loops))\n\n\n\nForger99\n\n# test Forger99's constructor\nmodel = Forger99()\n# test attributes\ntrue_default_params = {\n    'taux': 24.2, 'mu': 0.23, 'G': 33.75,\n    'alpha_0': 0.05, 'beta': 0.0075, 'p': 0.50,\n    'I0': 9500.0, 'k': 0.55, 'cbt_to_dlmo': 7.0}\ntest_eq(model._default_params, true_default_params)\ntrue_initial_condition = np.array([-0.0843259, -1.09607546, 0.45584306])\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, true_default_params)\ntest_eq(model._num_states, 3)\ntest_eq(model._num_inputs, 1)\nfor key, value in true_default_params.items():\n    test_eq(getattr(model, key), value)\n# test initialization with custom parameters\ncustom_params = {\n    'taux': 1.0, 'mu': 2.0, 'G': 3.0,\n    'alpha_0': 4.0, 'beta': 5.0, 'p': 6.0,\n    'I0': 7.0, 'k': 8.0, 'cbt_to_dlmo': 9.0}\nmodel = Forger99(custom_params)\n# test attributes\ntest_eq(model._default_params, true_default_params)\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, custom_params)\ntest_eq(model._num_states, 3)\ntest_eq(model._num_inputs, 1)\nfor key, value in custom_params.items():\n    test_eq(getattr(model, key), value)\n\n\n# test Forger99's integrate input handling\nmodel = Forger99()\ntime = np.array([0, 1, 2])\nlight_input = np.ones(len(time))\ntest_fail(lambda: model.integrate(time, input=\"1\"), contains=\"light must be a numpy array\")\ntest_fail(lambda: model.integrate(time, input=np.ones((1,1))), contains=\"light must be a 1D\")\ntest_fail(lambda: model.integrate(time, input=np.array([\"1\", \"2\"])), contains=\"light must be numeric\")\ntest_fail(lambda: model.integrate(time, input=-light_input), contains=\"light intensity must be nonnegative\")\n\n\n# test Forger99's derv\nmodel = Forger99()\n# single batch\nt = 0.0\nstate = np.array([-0.3, -1.13, 0.0])\nlight = 1.0\nderv_error = np.abs(np.sum(model.derv(t, state, light) - np.array([-0.28846216, 0.1267787, 0.03077935])))\ntest_eq(derv_error &lt; 1e-8, True)\n# multiple batches\nbatches = 5\nbatch_states = np.zeros((3, batches))\nfor batch in range(batches):\n    batch_states[:, batch] = state\nbatch_derv = model.derv(t, batch_states, light)\nfor batch in range(batches):\n    derv_error = np.abs(np.sum(batch_derv[:, batch] - np.array([-0.28846216, 0.1267787, 0.03077935])))\n    test_eq(derv_error &lt; 1e-8, True)\n\n\n# test Forger99's phase\nmodel = Forger99()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nmodel(time, input=light)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(time=t)\ntrue_phase = np.angle(model.trajectory.states[:,0] + complex(0,1)*(-1.0 * model.trajectory.states[:,1]))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(trajectory, t)\ntrue_phase = np.angle(model.trajectory.states[:,0] + complex(0,1)*(-1.0 * model.trajectory.states[:,1]))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test calculation for all trajectories\nphase = model.phase()\ntest_eq(np.all(np.isclose(phase, true_phase)), True)\n# test error handling\ntest_fail(lambda: model.phase(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.phase(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Forger99's amplitude\nmodel = Forger99()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nmodel(time, input=light)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(time=t)\ntrue_amplitude = np.sqrt(model.trajectory.states[:,0] ** 2 + model.trajectory.states[:,1] ** 2)\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(trajectory, t)\ntrue_amplitude = np.sqrt(model.trajectory.states[:,0] ** 2 + model.trajectory.states[:,1] ** 2)\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test calculation for all trajectories\namplitude = model.amplitude()\ntest_eq(np.all(np.isclose(amplitude, true_amplitude)), True)\n# test error handling\ntest_fail(lambda: model.amplitude(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.amplitude(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Forger99's cbt\nmodel = Forger99()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ntroughs = time[cbt_min_idxs]\ntest_eq(np.all(np.isclose(model.cbt(), troughs)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ntroughs = time[cbt_min_idxs]\ntest_eq(np.all(np.isclose(model.cbt(trajectory), troughs)), True)\n# test error handling\ntest_fail(lambda: model.cbt(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n# test Forger99's cbt under light blips\nmodel = Forger99()\ndt = 0.01 # hours\ntime = np.arange(0, 96, dt)\nlight = LightSchedule.Regular()(time)\n\nnp.random.seed(0)\nblip_idxs = np.arange(0, len(time), int(2 / dt))\nfor blip in blip_idxs:\n    if np.random.rand() &gt; 0.85:\n        for i in range(20):\n            light[blip + i] = light[blip] + 750\n\ntrajectory = model(time, input=light)\ncbt = model.cbt()\ndiff_cbt = np.diff(cbt)\ntest_eq(np.all(diff_cbt &gt; 13.0), True)\n\n\n# test Forger99's dlmos\nmodel = Forger99()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ndlmos = time[cbt_min_idxs] - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(), dlmos)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ndlmos = time[cbt_min_idxs] - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(trajectory), dlmos)), True)\n# test error handling\ntest_fail(lambda: model.dlmos(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n# test that Forger99 can be entrained to a regular 24 hour light schedule for different initial conditions - Scientific test\ndays = 80\ndt = 0.5\ntime = np.arange(0, 24*days, dt)\nregular_schedule = LightSchedule.Regular()\nlight_values = regular_schedule(time)\n# explore a broad space of initial conditions\namplitude_ic = np.linspace(1e-3, 1.0, 20)\nphase_ic = np.linspace(-np.pi, np.pi, 20)\n# convert amplitude and phase to x and xc\nic_stack = np.dstack(np.meshgrid(amplitude_ic, phase_ic)).reshape(-1, 2)\nic_stack = np.hstack((ic_stack, np.zeros((ic_stack.shape[0], 1))))\nic_x = np.sqrt(ic_stack[:, 0]) * np.cos(ic_stack[:, 1])\nic_xc = np.sqrt(ic_stack[:, 0]) * np.sin(ic_stack[:, 1])\ninitial_conditions = np.hstack((ic_x.reshape(-1, 1), ic_xc.reshape(-1, 1), np.zeros((ic_x.shape[0], 1))))\n# transpose initial conditions\ninitial_conditions = initial_conditions.T\n# simulate\nmodel = Forger99()\nresult = model(time, initial_conditions, light_values)\n# compare last ten days\nt_comparison_idx = int(24 * 70 / dt)\nreference_x = result.states[t_comparison_idx:, 0, 0]\nreference_xc = result.states[t_comparison_idx:, 1, 0]\ndiff_x = result.states[t_comparison_idx:, 0, :].T - reference_x\ndiff_xc = result.states[t_comparison_idx:, 1, :].T - reference_xc\ntest_eq(np.all(np.isclose(diff_x, 0.0, atol=1e-2)), True)\ntest_eq(np.all(np.isclose(diff_xc, 0.0, atol=1e-2)), True)\n\n\n\nHannay19\n\n# test Hannay19's constructor\nmodel = Hannay19()\n# test attributes\ntrue_default_params = {\n    'tau': 23.84, 'K': 0.06358, 'gamma': 0.024,\n    'Beta1': -0.09318, 'A1': 0.3855, 'A2': 0.1977,\n    'BetaL1': -0.0026, 'BetaL2': -0.957756, 'sigma': 0.0400692,\n    'G': 33.75, 'alpha_0': 0.05, 'delta': 0.0075, 'p': 1.5, 'I0': 9325.0,\n    'cbt_to_dlmo': 7.0}\ntest_eq(model._default_params, true_default_params)\ntrue_initial_condition = np.array([0.82041911, 1.71383697, 0.52318122])\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, true_default_params)\ntest_eq(model._num_states, 3)\ntest_eq(model._num_inputs, 1)\nfor key, value in true_default_params.items():\n    test_eq(getattr(model, key), value)\n# test initialization with custom parameters\ncustom_params = {\n    'tau': 1.0, 'K': 2.0, 'gamma': 3.0,\n    'Beta1': 4.0, 'A1': 5.0, 'A2': 6.0,\n    'BetaL1': 7.0, 'BetaL2': 8.0, 'sigma': 9.0,\n    'G': 10.0, 'alpha_0': 11.0, 'delta': 12.0, 'p': 13.0, 'I0': 14.0,\n    'cbt_to_dlmo': 15.0}\nmodel = Hannay19(custom_params)\n# test attributes\ntest_eq(model._default_params, true_default_params)\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, custom_params)\ntest_eq(model._num_states, 3)\ntest_eq(model._num_inputs, 1)\nfor key, value in custom_params.items():\n    test_eq(getattr(model, key), value)\n\n\n# test Hannay19's integrate input handling\nmodel = Hannay19()\ntime = np.array([0, 1, 2])\nlight_input = np.ones(len(time))\ntest_fail(lambda: model.integrate(time, input=\"1\"), contains=\"light must be a numpy array\")\ntest_fail(lambda: model.integrate(time, input=np.ones((1,1))), contains=\"light must be a 1D\")\ntest_fail(lambda: model.integrate(time, input=np.array([\"1\", \"2\"])), contains=\"light must be numeric\")\ntest_fail(lambda: model.integrate(time, input=-light_input), contains=\"light intensity must be nonnegative\")\n\n\n# test Hannay19's derv\nmodel = Hannay19()\n# single batch\nt = 0.0\nstate = np.array([0.1, 0.1, 0.1])\nlight = 1.0\nderv_error = np.abs(np.sum(model.derv(t, state, light) - np.array([0.0007973, 0.26058529, -0.04471049])))\ntest_eq(derv_error &lt; 1e-8, True)\n# multiple batches\nbatches = 5\nbatch_states = np.zeros((3, batches))\nfor batch in range(batches):\n    batch_states[:, batch] = state\nbatch_derv = model.derv(t, batch_states, light)\nfor batch in range(batches):\n    derv_error = np.abs(np.sum(batch_derv[:, batch] - np.array([0.0007973, 0.26058529, -0.04471049])))\n    test_eq(derv_error &lt; 1e-8, True)\n\n\n# test Hannay19's phase\nmodel = Hannay19()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nmodel(time, input=light)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(time=t)\nx_vals = np.cos(model.trajectory.states[:,1])\ny_vals = np.sin(model.trajectory.states[:,1])\ntrue_phase = np.angle(x_vals + complex(0,1)*(y_vals))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(trajectory, t)\nx_vals = np.cos(model.trajectory.states[:,1])\ny_vals = np.sin(model.trajectory.states[:,1])\ntrue_phase = np.angle(x_vals + complex(0,1)*(y_vals))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test calculation for all trajectories\nphase = model.phase()\ntest_eq(np.all(np.isclose(phase, true_phase)), True)\n# test error handling\ntest_fail(lambda: model.phase(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.phase(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Hannay19's amplitude\nmodel = Hannay19()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nmodel(time, input=light)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(time=t)\ntrue_amplitude = model.trajectory.states[:,0]\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(trajectory, t)\ntrue_amplitude = model.trajectory.states[:,0]\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test calculation for all trajectories\namplitude = model.amplitude()\ntest_eq(np.all(np.isclose(amplitude, true_amplitude)), True)\n# test error handling\ntest_fail(lambda: model.amplitude(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.amplitude(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Hannay19's cbt\nmodel = Hannay19()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*np.cos(trajectory.states[:,1]))[0]\ntroughs = time[cbt_min_idxs]\ntest_eq(np.all(np.isclose(model.cbt(), troughs)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*np.cos(trajectory.states[:,1]))[0]\ntroughs = time[cbt_min_idxs]\ntest_eq(np.all(np.isclose(model.cbt(trajectory), troughs)), True)\n# test error handling\ntest_fail(lambda: model.cbt(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n# test Hannay19's cbt under light blips\nmodel = Hannay19()\ndt = 0.01 # hours\ntime = np.arange(0, 96, dt)\nlight = LightSchedule.Regular()(time)\n\nnp.random.seed(0)\nblip_idxs = np.arange(0, len(time), int(2 / dt))\nfor blip in blip_idxs:\n    if np.random.rand() &gt; 0.85:\n        for i in range(20):\n            light[blip + i] = light[blip] + 750\n\ntrajectory = model(time, input=light)\ncbt = model.cbt()\ndiff_cbt = np.diff(cbt)\ntest_eq(np.all(diff_cbt &gt; 13.0), True)\n\n\n# test Hannay19's dlmos\nmodel = Hannay19()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*np.cos(trajectory.states[:,1]))[0]\ndlmos = time[cbt_min_idxs] - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(), dlmos)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*np.cos(trajectory.states[:,1]))[0]\ndlmos = time[cbt_min_idxs] - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(trajectory), dlmos)), True)\n# test error handling\ntest_fail(lambda: model.dlmos(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n# test that Hannay19 can be entrained to a regular 24 hour light schedule for different initial conditions - Scientific test\ndays = 30\ndt = 0.1\ntime = np.arange(0, 24*days, dt)\nregular_schedule = LightSchedule.Regular()\nlight_values = regular_schedule(time)\n# explore a broad space of initial conditions\namplitude_ic = np.linspace(1e-2, 1.0, 20)\nphase_ic = np.linspace(-np.pi, np.pi, 20)\ninitial_conditions = np.dstack(np.meshgrid(amplitude_ic, phase_ic)).reshape(-1, 2)\ninitial_conditions = np.hstack((initial_conditions, np.zeros((initial_conditions.shape[0], 1))))\n# transpose initial conditions\ninitial_conditions = initial_conditions.T\n# simulate\nmodel = Hannay19()\nresult = model(time, initial_conditions, light_values)\n# compare last 5 days for amplitude\nt_comparison_idx = int(24 * (days - 5) / dt)\nreference_R = result.states[t_comparison_idx:100:, 0, 0]\ndiff_R = result.states[t_comparison_idx:100:, 0, :].T - reference_R\ntest_eq(np.all(np.isclose(diff_R, 0.0, atol=1e-2)), True)\n# compare last 5 days for phase\ndiff_Psi = []\nfor t in time[t_comparison_idx:100:]:\n    phases = model.phase(t)\n    reference_phase = phases[0]\n    diff_Psi.append(phases - reference_phase)\ntest_eq(np.all(np.isclose(diff_Psi, 0.0, atol=1e-2)), True)\n\n\n\nHannay19TP\n\n# test Hannay19TP's constructor\nmodel = Hannay19TP()\n# test attributes\ntrue_default_params = {\n    'tauV': 24.25, 'tauD': 24.0, 'Kvv': 0.05,\n    'Kdd': 0.04, 'Kvd': 0.05, 'Kdv': 0.01,\n    'gamma': 0.024, 'A1': 0.440068, 'A2': 0.159136,\n    'BetaL': 0.06452, 'BetaL2': -1.38935, 'sigma': 0.0477375,\n    'G': 33.75, 'alpha_0': 0.05, 'delta': 0.0075, 'p': 1.5,\n    'I0': 9325.0, 'cbt_to_dlmo': 7.0}\ntest_eq(model._default_params, true_default_params)\ntrue_initial_condition = np.array([0.82423745, 0.82304996, 1.75233424, 1.863457, 0.52318122])\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, true_default_params)\ntest_eq(model._num_states, 5)\ntest_eq(model._num_inputs, 1)\nfor key, value in true_default_params.items():\n    test_eq(getattr(model, key), value)\n# test initialization with custom parameters\ncustom_params = {\n    'tauV': 1.0, 'tauD': 2.0, 'Kvv': 3.0,\n    'Kdd': 4.0, 'Kvd': 5.0, 'Kdv': 6.0,\n    'gamma': 7.0, 'A1': 8.0, 'A2': 9.0,\n    'BetaL': 10.0, 'BetaL2': 11.0, 'sigma': 12.0,\n    'G': 13.0, 'alpha_0': 14.0, 'delta': 15.0, 'p': 16.0,\n    'I0': 17.0, 'cbt_to_dlmo': 18.0}\nmodel = Hannay19TP(custom_params)\n# test attributes\ntest_eq(model._default_params, true_default_params)\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, custom_params)\ntest_eq(model._num_states, 5)\ntest_eq(model._num_inputs, 1)\nfor key, value in custom_params.items():\n    test_eq(getattr(model, key), value)\n\n\n# test Hannay19TP's integrate input handling\nmodel = Hannay19TP()\ntime = np.array([0, 1, 2])\nlight_input = np.ones(len(time))\ntest_fail(lambda: model.integrate(time, input=\"1\"), contains=\"light must be a numpy array\")\ntest_fail(lambda: model.integrate(time, input=np.ones((1,1))), contains=\"light must be a 1D\")\ntest_fail(lambda: model.integrate(time, input=np.array([\"1\", \"2\"])), contains=\"light must be numeric\")\ntest_fail(lambda: model.integrate(time, input=-light_input), contains=\"light intensity must be nonnegative\")\n\n\n# test Hannay19TP's derv\nmodel = Hannay19TP()\n# single batch\nt = 0.0\nstate = np.array([0.1, 0.1, 0.1, 0.1, 0.1])\nlight = 1.0\nderv_error = np.abs(np.sum(model.derv(t, state, light) - np.array([0.00063553,  0.00209955,  0.25906153,  0.26179939, -0.04471049])))\ntest_eq(derv_error &lt; 1e-8, True)\n# multiple batches\nbatches = 5\nbatch_states = np.zeros((5, batches))\nfor batch in range(batches):\n    batch_states[:, batch] = state\nbatch_derv = model.derv(t, batch_states, light)\nfor batch in range(batches):\n    derv_error = np.abs(np.sum(batch_derv[:, batch] - np.array([0.00063553,  0.00209955,  0.25906153,  0.26179939, -0.04471049])))\n    test_eq(derv_error &lt; 1e-8, True)\n\n\n# test Hannay19TP's phase\nmodel = Hannay19TP()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nmodel(time, input=light)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(time=t)\nx_vals = np.cos(model.trajectory.states[:,2])\ny_vals = np.sin(model.trajectory.states[:,2])\ntrue_phase = np.angle(x_vals + complex(0,1)*(y_vals))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(trajectory, t)\nx_vals = np.cos(model.trajectory.states[:,2])\ny_vals = np.sin(model.trajectory.states[:,2])\ntrue_phase = np.angle(x_vals + complex(0,1)*(y_vals))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test calculation for all trajectories\nphase = model.phase()\ntest_eq(np.all(np.isclose(phase, true_phase)), True)\n# test error handling\ntest_fail(lambda: model.phase(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.phase(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Hannay19TP's amplitude\nmodel = Hannay19TP()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nmodel(time, input=light)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(time=t)\ntrue_amplitude = model.trajectory.states[:,0]\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(trajectory, t)\ntrue_amplitude = model.trajectory.states[:,0]\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test calculation for all trajectories\namplitude = model.amplitude()\ntest_eq(np.all(np.isclose(amplitude, true_amplitude)), True)\n# test error handling\ntest_fail(lambda: model.amplitude(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.amplitude(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Hannay19TP's cbt\nmodel = Hannay19TP()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*np.cos(trajectory.states[:,2]))[0]\ntroughs = time[cbt_min_idxs]\ntest_eq(np.all(np.isclose(model.cbt(), troughs)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*np.cos(trajectory.states[:,2]))[0]\ntroughs = time[cbt_min_idxs]\ntest_eq(np.all(np.isclose(model.cbt(trajectory), troughs)), True)\n# test error handling\ntest_fail(lambda: model.cbt(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n# test Hannay19TP's cbt under light blips\nmodel = Hannay19TP()\ndt = 0.01 # hours\ntime = np.arange(0, 96, dt)\nlight = LightSchedule.Regular()(time)\n\nnp.random.seed(0)\nblip_idxs = np.arange(0, len(time), int(2 / dt))\nfor blip in blip_idxs:\n    if np.random.rand() &gt; 0.85:\n        for i in range(20):\n            light[blip + i] = light[blip] + 750\n\ntrajectory = model(time, input=light)\ncbt = model.cbt()\ndiff_cbt = np.diff(cbt)\ntest_eq(np.all(diff_cbt &gt; 13.0), True)\n\n\n# test Hannay19TP's dlmos\nmodel = Hannay19TP()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*np.cos(trajectory.states[:,2]))[0]\ndlmos = time[cbt_min_idxs] - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(), dlmos)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*np.cos(trajectory.states[:,2]))[0]\ndlmos = time[cbt_min_idxs] - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(trajectory), dlmos)), True)\n# test error handling\ntest_fail(lambda: model.dlmos(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n\nJewett99\n\n# test Jewett99's constructor\nmodel = Jewett99()\n# test attributes\ntrue_default_params = {\n    'taux': 24.2, 'mu': 0.13, 'G': 19.875,\n    'beta': 0.013, 'k': 0.55, 'q': 1.0/3,\n    'I0': 9500, 'p': 0.6, 'alpha_0': 0.16,\n    'phi_ref': 0.8, 'cbt_to_dlmo': 7.0}\ntest_eq(model._default_params, true_default_params)\ntrue_initial_condition = np.array([-0.10097101, -1.21985662, 0.50529415])\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, true_default_params)\ntest_eq(model._num_states, 3)\ntest_eq(model._num_inputs, 1)\nfor key, value in true_default_params.items():\n    test_eq(getattr(model, key), value)\n# test initialization with custom parameters\ncustom_params = {\n    'taux': 1.0, 'mu': 2.0, 'G': 3.0,\n    'beta': 4.0, 'k': 5.0, 'q': 6.0,\n    'I0': 7.0, 'p': 8.0, 'alpha_0': 9.0,\n    'phi_ref': 10.0, 'cbt_to_dlmo': 11.0}\n\nmodel = Jewett99(custom_params)\n# test attributes\ntest_eq(model._default_params, true_default_params)\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, custom_params)\ntest_eq(model._num_states, 3)\ntest_eq(model._num_inputs, 1)\nfor key, value in custom_params.items():\n    test_eq(getattr(model, key), value)\n\n\n# test Jewett99's integrate input handling\nmodel = Jewett99()\ntime = np.array([0, 1, 2])\nlight_input = np.ones(len(time))\ntest_fail(lambda: model.integrate(time, input=\"1\"), contains=\"light must be a numpy array\")\ntest_fail(lambda: model.integrate(time, input=np.ones((1,1))), contains=\"light must be a 1D\")\ntest_fail(lambda: model.integrate(time, input=np.array([\"1\", \"2\"])), contains=\"light must be numeric\")\ntest_fail(lambda: model.integrate(time, input=-light_input), contains=\"light intensity must be nonnegative\")\n\n\n# test Jewett99's phase\nmodel = Jewett99()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nmodel(time, input=light)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(time=t)\ntrue_phase = np.angle(model.trajectory.states[:,0] + complex(0,1)*(-1.0 * model.trajectory.states[:,1]))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(trajectory, t)\ntrue_phase = np.angle(model.trajectory.states[:,0] + complex(0,1)*(-1.0 * model.trajectory.states[:,1]))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test calculation for all trajectories\nphase = model.phase()\ntest_eq(np.all(np.isclose(phase, true_phase)), True)\n# test error handling\ntest_fail(lambda: model.phase(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.phase(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Jewett99's amplitude\nmodel = Jewett99()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nmodel(time, input=light)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(time=t)\ntrue_amplitude = np.sqrt(model.trajectory.states[:,0] ** 2 + model.trajectory.states[:,1] ** 2)\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(trajectory, t)\ntrue_amplitude = np.sqrt(model.trajectory.states[:,0] ** 2 + model.trajectory.states[:,1] ** 2)\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test calculation for all trajectories\namplitude = model.amplitude()\ntest_eq(np.all(np.isclose(amplitude, true_amplitude)), True)\n# test error handling\ntest_fail(lambda: model.amplitude(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.amplitude(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Jewett99's cbt\nmodel = Jewett99()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ntroughs = time[cbt_min_idxs] + model.phi_ref\ntest_eq(np.all(np.isclose(model.cbt(), troughs)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ntroughs = time[cbt_min_idxs] + model.phi_ref\ntest_eq(np.all(np.isclose(model.cbt(trajectory), troughs)), True)\n# test error handling\ntest_fail(lambda: model.cbt(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n# test Jewett99's cbt under light blips\nmodel = Jewett99()\ndt = 0.01 # hours\ntime = np.arange(0, 96, dt)\nlight = LightSchedule.Regular()(time)\n\nnp.random.seed(0)\nblip_idxs = np.arange(0, len(time), int(2 / dt))\nfor blip in blip_idxs:\n    if np.random.rand() &gt; 0.85:\n        for i in range(20):\n            light[blip + i] = light[blip] + 750\n\ntrajectory = model(time, input=light)\ncbt = model.cbt()\ndiff_cbt = np.diff(cbt)\ntest_eq(np.all(diff_cbt &gt; 13.0), True)\n\n\n# test Jewett99's dlmos\nmodel = Jewett99()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ndlmos = time[cbt_min_idxs] + model.phi_ref - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(), dlmos)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ndlmos = time[cbt_min_idxs] + model.phi_ref - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(trajectory), dlmos)), True)\n# test error handling\ntest_fail(lambda: model.dlmos(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n# test that Jewett99 can be entrained to a regular 24 hour light schedule for different initial conditions - Scientific test\ndays = 80\ndt = 0.5\ntime = np.arange(0, 24*days, dt)\nregular_schedule = LightSchedule.Regular()\nlight_values = regular_schedule(time)\n# explore a broad space of initial conditions\namplitude_ic = np.linspace(1e-3, 1.0, 20)\nphase_ic = np.linspace(-np.pi, np.pi, 20)\n# convert amplitude and phase to x and xc\nic_stack = np.dstack(np.meshgrid(amplitude_ic, phase_ic)).reshape(-1, 2)\nic_stack = np.hstack((ic_stack, np.zeros((ic_stack.shape[0], 1))))\nic_x = np.sqrt(ic_stack[:, 0]) * np.cos(ic_stack[:, 1])\nic_xc = np.sqrt(ic_stack[:, 0]) * np.sin(ic_stack[:, 1])\ninitial_conditions = np.hstack((ic_x.reshape(-1, 1), ic_xc.reshape(-1, 1), np.zeros((ic_x.shape[0], 1))))\n# transpose initial conditions\ninitial_conditions = initial_conditions.T\n# simulate\nmodel = Jewett99()\nresult = model(time, initial_conditions, light_values)\n# compare last ten days\nt_comparison_idx = int(24 * 70 / dt)\nreference_x = result.states[t_comparison_idx:, 0, 0]\nreference_xc = result.states[t_comparison_idx:, 1, 0]\ndiff_x = result.states[t_comparison_idx:, 0, :].T - reference_x\ndiff_xc = result.states[t_comparison_idx:, 1, :].T - reference_xc\ntest_eq(np.all(np.isclose(diff_x, 0.0, atol=1e-2)), True)\ntest_eq(np.all(np.isclose(diff_xc, 0.0, atol=1e-2)), True)\n\n\n\nHilaire07\n\n# test Hilaire07's constructor\nmodel = Hilaire07()\n# test attributes\ntrue_default_params = {\n    'taux': 24.2, 'G': 37.0, 'k': 0.55, 'mu': 0.13, 'beta': 0.007, \n    'q': 1.0/3.0, 'rho': 0.032, 'I0': 9500.0, 'p': 0.5, 'a0': 0.1, \n    'phi_xcx': -2.98, 'phi_ref': 0.97, 'cbt_to_dlmo': 7.0,\n    }\ntest_eq(model._default_params, true_default_params)\ntrue_initial_condition = np.array([-0.0480751, -1.22504441, 0.51854818])\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, true_default_params)\ntest_eq(model._num_states, 3)\ntest_eq(model._num_inputs, 2)\nfor key, value in true_default_params.items():\n    test_eq(getattr(model, key), value)\n# test initialization with custom parameters\ncustom_params = {\n    'taux': 1.0, 'mu': 2.0, 'G': 3.0,\n    'beta': 4.0, 'k': 5.0, 'q': 6.0,\n    'I0': 7.0, 'p': 8.0, 'alpha_0': 9.0,\n    'phi_ref': 10.0, 'cbt_to_dlmo': 11.0}\nmodel = Hilaire07(custom_params)\n# test attributes\ntest_eq(model._default_params, true_default_params)\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, custom_params)\ntest_eq(model._num_states, 3)\ntest_eq(model._num_inputs, 2)\nfor key, value in custom_params.items():\n    test_eq(getattr(model, key), value)\n\n\n# test Hilaire07's derv\nmodel = Hilaire07()\n# single batch\nt = 0.0\nstate = np.array([0.1, 0.1, 0.1])\nlight = 1.0\nwake = 0.0\ninput = np.array([light, wake])\nderv_error = np.abs(np.sum(model.derv(t, state, input) - np.array([0.02610988, -0.0258909, -0.04145146])))\ntest_eq(derv_error &lt; 1e-8, True)\n# multiple batches\nbatches = 5\nbatch_states = np.zeros((3, batches))\nfor batch in range(batches):\n    batch_states[:, batch] = state\nbatch_derv = model.derv(t, batch_states, input)\nfor batch in range(batches):\n    derv_error = np.abs(np.sum(batch_derv[:, batch] - np.array([0.02610988, -0.0258909, -0.04145146])))\n    test_eq(derv_error &lt; 1e-8, True)\n\n\n# test Hilaire07's phase\nmodel = Hilaire07()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nwake = np.zeros_like(time)\ninput = np.stack((light, wake), axis=1)\nmodel(time, input=input)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(time=t)\ntrue_phase = np.angle(model.trajectory.states[:,0] + complex(0,1)*(-1.0 * model.trajectory.states[:,1]))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\nwake = np.zeros_like(time)\nwake[light &gt; 0] = 0.0\nwake[light == 0] = 1.0\ninput = np.stack((light, wake), axis=1)\ntrajectory = model(time, input=input)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(trajectory, t)\ntrue_phase = np.angle(model.trajectory.states[:,0] + complex(0,1)*(-1.0 * model.trajectory.states[:,1]))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test calculation for all trajectories\nphase = model.phase()\ntest_eq(np.all(np.isclose(phase, true_phase)), True)\n# test error handling\ntest_fail(lambda: model.phase(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.phase(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Hilaire07's amplitude\nmodel = Hilaire07()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nwake = np.zeros_like(time)\ninput = np.stack((light, wake), axis=1)\nmodel(time, input=input)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(time=t)\ntrue_amplitude = np.sqrt(model.trajectory.states[:,0] ** 2 + model.trajectory.states[:,1] ** 2)\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\nwake = np.zeros_like(time)\nwake[light &gt; 0] = 0.0\nwake[light == 0] = 1.0\ninput = np.stack((light, wake), axis=1)\ntrajectory = model(time, input=input)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(trajectory, t)\ntrue_amplitude = np.sqrt(model.trajectory.states[:,0] ** 2 + model.trajectory.states[:,1] ** 2)\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test calculation for all trajectories\namplitude = model.amplitude()\ntest_eq(np.all(np.isclose(amplitude, true_amplitude)), True)\n# test error handling\ntest_fail(lambda: model.amplitude(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.amplitude(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Hilaire07's cbt\nmodel = Hilaire07()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\nwake = np.zeros_like(time)\ninput = np.stack((light, wake), axis=1)\ntrajectory = model(time, input=input)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ntroughs = time[cbt_min_idxs] + model.phi_ref\ntest_eq(np.all(np.isclose(model.cbt(), troughs)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\nwake = np.zeros_like(time)\nwake[light &gt; 0] = 0.0\nwake[light == 0] = 1.0\ninput = np.stack((light, wake), axis=1)\ntrajectory = model(time, input=input)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ntroughs = time[cbt_min_idxs] + model.phi_ref\ntest_eq(np.all(np.isclose(model.cbt(trajectory), troughs)), True)\n# test error handling\ntest_fail(lambda: model.cbt(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n# test Hilaire07's cbt under light blips\nmodel = Hilaire07()\ndt = 0.01 # hours\ntime = np.arange(0, 96, dt)\nlight = LightSchedule.Regular()(time)\n\nnp.random.seed(0)\nblip_idxs = np.arange(0, len(time), int(2 / dt))\nfor blip in blip_idxs:\n    if np.random.rand() &gt; 0.85:\n        for i in range(20):\n            light[blip + i] = light[blip] + 750\n\nwake = np.zeros_like(time)\nwake[light &gt; 0] = 0.0\nwake[light == 0] = 1.0\ninput = np.stack((light, wake), axis=1)\n\ntrajectory = model(time, input=input)\ncbt = model.cbt()\ndiff_cbt = np.diff(cbt)\ntest_eq(np.all(diff_cbt &gt; 13.0), True)\n\n\n# test Hilaire07's dlmos\nmodel = Hilaire07()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\nwake = np.zeros_like(time)\ninput = np.stack((light, wake), axis=1)\ntrajectory = model(time, input=input)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ndlmos = time[cbt_min_idxs] + model.phi_ref - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(), dlmos)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\nwake = np.zeros_like(time)\nwake[light &gt; 0] = 0.0\nwake[light == 0] = 1.0\ninput = np.stack((light, wake), axis=1)\ntrajectory = model(time, input=input)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ndlmos = time[cbt_min_idxs] + model.phi_ref - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(trajectory), dlmos)), True)\n# test error handling\ntest_fail(lambda: model.dlmos(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n# test that Hilaire07 can be entrained to a regular 24 hour light schedule for different initial conditions - Scientific test\ndays = 80\ndt = 0.5\ntime = np.arange(0, 24*days, dt)\nregular_schedule = LightSchedule.Regular()\nlight_values = regular_schedule(time)\nwake_values = np.zeros_like(time)\nwake_values[light_values &gt; 0] = 0.0\nwake_values[light_values == 0] = 1.0\ninput = np.stack((light_values, wake_values), axis=1)\n# explore a broad space of initial conditions\namplitude_ic = np.linspace(1e-3, 1.0, 20)\nphase_ic = np.linspace(-np.pi, np.pi, 20)\n# convert amplitude and phase to x and xc\nic_stack = np.dstack(np.meshgrid(amplitude_ic, phase_ic)).reshape(-1, 2)\nic_stack = np.hstack((ic_stack, np.zeros((ic_stack.shape[0], 1))))\nic_x = np.sqrt(ic_stack[:, 0]) * np.cos(ic_stack[:, 1])\nic_xc = np.sqrt(ic_stack[:, 0]) * np.sin(ic_stack[:, 1])\ninitial_conditions = np.hstack((ic_x.reshape(-1, 1), ic_xc.reshape(-1, 1), np.zeros((ic_x.shape[0], 1))))\n# transpose initial conditions\ninitial_conditions = initial_conditions.T\n# simulate\nmodel = Hilaire07()\nresult = model(time, initial_conditions, input)\n# compare last ten days\nt_comparison_idx = int(24 * 70 / dt)\nreference_x = result.states[t_comparison_idx:, 0, 0]\nreference_xc = result.states[t_comparison_idx:, 1, 0]\ndiff_x = result.states[t_comparison_idx:, 0, :].T - reference_x\ndiff_xc = result.states[t_comparison_idx:, 1, :].T - reference_xc\ntest_eq(np.all(np.isclose(diff_x, 0.0, atol=1e-2)), True)\ntest_eq(np.all(np.isclose(diff_xc, 0.0, atol=1e-2)), True)\n\n\n\nSkeldon23\n\n# test Skeldon23's constructor\nmodel = Skeldon23()\n# test attributes\ntrue_default_params = {\n    'mu': 17.78, 'chi': 45.0, 'H0': 13.0, 'Delta': 1.0, 'ca': 1.72,\n    'tauc': 24.2, 'f': 0.99669, 'G': 19.9, 'p': 0.6, 'k': 0.55, 'b': 0.4,\n    'gamma': 0.23, 'alpha_0': 0.16, 'beta': 0.013, 'I0': 9500.0,\n    'kappa': 24.0 / (2.0 * np.pi),\n    'c20': 0.7896, 'alpha21': -0.3912, 'alpha22': 0.7583,\n    'beta21': -0.4442, 'beta22': 0.0250, 'beta23': -0.9647, \n    'S0': 0.0,\n    'cbt_to_dlmo': 7.0,\n    'forced_wakeup_light_threshold': None,\n    'forced_wakeup_weekday_only': False,\n}\ntest_eq(model._default_params, true_default_params)\ntrue_initial_condition = np.array([0.23995682, -1.1547196, 0.50529415, 12.83846474])\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, true_default_params)\ntest_eq(model._num_states, 4)\ntest_eq(model._num_inputs, 1)\ntest_eq(model.current_sleep_state, 0.0)\ntest_eq(model.sleep_state, np.array([0.0]))\nfor key, value in true_default_params.items():\n    test_eq(getattr(model, key), value)\n# test initialization with custom parameters\ncustom_params = {\n    'mu': 1.0, 'chi': 2.0, 'H0': 3.0, 'Delta': 4.0, 'ca': 5.0,\n    'tauc': 6.0, 'f': 7.0, 'G': 8.0, 'p': 9.0, 'k': 10.0, 'b': 11.0,\n    'gamma': 12.0, 'alpha_0': 13.0, 'beta': 14.0, 'I0': 15.0,\n    'kappa': 16.0,\n    'c20': 17.0, 'alpha21': 18.0, 'alpha22': 19.0,\n    'beta21': 20.0, 'beta22': 21.0, 'beta23': 22.0,\n    'S0': 23.0,\n    'cbt_to_dlmo': 24.0,\n}\nmodel = Skeldon23(custom_params)\n# test attributes\ntest_eq(model._default_params, true_default_params)\ntest_eq(model._default_initial_condition, true_initial_condition)\ntest_eq(model.parameters, custom_params)\ntest_eq(model._num_states, 4)\ntest_eq(model._num_inputs, 1)\ntest_eq(model.current_sleep_state, 23.0)\ntest_eq(model.sleep_state, np.array([23.0]))\nfor key, value in custom_params.items():\n    test_eq(getattr(model, key), value)\n\n\n# test Skeldon23's forced wakeup parameters\ncustom_params = {'forced_wakeup_light_threshold': 1.0}\nmodel = Skeldon23(params=custom_params)\ntest_eq(model.forced_wakeup_by_light, True)\ntest_eq(model.forced_wakeup_light_threshold, 1.0)\n\n\n# test Skeldon23's steprk4 new sleep state calculation\nmodel = Skeldon23()\nt = 0.0\ninput = np.array([1.0])\ndt = 0.01 \nstate = np.array([0.1, 0.1, 0.1, 0.1])\nground_truth_state = np.array([0.12340915, 0.07618475, 0.04766054, 0.48855561])\nnew_state = model.step_rk4(t, state, dt, input)\ntest_eq(np.all(np.isclose(new_state, ground_truth_state)), True)\n# sleep to wake transition\nmodel = Skeldon23()\nmodel.current_sleep_state = 1.0\nstate = np.array([0.1, 0.1, 0.1, 0.1])\nmodel.step_rk4(t, state, dt, input)\nnew_sleep_state = model.current_sleep_state\ntest_eq(new_sleep_state, 0.0)\n# wake to sleep transition\nmodel = Skeldon23()\nmodel.current_sleep_state = 0.0\nstate = np.array([0.1, 0.1, 0.1, 16.0])\nmodel.step_rk4(t, state, dt, input)\nnew_sleep_state = model.current_sleep_state\ntest_eq(new_sleep_state, 1.0)\n# catch error if sleep state is not 0 or 1\nmodel = Skeldon23()\nmodel.current_sleep_state = 0.5\nstate = np.array([0.1, 0.1, 0.1, 0.1])\ntest_fail(lambda: model.step_rk4(t, state, dt, input), contains=\"sleep state must be 0 or 1\")\n\n\n# test Skeldon's integrate warnings\nmodel = Skeldon23()\ntime = np.arange(0, 10, 0.1)\nlight = np.ones_like(time)\ntest_fail(lambda: model(time, np.ones((4,2)), light), contains=\"Skeldon23 model can't be run in batch mode\")\n\n\n# test Skeldon23's derv\nmodel = Skeldon23()\n# single batch\nt = 0.0\nstate = np.array([0.1, 0.1, 0.1, 0.1])\nlight = 1.0\nderv_error = np.abs(np.sum(model.derv(t, state, light) - np.array([0.02901846, -0.02013533, -0.0425285, 0.39288889])))\ntest_eq(derv_error &lt; 1e-8, True)\n# multiple batches\nbatches = 5\nbatch_states = np.zeros((4, batches))\nfor batch in range(batches):\n    batch_states[:, batch] = state\nbatch_derv = model.derv(t, batch_states, light)\nfor batch in range(batches):\n    derv_error = np.abs(np.sum(batch_derv[:, batch] - np.array([0.02901846, -0.02013533, -0.0425285, 0.39288889])))\n    test_eq(derv_error &lt; 1e-8, True)\n\n\n# test Skeldon23's phase\nmodel = Skeldon23()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nmodel(time, input=light)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(time=t)\ntrue_phase = np.angle(model.trajectory.states[:,0] + complex(0,1)*(-1.0 * model.trajectory.states[:,1]))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\nphase_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    phase_array[idx] = model.phase(trajectory, t)\ntrue_phase = np.angle(model.trajectory.states[:,0] + complex(0,1)*(-1.0 * model.trajectory.states[:,1]))\ntest_eq(np.all(np.isclose(phase_array, true_phase)), True)\n# test calculation for all trajectories\nphase = model.phase()\ntest_eq(np.all(np.isclose(phase, true_phase)), True)\n# test error handling\ntest_fail(lambda: model.phase(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.phase(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Skeldon23's amplitude\nmodel = Skeldon23()\ntime = np.linspace(0, 96, 1000)\nlight = np.zeros_like(time)\nmodel(time, input=light)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(time=t)\ntrue_amplitude = np.sqrt(model.trajectory.states[:,0] ** 2 + model.trajectory.states[:,1] ** 2)\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\namplitude_array = np.zeros_like(time)\nfor idx, t in enumerate(time):\n    amplitude_array[idx] = model.amplitude(trajectory, t)\ntrue_amplitude = np.sqrt(model.trajectory.states[:,0] ** 2 + model.trajectory.states[:,1] ** 2)\ntest_eq(np.all(np.isclose(amplitude_array, true_amplitude)), True)\n# test calculation for all trajectories\namplitude = model.amplitude()\ntest_eq(np.all(np.isclose(amplitude, true_amplitude)), True)\n# test error handling\ntest_fail(lambda: model.amplitude(1), contains=\"trajectory must be a DynamicalTrajectory\")\ntest_fail(lambda: model.amplitude(trajectory, \"1\"), contains=\"time must be a float or an int\")\n\n\n# test Skeldon23's cbt\nmodel = Skeldon23()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ntroughs = time[cbt_min_idxs]\ntest_eq(np.all(np.isclose(model.cbt(), troughs)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ntroughs = time[cbt_min_idxs]\ntest_eq(np.all(np.isclose(model.cbt(trajectory), troughs)), True)\n# test error handling\ntest_fail(lambda: model.cbt(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n# test Skeldon23's cbt under light blips\nmodel = Skeldon23()\ndt = 0.01 # hours\ntime = np.arange(0, 96, dt)\nlight = LightSchedule.Regular()(time)\n\nnp.random.seed(0)\nblip_idxs = np.arange(0, len(time), int(2 / dt))\nfor blip in blip_idxs:\n    if np.random.rand() &gt; 0.85:\n        for i in range(20):\n            light[blip + i] = light[blip] + 750\n\ntrajectory = model(time, input=light)\ncbt = model.cbt()\ndiff_cbt = np.diff(cbt)\ntest_eq(np.all(diff_cbt &gt; 13.0), True)\n\n\n# test Skeldon23's dlmos\nmodel = Skeldon23()\ntime = np.linspace(0, 96, 2000)\nlight = np.zeros_like(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ndlmos = time[cbt_min_idxs] - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(), dlmos)), True)\n# test passing the trajectory\nlight = LightSchedule.Regular()(time)\ntrajectory = model(time, input=light)\ncbt_min_idxs = find_peaks(-1*trajectory.states[:,0])[0]\ndlmos = time[cbt_min_idxs] - 7.0\ntest_eq(np.all(np.isclose(model.dlmos(trajectory), dlmos)), True)\n# test error handling\ntest_fail(lambda: model.dlmos(1), contains=\"trajectory must be a DynamicalTrajectory\")\n\n\n# TODO: vectorize sleep switching to be able to handle multiple initial conditions\n'''\n# test that Skeldon23 can be entrained to a regular 24 hour light schedule for different initial conditions - Scientific test\ndays = 50\ndt = 0.5\ntime = np.arange(0, 24*days, dt)\nregular_schedule = LightSchedule.Regular()\nlight_values = regular_schedule(time)\n# explore a broad space of initial conditions\namplitude_ic = np.linspace(1e-3, 1.0, 20)\nphase_ic = np.linspace(-np.pi, np.pi, 20)\n# convert amplitude and phase to x and xc\nic_stack = np.dstack(np.meshgrid(amplitude_ic, phase_ic)).reshape(-1, 2)\nic_stack = np.hstack((ic_stack, \n                      np.zeros((ic_stack.shape[0], 1)),\n                      np.zeros((ic_stack.shape[0], 1))))\n# transpose initial conditions\ninitial_conditions = ic_stack.T\n# simulate\nmodel = Skeldon23()\nresult = model(time, initial_conditions, light_values)\n# compare last 5 days for x and xc\nt_comparison_idx = int(24 * (days - 5) / dt)\nreference_x = result.states[t_comparison_idx:, 0, 0]\nreference_xc = result.states[t_comparison_idx:, 1, 0]\ndiff_x = result.states[t_comparison_idx:, 0, :].T - reference_x\ndiff_xc = result.states[t_comparison_idx:, 1, :].T - reference_xc\ntest_eq(np.all(np.isclose(diff_x, 0.0, atol=1e-2)), True)\ntest_eq(np.all(np.isclose(diff_xc, 0.0, atol=1e-2)), True)\n'''\n\n'\\n# test that Skeldon23 can be entrained to a regular 24 hour light schedule for different initial conditions - Scientific test\\ndays = 50\\ndt = 0.5\\ntime = np.arange(0, 24*days, dt)\\nregular_schedule = LightSchedule.Regular()\\nlight_values = regular_schedule(time)\\n# explore a broad space of initial conditions\\namplitude_ic = np.linspace(1e-3, 1.0, 20)\\nphase_ic = np.linspace(-np.pi, np.pi, 20)\\n# convert amplitude and phase to x and xc\\nic_stack = np.dstack(np.meshgrid(amplitude_ic, phase_ic)).reshape(-1, 2)\\nic_stack = np.hstack((ic_stack, \\n                      np.zeros((ic_stack.shape[0], 1)),\\n                      np.zeros((ic_stack.shape[0], 1))))\\n# transpose initial conditions\\ninitial_conditions = ic_stack.T\\n# simulate\\nmodel = Skeldon23()\\nresult = model(time, initial_conditions, light_values)\\n# compare last 5 days for x and xc\\nt_comparison_idx = int(24 * (days - 5) / dt)\\nreference_x = result.states[t_comparison_idx:, 0, 0]\\nreference_xc = result.states[t_comparison_idx:, 1, 0]\\ndiff_x = result.states[t_comparison_idx:, 0, :].T - reference_x\\ndiff_xc = result.states[t_comparison_idx:, 1, :].T - reference_xc\\ntest_eq(np.all(np.isclose(diff_x, 0.0, atol=1e-2)), True)\\ntest_eq(np.all(np.isclose(diff_xc, 0.0, atol=1e-2)), True)\\n'"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Circadian",
    "section": "",
    "text": "Welcome to circadian, a computational package for the simulation and analysis of circadian rhythms",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Circadian",
    "section": "Install",
    "text": "Install\ncircadian can be installed via pip:\npip install circadian",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Circadian",
    "section": "Overview",
    "text": "Overview\nThe circadian package implements key mathematical models in the field such as:\n\nForger99 - Forger et al. (1999)\nHannay19 and Hannay19TP - Hannay et al. (2019)\nJewett99 - Kronauer et al. (1999)\n\nSee all the available models at circadian/models.py\nAdditionally, circadian provides a set of tools for simulating and analzying circadian rhythms:\n\nDefine light schedules using the Light class and feed directly into the models\nCalculate phase response curves using the PRCFinder class\nGenerate actograms and phase plots with the circadian.plots module\n\nFinally, the package streamlines the process of reading, processing, and analyzing wereable data via the circadian.readers module.\nCheck out the documentation for a full overview of the package and its features.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#example",
    "href": "index.html#example",
    "title": "Circadian",
    "section": "Example",
    "text": "Example\nThe code below shows how to simulate the circadian rhythm of a shift worker for four different models and visualize the results in an actogram plot\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as lines\nfrom circadian.plots import Actogram\nfrom circadian.lights import LightSchedule\nfrom circadian.models import Forger99, Jewett99, Hannay19, Hannay19TP\n\ndays_night = 3\ndays_day = 2\nslam_shift = LightSchedule.ShiftWork(lux=300.0, days_on=days_night, days_off=days_day)\n\ntotal_days = 30\ntime = np.arange(0, 24*total_days, 0.10)\nlight_values = slam_shift(time)\n\nf_model = Forger99()\nkj_model = Jewett99()\nspm_model = Hannay19()\ntpm_model = Hannay19TP()\n\nequilibration_reps = 2\ninitial_conditions_forger = f_model.equilibrate(time, light_values, equilibration_reps)\ninitial_conditions_kj = kj_model.equilibrate(time, light_values, equilibration_reps)\ninitial_conditions_spm = spm_model.equilibrate(time, light_values, equilibration_reps)\ninitial_conditions_tpm = tpm_model.equilibrate(time, light_values, equilibration_reps)\n\nThe models are integrated using an explicit Runge-Kutta 4 (RK4) scheme\n\ntrajectory_f = f_model(time, initial_conditions_forger, light_values)\ntrajectory_kj = kj_model(time, initial_conditions_kj, light_values)\ntrajectory_spm = spm_model(time, initial_conditions_spm, light_values)\ntrajectory_tpm = tpm_model(time, initial_conditions_tpm, light_values)\n\nThe Dim Light Melatonin Onset (DLMO), an experimental measurement of circadian phase, is calculated for each model by\n\ndlmo_f = f_model.dlmos()\ndlmo_kj = kj_model.dlmos()\ndlmo_spm = spm_model.dlmos()\ndlmo_tpm = tpm_model.dlmos()\n\nLastly, the results of the simulation–DLMOs included– are visualized in an Actogram plot from the circadian.plots module\n\nacto = Actogram(time, light_vals=light_values, opacity=1.0, smooth=False)\nacto.plot_phasemarker(dlmo_f, color='blue')\nacto.plot_phasemarker(dlmo_spm, color='darkgreen')\nacto.plot_phasemarker(dlmo_tpm, color='red')\nacto.plot_phasemarker(dlmo_kj, color='purple')\n# legend\nblue_line = lines.Line2D([], [], color='blue', label='Forger99')\ngreen_line = lines.Line2D([], [], color='darkgreen', label='Hannay19')\nred_line = lines.Line2D([], [], color='red', label='Hannay19TP')\npurple_line = lines.Line2D([], [], color='purple', label='Jewett99')\n\nplt.legend(handles=[blue_line, purple_line, green_line, red_line], \n           loc='upper center', bbox_to_anchor=(0.5, 1.12), ncol=4)\nplt.title(\"Actogram for a Simulated Shift Worker\", pad=35)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Contributing to circadian",
    "section": "",
    "text": "Thanks for contributing to circadian! We welcome issues, pull requests, and comments on GitHub. Please read the following guidelines for more details on how to contribute.",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "contributing.html#example",
    "href": "contributing.html#example",
    "title": "Contributing to circadian",
    "section": "Example",
    "text": "Example\nLet’s assume we want to add a new feature to circadian for calculating the average sleep duration of a person given a set of timepoints and sleep states. This new feature will add a new function called average_sleep_duration to the utils module of circadian. First, we need to create a new branch for this feature. We can do this by running the following command in the terminal:\ngit checkout -b avg-sleep-duration\nThen, we open the notebook corresponding to the utils module which is located at circadian/nbs/api/07_utils.ipynb. We can see that the notebook contains many cells at the top where we import python packages, then a couple of function definitions, and finally a cell where we tell nbdev to export the code in this notebook to .py files. We will add our code just before this final cell.\nWe create a new cell and add the following code to it:\n#| export\n#| hide\ndef average_sleep_duration(time: np.ndarray, # time array in hours\n                           sleep: np.ndarray # sleep/wake information. 1 for sleep, 0 for wake\n                           ) -&gt; float: # average sleep duration in hours\n    \"Calculate the average sleep duration from a sleep/wake array.\"\n    # input validation\n    if not isinstance(time, np.ndarray):\n        raise TypeError(\"time must be a numpy array\")\n    if not isinstance(sleep, np.ndarray):\n        raise TypeError(\"sleep must be a numpy array\")\n    if time.shape != sleep.shape:\n        raise ValueError(\"time and sleep must have the same shape\")\n    # calculate sleep duration\n    sleep_starts = np.where(np.diff(sleep) == 1)[0]\n    sleep_ends = np.where(np.diff(sleep) == -1)[0]\n    sleep_durations = time[sleep_ends] - time[sleep_starts]\n    return np.mean(sleep_durations)\nSeveral things to notice:\n\nAt the top of our cell we are including nbdev directives. These are special comments that tell nbdev how to process the cell. In this case, we are telling nbdev to export (#| export) the cell to the .py source file and not to show (#| hide) the cell or its output in the documentation.\nWe are using type-hinting to specify the type of the input and output of our function. This is not required, but it is good practice and will help us catch errors.\nAfter each function input and output we’re adding a comment explaining what the input/output is. This is important to generate good documentation. nbdev will automatically convert these comments into documentation for us when we build our documentation site. Similarly, the string after the function definition will be used as the function’s docstring.\n\nBelow this line we can add some text describing what our function does and an example outlining how to use it. We do this by creating the following three cells:\n# Average sleep duration\nThis function calculates the average sleep duration for a dataset of sleep logs. For example,\ntime = np.linspace(0.0, 108.0, 100)\nsleep = np.sin(2 * np.pi * time / 24.0)\nsleep[sleep &gt;= 0] = 0.0\nsleep[sleep &lt; 0] = 1.0\naverage_sleep = average_sleep_duration(time, sleep)\nprint(average_sleep) #| hide_line\n#| echo: false\nplt.plot(time / 24.0, sleep)\nplt.axhline(y=averag_sleep, color='r', linestyle='--',\n            label='Average sleep duration')\nplt.xlabel('Time (days)')\nplt.ylabel('Sleep state')\nplt.show()\nIn this case:\n\nThe first cell (in Markdown) will appear rendered as text in the documentation website\nThe second cell will appear rendered as a code cell in the documentation website without the print statement (#| hide_line). However, below the cell we will see the output of print.\nThe third cell will only show the final plot (#| echo: false). The code will not appear in the documentation but it’s output will.\n\nFinally, we want to test that our function works properly. To do this we head to circadian/nbs/test/test_utils.ipynb (or create it if it doesn’t exist) and add the following cells:\n#| hide \n%load_ext autoreload\n%autoreload 2\nimport numpy as np\nfrom fastcore.test import * # if not already present\nfrom circadian.utils import average_sleep_duration\n# test average_sleep_duration\ntime = np.linspace(0.0, 108.0, 100)\nsleep = np.sin(2 * np.pi * time / 24.0)\nsleep[sleep &gt;= 0] = 0.0\nsleep[sleep &lt; 0] = 1.0\naverage_sleep = average_sleep_duration(time, sleep)\ntest_eq(np.isclose(average_sleep, 12.0), True)\n# test input validation\ntest_fail(lambda: average_sleep_duration([1.0, 1.0], sleep), \n          contains=\"time must be a numpy array\")\ntest_fail(lambda: average_sleep_duration(time, [1.0, 1.0]),\n            contains=\"sleep must be a numpy array\")\ntest_fail(lambda: average_sleep_duration(time, sleep[:-1]), \n          contains=\"time and sleep must have the same shape\")\n\nThe first cell tells IPython to reload imported modules before execution. It’s useful for development. See more details at IPython’s documentation.\nnbdev requires import statements to be in different cells than code. So that’s why we have a separate imports cell.\nFor testing, we can use nbdev functions to test our code such as test_eq and test_fail. See more details at nbdev’s documentation.\n\nOnce we are done writing our code, tests, and documentation we’re ready to generate the source .py files and strip notebooks of innecessary information. This is done by running the following command from the root of the repository:\nnbdev_prepare\nIf the code in all notebooks is valid and no cell throws an error you should see a Success output.\nThen we can follow the usual git workflow to get our changes into our fork:\ngit add .\ngit commit -m \"Add Average sleep calculation, tests, and docs\"\ngit push --set-upstream origin avg-sleep-duration # This will create a new branch on our fork\nFinally, we can open a pull request on GitHub to get our changes into the main repository. Arcascope developers will review your pull request and merge it into the main repository if everything looks good! Here’s more info on creating a pull request.\nTherefore, the steps to add a new feature to circadian using nbdev are:\n\nGo to the notebook you want to modify or create a new one in the nbs folder\nAdd your code with the proper directives and documentation\nAdd your tests on circadian/nbs/test/TEST_FILE.ipynb\nSave notebooks and run nbdev_prepare from the root folder\nCommit and push your changes to GitHub\nCreate a pull request to the main branch\nWait for our review!",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "test/test_synthetic_data.html",
    "href": "test/test_synthetic_data.html",
    "title": "Tests for the synthetic data module",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom fastcore.test import *\nfrom circadian.lights import LightSchedule\nfrom circadian.synthetic_data import generate_activity_from_light"
  },
  {
    "objectID": "test/test_synthetic_data.html#activity-from-light",
    "href": "test/test_synthetic_data.html#activity-from-light",
    "title": "Tests for the synthetic data module",
    "section": "Activity from Light",
    "text": "Activity from Light\n\n# test generate_activity_from_light\n\n# Activity levels.\nmu_l = 50    # Mean of low activity levels.\nmu_h = 100   # Mean of high activity levels.\nmu_s = 0    # Mean of sleep activity levels.\n\n# Activity uncertainty.\nsigma_l = 7.5   # Std of low activity levels.\nsigma_h = 30    # Std of high activity levels.\nsigma_s = 2     # Std of activity during sleep.\n\n# The person's activity level from 0 to 1.\nactive_level = 0.5\n\n# Number of days and samples of interest.\nnum_days = 12\n\n# Time vector.\ntime = np.arange(0, 24*num_days, 1/60)\n\n# Light schedules.\nregular_light = LightSchedule.Regular()\n\n# Generate activity signal.\nactivity = generate_activity_from_light(time, regular_light, mu_l, mu_h, mu_s, sigma_l, sigma_h, sigma_s, active_level)\n\n# Test that mean sleep activity is close to theoretical mean of a half-normal distribution when the pulse is zero\n# Half-normal distribution: https://en.wikipedia.org/wiki/Half-normal_distribution\ntest_eq(\n    np.isclose(np.mean(activity[np.where(regular_light(time) == 0.0)]),\n        sigma_s*np.sqrt(2/np.pi), # mean of a half-normal distribution\n        atol=1e-1,\n        rtol=1e-3),\n    True\n)\n# Plot a histogram of sleep activity levels, distribution, theoretical mean and sample mean\nplt.figure()\nplt.hist(activity[np.where(regular_light(time) == 0.0)], label=\"Sleep Activity\")\nplt.vlines(np.mean(activity[np.where(regular_light(time) == 0.0)]), ymin=0, ymax=2400, colors='r', linestyles='solid', label=\"Population Mean\")\nplt.vlines(sigma_s*np.sqrt(2/np.pi), ymin=0, ymax=2400, colors='k', linestyles='dashed', label=\"Theoretical Mean\")\nplt.legend()\nplt.xlabel(\"Activity (steps/min)\")\nplt.ylabel(\"Count\")\nplt.title(\"Sleep Activity\")\n\n# Test: activity is close to theoretical mean with the high and low distributions\ntest_eq(\n    np.isclose(np.mean(activity[np.where(regular_light(time) &gt; 0.0)]),\n        (active_level*mu_h) + ((1-active_level)*mu_l), # theoretical mean of activity level\n        atol=7.5e-1,\n        rtol=1e-3),\n    True\n)\n# Plot a histogram of awake activity levels, distribution, theoretical mean and sample mean\nplt.figure()\nplt.hist(activity[np.where(regular_light(time) &gt; 0.0)], label=\"Awake Activity\")\nplt.vlines(np.mean(activity[np.where(regular_light(time) &gt; 0.0)]), ymin=0, ymax=4000, colors='r', linestyles='solid', label=\"Population Mean\")\nplt.vlines((active_level*mu_h) + ((1-active_level)*mu_l), ymin=0, ymax=4000, colors='k', linestyles='dashed', label=\"Theoretical Mean\")\nplt.legend()\nplt.xlabel(\"Activity (steps/min)\")\nplt.ylabel(\"Count\")\nplt.title(f\"Awake Activity with active_level = {active_level}\")\n\n# Test: When active level is 1.0, awake activity should be drawn only from the high distribution\nactive_level = 1.0\nactivity = generate_activity_from_light(\n    time, regular_light, mu_l, mu_h, mu_s,\n    sigma_l, sigma_h, sigma_s, active_level\n)\ntest_eq(\n    np.isclose(np.mean(activity[np.where(regular_light(time) &gt; 0.0)]),\n        mu_h,\n        atol=7.5e-1,\n        rtol=1e-3),\n    True\n)\n# Plot a histogram of awake activity levels, distribution, theoretical mean and sample mean\nplt.figure()\nplt.hist(activity[np.where(regular_light(time) &gt; 0.0)], label=\"Awake Activity\")\nplt.vlines(np.mean(activity[np.where(regular_light(time) &gt; 0.0)]), ymin=0, ymax=4000, colors='r', linestyles='solid', label=\"Population Mean\")\nplt.vlines(mu_h, ymin=0, ymax=4000, colors='k', linestyles='dashed', label=\"Theoretical Mean\")\nplt.legend()\nplt.xlabel(\"Activity (steps/min)\")\nplt.ylabel(\"Count\")\nplt.title(f\"Awake Activity with active_level = {active_level}\")\n\n# Test: When active level is 0.0, activity should have the low level mean\nactive_level = 0.0\nactivity = generate_activity_from_light(\n    time, regular_light, mu_l, mu_h, mu_s,\n    sigma_l, sigma_h, sigma_s, active_level\n)\ntest_eq(\n    np.isclose(np.mean(activity[np.where(regular_light(time) &gt; 0.0)]),\n        mu_l,\n        atol=7.5e-1,\n        rtol=1e-3),\n    True\n)\n# Plot a histogram of awake activity levels, distribution, theoretical mean and sample mean\nplt.figure()\nplt.hist(activity[np.where(regular_light(time) &gt; 0.0)], label=\"Awake Activity\")\nplt.vlines(np.mean(activity[np.where(regular_light(time) &gt; 0.0)]), ymin=0, ymax=4000, colors='r', linestyles='solid', label=\"Population Mean\")\nplt.vlines(mu_l, ymin=0, ymax=4000, colors='k', linestyles='dashed', label=\"Theoretical Mean\")\nplt.legend()\nplt.xlabel(\"Activity (steps/min)\")\nplt.ylabel(\"Count\")\nplt.title(f\"Awake Activity with active_level = {active_level}\")\n\nplt.tight_layout(pad=2,w_pad=2,h_pad=2)\n\n# Tests: Error handling\ntest_fail(lambda: generate_activity_from_light(time=1, light=regular_light), contains=\"`time` must be a Numpy array\")\ntest_fail(lambda: generate_activity_from_light(time=time, light=1), contains=\"`light` must be a `LightSchedule` object\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, mu_l='a'), contains=\"mu_l must be a float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, mu_l=-1.0), contains=\"mu_l must be a nonnegative float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, mu_h='a'), contains=\"mu_h must be a float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, mu_h=-1.0), contains=\"mu_h must be a nonnegative float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, mu_s='a'), contains=\"mu_s must be a float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, mu_s=-1.0), contains=\"mu_s must be a nonnegative float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, sigma_l='a'), contains=\"sigma_l must be a float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, sigma_l=-1.0), contains=\"sigma_l must be a nonnegative float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, sigma_h='a'), contains=\"sigma_h must be a float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, sigma_h=-1.0), contains=\"sigma_h must be a nonnegative float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, sigma_s='a'), contains=\"sigma_s must be a float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, sigma_s=-1.0), contains=\"sigma_s must be a nonnegative float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, active_level='a'), contains=\"active_level must be a float or int\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, active_level=-1.0), contains=\"active_level must be between 0.0 and 1.0\")\ntest_fail(lambda: generate_activity_from_light(time, regular_light, active_level=2.0), contains=\"active_level must be between 0.0 and 1.0\")"
  },
  {
    "objectID": "test/test_lights.html",
    "href": "test/test_lights.html",
    "title": "Tests for the lights module",
    "section": "",
    "text": "import warnings\nimport numpy as np\nfrom fastcore.test import *\nfrom circadian.lights import LightSchedule\n\n\n# test LightSchedule's init\ntest_eq(LightSchedule(1.0)._func(0.0), 1.0)\ntest_eq(LightSchedule(1)._func(0.0), 1.0)\ntest_eq(LightSchedule(lambda t: t)._func(0.0), 0.0)\ntest_eq(LightSchedule(lambda t: 2*t)._func(10.0), 20.0)\ntest_eq(LightSchedule(lambda t: t)._func([0.0, 1.0, 2.0]), [0.0, 1.0, 2.0])\ntest_eq(LightSchedule(lambda t: t)._func(np.array([0.0, 1.0, 2.0])), np.array([0.0, 1.0, 2.0]))\n# test periodic light schedules\ntest_eq(LightSchedule(lambda t: t, period=24.0)._func(0.0), 0.0)\ntest_eq(LightSchedule(lambda t: t, period=24.0)._func(25.0), 1.0)\n# test error handling for light\nlight_input_err_msg = \"`light` should be a `float`, or a callable with a single `float` parameter which returns `float`\"\ntest_fail(lambda: LightSchedule('a'), msg=light_input_err_msg)\ntest_fail(lambda: LightSchedule([]), msg=light_input_err_msg)\ntest_fail(lambda: LightSchedule(lambda x: 'a'), msg=light_input_err_msg)\ntest_fail(lambda: LightSchedule(lambda x: []), msg=light_input_err_msg)\ntest_fail(lambda: LightSchedule(lambda x, y: 1.0), msg=light_input_err_msg)\ntest_fail(lambda: LightSchedule(-1.0), msg=light_input_err_msg)\n# test error handling for period\nperiod_err_msg = \"`period` should be a positive `float` or `int`\"\ntest_fail(lambda: LightSchedule(lambda t: t, period='a'), msg=period_err_msg)\ntest_fail(lambda: LightSchedule(lambda t: t, period=[]), msg=period_err_msg)\ntest_fail(lambda: LightSchedule(lambda t: t, period=lambda t: t), msg=period_err_msg)\ntest_fail(lambda: LightSchedule(lambda t: t, period=-1.0), msg=period_err_msg)\ntest_fail(lambda: LightSchedule(lambda t: t, period=0.0), msg=period_err_msg)\n\n\n# test LightSchedule's call\ntest_eq(LightSchedule(1.0)(0.0), 1.0)\ntest_eq(LightSchedule(1.0)([0.0, 1.0, 2.0]), [1.0, 1.0, 1.0])\ntest_eq(LightSchedule(1.0)(np.array([0.0, 1.0, 2.0])), np.array([1.0, 1.0, 1.0]))\ntest_eq(LightSchedule(lambda t: t)(0.0), 0.0)\ntest_eq(LightSchedule(lambda t: t)([0.0, 1.0, 2.0]), [0.0, 1.0, 2.0])\ntest_eq(LightSchedule(lambda t: t)(np.array([0.0, 1.0, 2.0])), np.array([0.0, 1.0, 2.0]))\ntest_eq(LightSchedule(lambda t: 2*t)(10.0), 20.0)\ntest_eq(LightSchedule(lambda t: 2*t)([0.0, 1.0, 2.0]), [0.0, 2.0, 4.0])\n# test periodic light schedules\ntest_eq(LightSchedule(lambda t: t, period=24.0)(0.0), 0.0)\ntest_eq(LightSchedule(lambda t: t, period=24.0)(25.0), 1.0)\n# test error handling\ntime_err_msg = \"`time` should be a `float` or a 1d `numpy.ndarray` of `float`\"\ntest_fail(lambda: LightSchedule(1.0)('a'), msg=time_err_msg)\ntest_fail(lambda: LightSchedule(1.0)(np.zeros((2,2))), msg=time_err_msg)\n# test passing an object that can't be converted to numpy array\ntest_fail(lambda: LightSchedule(1.0)(object()), msg=time_err_msg)\n# test warning of negative light values\nwith warnings.catch_warnings(record=True) as w:\n    warnings.simplefilter(\"always\")\n    LightSchedule(lambda t: -1.0)(0.0)\n    assert len(w) == 1\n    assert issubclass(w[-1].category, UserWarning)\n    assert \"Some light values are negative\" in str(w[-1].message)\n\n\n# test LightSchedule.from_pulse\ndef ground_truth_schedule(time):\n    if time &lt; 1.0 or time &gt; 3.0:\n        return 0.0\n    else:\n        return 100.0\nground_truth_schedule = np.vectorize(ground_truth_schedule, otypes=[float])\nschedule = LightSchedule.from_pulse(100.0, 1.0, 2.0)\ntime = np.linspace(0.0, 48.0, 1000)\ntest_eq(schedule(time), ground_truth_schedule(time))\n# test repetitive pulse\ndef ground_truth_repetitive_schedule(time):\n    t = np.mod(time, 24.0)\n    if t &lt; 1.0 or t &gt; 3.0:\n        return 0.0\n    else:\n        return 100.0\nground_truth_repetitive_schedule = np.vectorize(ground_truth_repetitive_schedule, otypes=[float])\nrepetitive_schedule = LightSchedule.from_pulse(100.0, 1.0, 2.0, 24.0)\ntime = np.linspace(0.0, 48.0, 1000)\ntest_eq(repetitive_schedule(time), ground_truth_repetitive_schedule(time))\n# test error handling\nlux_err_msg = \"`lux` should be a nonnegative `float` or `int`\"\ntest_fail(lambda: LightSchedule.from_pulse(-1.0, 1.0, 2.0), msg=lux_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse('a', 1.0, 2.0), msg=lux_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse([], 1.0, 2.0), msg=lux_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(lambda t: t, 1.0, 2.0), msg=lux_err_msg)\nstart_err_msg = \"`start` should be a `float` or `int`\"\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 'a', 2.0), msg=start_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, [], 2.0), msg=start_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, lambda t: t, 2.0), msg=start_err_msg)\nduration_err_msg = \"`duration` should be a positive `float` or `int`\"\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, 0.0), msg=duration_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, -2.0), msg=duration_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, 'a'), msg=duration_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, []), msg=duration_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, lambda t: t), msg=duration_err_msg)\nperiod_err_msg = \"`period` should be a positive `float` or `int`\"\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, 2.0, 0.0), msg=period_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, 2.0, -2.0), msg=period_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, 2.0, 'a'), msg=period_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, 2.0, []), msg=period_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, 2.0, lambda t: t), msg=period_err_msg)\nbaseline_err_msg = \"`baseline` should be a nonnegative `float` or `int`\"\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, 2.0, baseline=-1.0), msg=baseline_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, 2.0, baseline='a'), msg=baseline_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, 2.0, baseline=[]), msg=baseline_err_msg)\ntest_fail(lambda: LightSchedule.from_pulse(100.0, 1.0, 2.0, baseline=lambda t: t), msg=baseline_err_msg)\n\n\n# test LightSchedule's add\ntime = np.linspace(0.0, 48.0, 1000)\nconstant_1 = LightSchedule(1.0)\nconstant_2 = LightSchedule(2.0)\ntest_eq((constant_1 + constant_2)(time), 3.0*np.ones_like(time))\n# test combining two pulse schedules that don't repeat\ndef ground_truth_pulses_combined(time):\n    if time &lt; 1.0:\n        return 0.0\n    elif time &gt;= 1.0 and time &lt; 3.0:\n        return 100.0\n    elif time &gt;= 3.0 and time &lt; 5.0:\n        return 0.0\n    elif time &gt;= 5.0 and time &lt; 10.0:\n        return 50.0\n    else:\n        return 0.0\n\nground_truth_pulses_combined = np.vectorize(ground_truth_pulses_combined, otypes=[float])\nschedule_1 = LightSchedule.from_pulse(100.0, 1.0, 2.0)\nschedule_2 = LightSchedule.from_pulse(50.0, 5.0, 5.0)\nschedule = schedule_1 + schedule_2\ntime = np.linspace(0.0, 48.0, 1000)\ntest_eq(schedule(time), ground_truth_pulses_combined(time))\n# test combining two repetitive pulses\ndef ground_truth_repetitive_pulses_combined(time):\n    t = np.mod(time, 13.0) \n    if t &lt; 1.0:\n        return 0.0\n    elif t &gt;= 1.0 and t &lt; 3.0:\n        return 100.0\n    elif t &gt;= 3.0 and t &lt; 5.0:\n        return 0.0\n    elif t &gt;= 5.0 and t &lt; 10.0:\n        return 50.0\n    else:\n        return 0.0\n\nground_truth_repetitive_pulses_combined = np.vectorize(ground_truth_repetitive_pulses_combined, otypes=[float])\nrepetitive_schedule_1 = LightSchedule.from_pulse(100.0, 1.0, 2.0, 13.0)\nrepetitive_schedule_2 = LightSchedule.from_pulse(50.0, 5.0, 5.0, 13.0)\nrepetitive_schedule = repetitive_schedule_1 + repetitive_schedule_2\ntime = np.linspace(0.0, 150.0, 1000)\ntest_eq(repetitive_schedule(time), ground_truth_repetitive_pulses_combined(time))\n# TODO: fix edge case when the two schedules match at a single point\n# test error handling\nschedule_err_msg = \"`schedule` should be a `LightSchedule` object\"\ntest_fail(lambda: LightSchedule(1.0) + 1.0, msg=schedule_err_msg)\ntest_fail(lambda: LightSchedule(1.0) + [], msg=schedule_err_msg)\n\n\n# test LightSchedule's sub\ntime = np.linspace(0.0, 48.0, 1000)\nconstant_1 = LightSchedule(10.0)\nconstant_2 = LightSchedule(3.0)\ntest_eq((constant_1 - constant_2)(time), 7.0*np.ones_like(time))\n# test combining two pulse schedules that don't repeat\ndef ground_truth_pulses_subtract(time):\n    if time &gt;= 5.0 and time &lt; 10.0:\n        return 50.0\n    else:\n        return 0.0\n\nground_truth_pulses_subtract = np.vectorize(ground_truth_pulses_subtract, otypes=[float])\nschedule_1 = LightSchedule.from_pulse(100.0, 5.0, 5.0)\nschedule_2 = LightSchedule.from_pulse(50.0, 5.0, 5.0)\nschedule = schedule_1 - schedule_2\ntest_eq(schedule(time), ground_truth_pulses_subtract(time))\n# test combining two repetitive pulses\ndef ground_truth_repetitive_pulses_subtract(time):\n    t = np.mod(time, 13.0) \n    if t &gt;= 5.0 and t &lt; 10.0:\n        return 50.0\n    else:\n        return 0.0\n\nground_truth_repetitive_pulses_subtract = np.vectorize(ground_truth_repetitive_pulses_subtract, otypes=[float])\nrepetitive_schedule_1 = LightSchedule.from_pulse(100.0, 5.0, 5.0, 13.0)\nrepetitive_schedule_2 = LightSchedule.from_pulse(50.0, 5.0, 5.0, 13.0)\nrepetitive_schedule = repetitive_schedule_1 - repetitive_schedule_2\ntest_eq(repetitive_schedule(time), ground_truth_repetitive_pulses_subtract(time))\n# TODO: fix edge case when the two schedules match at a single point\n# test error handling\nschedule_err_msg = \"`schedule` should be a `LightSchedule` object\"\ntest_fail(lambda: LightSchedule(1.0) - 1.0, msg=schedule_err_msg)\ntest_fail(lambda: LightSchedule(1.0) - [], msg=schedule_err_msg)\n\n\n# test LightSchedule's concatenate_at\ntime = np.linspace(0.0, 48.0, 1000)\ntimepoint = 24.0\nconstant_1 = LightSchedule(1.0)\nconstant_2 = LightSchedule(2.0)\nground_truth_before = np.ones_like(time[time &lt; timepoint])\nground_truth_after = 2.0*np.ones_like(time[time &gt;= timepoint])\ntest_eq(constant_1.concatenate_at(constant_2, timepoint)(time), np.concatenate((ground_truth_before, ground_truth_after)))\n# test combining two pulse schedules that don't repeat\ndef ground_truth_pulses_concatenate(time):\n    if time &lt; 1.0:\n        return 0.0\n    elif time &gt;= 1.0 and time &lt; 3.0:\n        return 100.0\n    elif time &gt;= 3.0 and time &lt; 5.0:\n        return 0.0\n    elif time &gt;= 5.0 and time &lt; 10.0:\n        return 50.0\n    else:\n        return 0.0\n\nground_truth_pulses_concatenate = np.vectorize(ground_truth_pulses_concatenate, otypes=[float])\nschedule_1 = LightSchedule.from_pulse(100.0, 1.0, 2.0)\nschedule_2 = LightSchedule.from_pulse(50.0, 2.0, 5.0)\nschedule = schedule_1.concatenate_at(schedule_2, 3.0)\ntest_eq(schedule(time), ground_truth_pulses_concatenate(time))\n# same schedule but built from constant portions\nconstant_1 = LightSchedule(0.0)\nconstant_2 = LightSchedule(100.0)\nconstant_3 = LightSchedule(50.0)\nschedule_const = constant_1.concatenate_at(constant_2, 1.0)\nschedule_const = schedule_const.concatenate_at(constant_1, 3.0)\nschedule_const = schedule_const.concatenate_at(constant_3, 5.0)\nschedule_const = schedule_const.concatenate_at(constant_1, 10.0)\ntest_eq(schedule_const(time), ground_truth_pulses_concatenate(time))\n# test combining two repetitive pulses\ndef ground_truth_repetitive_pulses_concatenate(time):\n    if time &lt; 13*4 + 2:\n        t = np.mod(time, 13.0) \n        if t &lt; 1.0:\n            return 0.0\n        elif t &gt;= 1.0 and t &lt; 3.0:\n            return 100.0\n        else:\n            return 0.0\n    else:\n        t = np.mod(time - 2, 26.0) # note the shift in time\n        if t &lt; 1.0:\n            return 0.0\n        elif t &gt;= 2.0 and t &lt; 5.0:\n            return 50.0\n        else:\n            return 0.0\n\nground_truth_repetitive_pulses_concatenate = np.vectorize(ground_truth_repetitive_pulses_concatenate, otypes=[float])\nrepetitive_schedule_1 = LightSchedule.from_pulse(100.0, 1.0, 2.0, 13.0)\nrepetitive_schedule_2 = LightSchedule.from_pulse(50.0, 2.0, 3.0, 26.0)\nrepetitive_schedule = repetitive_schedule_1.concatenate_at(repetitive_schedule_2, 13*4 + 2)\ntime = np.linspace(0.0, 13*4 + 26*4, 5000)\ntest_eq(repetitive_schedule(time), ground_truth_repetitive_pulses_concatenate(time))\n# test combining two repetitive pulses with shift_schedule=False\ndef ground_truth_repetitive_pulses_concatenate_no_shift(time):\n    if time &lt; 13*4:\n        t = np.mod(time, 13.0) \n        if t &lt; 1.0:\n            return 0.0\n        elif t &gt;= 1.0 and t &lt; 3.0:\n            return 100.0\n        else:\n            return 0.0\n    else:\n        t = np.mod(time, 26.0) \n        if t &lt; 1.0:\n            return 0.0\n        elif t &gt;= 2.0 and t &lt; 5.0:\n            return 50.0\n        else:\n            return 0.0\n\nground_truth_repetitive_pulses_concatenate_no_shift = np.vectorize(ground_truth_repetitive_pulses_concatenate_no_shift, otypes=[float])\nrepetitive_schedule_1 = LightSchedule.from_pulse(100.0, 1.0, 2.0, 13.0)\nrepetitive_schedule_2 = LightSchedule.from_pulse(50.0, 2.0, 3.0, 26.0)\nrepetitive_schedule = repetitive_schedule_1.concatenate_at(repetitive_schedule_2, 13*4, shift_schedule=False)\ntest_eq(repetitive_schedule(time), ground_truth_repetitive_pulses_concatenate_no_shift(time))\n# test error handling\nschedule_err_msg = \"`schedule` should be a `LightSchedule` object\"\ntest_fail(lambda: LightSchedule(1.0).concatenate_at(1.0, 1.0), msg=schedule_err_msg)\ntest_fail(lambda: LightSchedule(1.0).concatenate_at([], 1.0), msg=schedule_err_msg)\ntest_fail(lambda: LightSchedule(1.0).concatenate_at(lambda t: t, 1.0), msg=schedule_err_msg)\ntimepoint_err_msg = \"`timepoint` should be a `float` or `int`\"\ntest_fail(lambda: LightSchedule(1.0).concatenate_at(LightSchedule(1.0), 'a'), msg=timepoint_err_msg)\ntest_fail(lambda: LightSchedule(1.0).concatenate_at(LightSchedule(1.0), []), msg=timepoint_err_msg)\ntest_fail(lambda: LightSchedule(1.0).concatenate_at(LightSchedule(1.0), lambda t: t), msg=timepoint_err_msg)\nshift_schedule_err_msg = \"`shift_schedule` should be a `bool`\"\ntest_fail(lambda: LightSchedule(1.0).concatenate_at(LightSchedule(1.0), 1.0, shift_schedule='a'), msg=shift_schedule_err_msg)\n\n\n# Tests: Plot type checking\nschedule = LightSchedule.from_pulse(100.0, 1.0, 2.0, 24.0)\ntest_fail(lambda: schedule.plot(\"a\", 1), contains=\"plot_start_time must be a float or int\")\ntest_fail(lambda: schedule.plot(0, \"a\"), contains=\"plot_end_time must be a float or int\")\ntest_fail(lambda: schedule.plot(0, 1, num_samples=\"a\"), contains=\"num_samples must be an int\")\ntest_fail(lambda: schedule.plot(0, 1, ax=\"a\"), contains=\"ax must be a matplotlib Axes object\")\n\n\nschedule = LightSchedule.from_pulse(100.0, 1.0, 2.0, 24.0)\nax = schedule.plot(0.0, 48.0)\nax.set_xlabel('Time (hours)');\nax.set_ylabel('Light (lux)');\nax.set_ylim(-5, 110);\n\n\n\n\n\n\n\n\n\nsum_schedule = LightSchedule.from_pulse(100.0, 6.0, 2.0, 24.0) + LightSchedule.from_pulse(50.0, 5.0, 5.0, 24.0)\nax = sum_schedule.plot(0.0, 48.0)\nax.set_xlabel('Time (hours)');\nax.set_ylabel('Light (lux)');\nax.set_ylim(-5, 160);\n\n\n\n\n\n\n\n\n\nsum_schedule = LightSchedule.from_pulse(50.0, 5.0, 5.0, 24.0) - LightSchedule.from_pulse(20.0, 6.0, 2.0, 24.0)\nax = sum_schedule.plot(0.0, 48.0)\nax.set_xlabel('Time (hours)');\nax.set_ylabel('Light (lux)');\nax.set_ylim(-5, 60);\n\n\n\n\n\n\n\n\n\n# test Regular\ntime = np.linspace(0.0, 48.0, 1000)\n# correct creation of standard Regular\nregular_light = LightSchedule.Regular()\ntest_eq(np.all(regular_light(time[time &lt; 7.0]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 7.0) & (time &lt;= 23.0)]) == 150.0), True)\ntest_eq(np.all(regular_light(time[(time &gt; 23.0) & (time &lt; 24.0)]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 24.0) & (time &lt; 7.0 + 24.0)]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 7.0 + 24.0) & (time &lt;= 23.0 + 24.0)]) == 150.0), True)\ntest_eq(np.all(regular_light(time[(time &gt; 23.0 + 24.0) & (time &lt; 24.0 + 24.0)]) == 0.0), True)\n# correct creation of Regular with custom lux\nregular_light = LightSchedule.Regular(lux=100.0)\ntest_eq(np.all(regular_light(time[time &lt; 7.0]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 7.0) & (time &lt;= 23.0)]) == 100.0), True)\ntest_eq(np.all(regular_light(time[(time &gt; 23.0) & (time &lt; 24.0)]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 24.0) & (time &lt; 7.0 + 24.0)]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 7.0 + 24.0) & (time &lt;= 23.0 + 24.0)]) == 100.0), True)\ntest_eq(np.all(regular_light(time[(time &gt; 23.0 + 24.0) & (time &lt; 24.0 + 24.0)]) == 0.0), True)\n# correct creation of Regular with custom lights_on\nregular_light = LightSchedule.Regular(lights_on=6.0)\ntest_eq(np.all(regular_light(time[time &lt; 6.0]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 6.0) & (time &lt;= 23.0)]) == 150.0), True)\ntest_eq(np.all(regular_light(time[(time &gt; 23.0) & (time &lt; 24.0)]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 24.0) & (time &lt; 6.0 + 24.0)]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 6.0 + 24.0) & (time &lt;= 23.0 + 24.0)]) == 150.0), True)\ntest_eq(np.all(regular_light(time[(time &gt; 23.0 + 24.0) & (time &lt; 24.0 + 24.0)]) == 0.0), True)\n# correct creation of Regular with custom lights_off\nregular_light = LightSchedule.Regular(lights_off=18.0)\ntest_eq(np.all(regular_light(time[time &lt; 7.0]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 7.0) & (time &lt;= 18.0)]) == 150.0), True)\ntest_eq(np.all(regular_light(time[(time &gt; 18.0) & (time &lt; 24.0)]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 24.0) & (time &lt; 7.0 + 24.0)]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 7.0 + 24.0) & (time &lt;= 18.0 + 24.0)]) == 150.0), True)\ntest_eq(np.all(regular_light(time[(time &gt; 18.0 + 24.0) & (time &lt; 24.0 + 24.0)]) == 0.0), True)\n# correct creation of Regular with custom lights_on &gt; lights_off\nregular_light = LightSchedule.Regular(lights_on=18.0, lights_off=6.0)\ntest_eq(np.all(regular_light(time[time &lt; 6.0]) == 150.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 6.0) & (time &lt;= 18.0)]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt; 18.0) & (time &lt; 24.0)]) == 150.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 24.0) & (time &lt; 6.0 + 24.0)]) == 150.0), True)\ntest_eq(np.all(regular_light(time[(time &gt;= 6.0 + 24.0) & (time &lt;= 18.0 + 24.0)]) == 0.0), True)\ntest_eq(np.all(regular_light(time[(time &gt; 18.0 + 24.0) & (time &lt; 24.0 + 24.0)]) == 150.0), True)\n# Tests: Type checking\ntest_fail(lambda: LightSchedule.Regular(lux='a'), contains=\"lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Regular(lux=-1.0), contains=\"lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Regular(lights_on='a'), contains=\"lights_on must be a float or int\")\ntest_fail(lambda: LightSchedule.Regular(lights_on=-1.0), contains=\"lights_on must be between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.Regular(lights_on=25.0), contains=\"lights_on must be between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.Regular(lights_off='a'), contains=\"lights_off must be a float or int\")\ntest_fail(lambda: LightSchedule.Regular(lights_off=-1.0), contains=\"lights_off must be between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.Regular(lights_off=25.0), contains=\"lights_off must be between 0.0 and 24.0\")\n\n\n# test ShiftWork\n# correct creation of standard ShiftWork\nshift_work_light = LightSchedule.ShiftWork()\ndef ground_truth_shift_schedule(time):\n    lux = 150.0 \n    days_on = 5 \n    days_off = 2\n    t = np.mod(time, 24*(days_on + days_off))\n    lights_on_workday = 17.0\n    lights_off_workday = 9.0\n    lights_on_day_off = 9.0\n    lights_off_day_off = 24.0\n    workdays_finish = 24*(days_on - 1) + lights_on_workday\n    first_transition_end = 24*days_on + lights_on_day_off\n    second_transition_start = 24*(days_on + days_off - 2) + lights_off_day_off \n    workdays_start_again = 24*(days_on + days_off - 1) + lights_on_workday\n    if t &lt; workdays_finish:\n        # work days\n        schedule = LightSchedule.Regular(lux, lights_on_workday, lights_off_workday)\n        return schedule(time)\n    elif t &gt;= workdays_finish and t &lt; first_transition_end:\n        # transition from workday to day off\n        sleep_time = 0.5 * (workdays_finish + first_transition_end)\n        if t &lt; sleep_time:\n            return lux\n        else:\n            return 0.0\n    elif t &gt;= first_transition_end and t &lt; second_transition_start:\n        # days off\n        schedule = LightSchedule.Regular(lux, lights_on_day_off, lights_off_day_off)\n        return schedule(time)\n    elif t &gt;= second_transition_start and t &lt; workdays_start_again:\n        # transition from day off to workday\n        sleep_bank = (24*(days_on + days_off - 1) + lights_on_workday - second_transition_start) / 3.0\n        schedule = LightSchedule.from_pulse(lux, second_transition_start + sleep_bank, sleep_bank, 24*(days_on + days_off))\n        return schedule(time)\n    else:\n        # work days\n        schedule = LightSchedule.Regular(lux, lights_on_workday, lights_off_workday)\n        return schedule(time)\n\ntime = np.linspace(0.0, 3* 24*(5+2), 5000)\nground_truth_shift_schedule = np.vectorize(ground_truth_shift_schedule, otypes=[float])\ntest_eq(shift_work_light(time), ground_truth_shift_schedule(time))\n# test error handling\ntest_fail(lambda: LightSchedule.ShiftWork(lux='a'), contains=\"lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.ShiftWork(lux=-1.0), contains=\"lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.ShiftWork(days_on='a'), contains=\"days_on must be an int &gt; 1\")\ntest_fail(lambda: LightSchedule.ShiftWork(days_on=-1), contains=\"days_on must be an int &gt; 1\")\ntest_fail(lambda: LightSchedule.ShiftWork(days_off='a'), contains=\"days_off must be an int &gt; 1\")\ntest_fail(lambda: LightSchedule.ShiftWork(days_off=-1), contains=\"days_off must be an int &gt; 1\") \ntest_fail(lambda: LightSchedule.ShiftWork(lights_on_workday='a'), contains=\"lights_on_workday must be a float or int between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.ShiftWork(lights_on_workday=-1.0), contains=\"lights_on_workday must be a float or int between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.ShiftWork(lights_on_workday=25.0), contains=\"lights_on_workday must be a float or int between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.ShiftWork(lights_off_workday='a'), contains=\"lights_off_workday must be a float or int between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.ShiftWork(lights_off_workday=-1.0), contains=\"lights_off_workday must be a float or int between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.ShiftWork(lights_off_workday=25.0), contains=\"lights_off_workday must be a float or int between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.ShiftWork(lights_on_day_off='a'), contains=\"lights_on_day_off must be a float or int between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.ShiftWork(lights_on_day_off=-1.0), contains=\"lights_on_day_off must be a float or int between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.ShiftWork(lights_on_day_off=25.0), contains=\"lights_on_day_off must be a float or int between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.ShiftWork(lights_off_day_off='a'), contains=\"lights_off_day_off must be a float or int between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.ShiftWork(lights_off_day_off=-1.0), contains=\"lights_off_day_off must be a float or int between 0.0 and 24.0\")\ntest_fail(lambda: LightSchedule.ShiftWork(lights_off_day_off=25.0), contains=\"lights_off_day_off must be a float or int between 0.0 and 24.0\")\n\n\n# test SlamShift\nslam_shift = LightSchedule.SlamShift()\ndef ground_truth_slam_shift(time):\n    shift = 8.0\n    before_days = 5\n    starting_lights_on = 7.0\n    starting_lights_off = 23.0\n    last_lights_off_before = 24.0 * (before_days - 1) + starting_lights_off \n    first_lights_on_after =  24.0 * before_days + starting_lights_on + shift\n    t = np.mod(time, 24.0)\n    if time &lt; last_lights_off_before:\n        # before transition\n        if t &lt; 7.0:\n            return 0.0\n        elif t &gt;= 7.0 and t &lt;= 23.0:\n            return 150.0\n        else:\n            return 0.0        \n    elif time &gt;= last_lights_off_before and time &lt; first_lights_on_after:\n        # transition\n        third = (first_lights_on_after - last_lights_off_before) / 3.0\n        light_start = last_lights_off_before + third\n        if time &lt;= light_start:\n            return 0.0\n        elif time &gt;  light_start and time &lt;= light_start + third:\n            return 150.0\n        else:\n            return 0.0\n    elif time &gt;= first_lights_on_after:\n        # after transition\n        t = np.mod(time - shift, 24.0)\n        if t &lt; 7.0:\n            return 0.0\n        elif t &gt;= 7.0 and t &lt;= 23.0:\n            return 150.0\n        else:\n            return 0.0\n        \nground_truth_slam_shift = np.vectorize(ground_truth_slam_shift, otypes=[float])\ntest_eq(slam_shift(time), ground_truth_slam_shift(time))\n# test error handling\ntest_fail(lambda: LightSchedule.SlamShift(lux=\"a\"), contains=\"lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.SlamShift(lux=-1.0), contains=\"lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.SlamShift(shift=\"a\"), contains=\"shift must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.SlamShift(shift=-1.0), contains=\"shift must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.SlamShift(before_days=\"a\"), contains=\"before_days must be a nonnegative int\")\ntest_fail(lambda: LightSchedule.SlamShift(before_days=-1), contains=\"before_days must be a nonnegative int\")\ntest_fail(lambda: LightSchedule.SlamShift(starting_lights_on=\"a\"), contains=\"starting_lights_on must be a float or int between 0 and 24\")\ntest_fail(lambda: LightSchedule.SlamShift(starting_lights_on=-1.0), contains=\"starting_lights_on must be a float or int between 0 and 24\")\ntest_fail(lambda: LightSchedule.SlamShift(starting_lights_on=25.0), contains=\"starting_lights_on must be a float or int between 0 and 24\")\ntest_fail(lambda: LightSchedule.SlamShift(starting_lights_off=\"a\"), contains=\"starting_lights_off must be a float or int between 0 and 24\")\ntest_fail(lambda: LightSchedule.SlamShift(starting_lights_off=-1.0), contains=\"starting_lights_off must be a float or int between 0 and 24\")\ntest_fail(lambda: LightSchedule.SlamShift(starting_lights_off=25.0), contains=\"starting_lights_off must be a float or int between 0 and 24\")\n\n\n# test SocialJetlag\nsocial_jetlag = LightSchedule.SocialJetlag()\ndef ground_truth_social_jetlag(time):\n    lux = 150.0\n    num_regular_days = 5\n    num_jetlag_days = 2\n    hours_delayed = 2.0\n    regular_days_lights_on = 7.0\n    regular_days_lights_off = 23.0\n    overall_period = 24.0 * (num_regular_days + num_jetlag_days)\n    timepoint_change = 24.0 * (num_regular_days - 1) + regular_days_lights_off\n    t = np.mod(time, 24)\n    if np.mod(time, overall_period) &lt;= timepoint_change:\n        # regular days\n        if t &lt;= regular_days_lights_on:\n            return 0.0\n        elif t &gt; regular_days_lights_on and t &lt; regular_days_lights_off:\n            return lux\n        else:\n            return 0.0\n    else:\n        # jetlag days\n        if t &lt; np.mod(regular_days_lights_off + hours_delayed, 24):\n            return lux\n        if t &gt;= np.mod(regular_days_lights_off + hours_delayed, 24) and t &lt; regular_days_lights_on + hours_delayed:\n            return 0.0\n        elif t &gt;= regular_days_lights_on + hours_delayed:\n            return lux\n        \nground_truth_social_jetlag = np.vectorize(ground_truth_social_jetlag, otypes=[float])\ntest_eq(social_jetlag(time), ground_truth_social_jetlag(time))\n# test error handling\ntest_fail(lambda: LightSchedule.SocialJetlag(lux=\"a\"), contains=\"lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.SocialJetlag(lux=-1.0), contains=\"lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.SocialJetlag(num_regular_days=\"a\"), contains=\"num_regular_days must be a nonnegative int\")\ntest_fail(lambda: LightSchedule.SocialJetlag(num_regular_days=-1), contains=\"num_regular_days must be a nonnegative int\")\ntest_fail(lambda: LightSchedule.SocialJetlag(num_jetlag_days=\"a\"), contains=\"num_jetlag_days must be a nonnegative int\")\ntest_fail(lambda: LightSchedule.SocialJetlag(num_jetlag_days=-1), contains=\"num_jetlag_days must be a nonnegative int\")\ntest_fail(lambda: LightSchedule.SocialJetlag(hours_delayed=\"a\"), contains=\"hours_delayed must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.SocialJetlag(hours_delayed=-1.0), contains=\"hours_delayed must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.SocialJetlag(regular_days_lights_on=\"a\"), contains=\"regular_days_lights_on must be a float or int between 0 and 24\")\ntest_fail(lambda: LightSchedule.SocialJetlag(regular_days_lights_on=-1.0), contains=\"regular_days_lights_on must be a float or int between 0 and 24\")\ntest_fail(lambda: LightSchedule.SocialJetlag(regular_days_lights_on=25.0), contains=\"regular_days_lights_on must be a float or int between 0 and 24\")\ntest_fail(lambda: LightSchedule.SocialJetlag(regular_days_lights_off=\"a\"), contains=\"regular_days_lights_off must be a float or int between 0 and 24\")\ntest_fail(lambda: LightSchedule.SocialJetlag(regular_days_lights_off=-1.0), contains=\"regular_days_lights_off must be a float or int between 0 and 24\")\ntest_fail(lambda: LightSchedule.SocialJetlag(regular_days_lights_off=25.0), contains=\"regular_days_lights_off must be a float or int between 0 and 24\")\n\n\n# test Hilaire12\nfirst_constant_routine_duration = 24\nsecond_constant_routine_duration = 48\nhilaire_schedule = LightSchedule.Hilaire12(first_constant_routine_duration,\n                                           second_constant_routine_duration)\ndef ground_truth_hilaire_12(time):\n    regular_lux = 90\n    constant_routine_lux = 3\n    pulse_duration = 1\n    pulse_lux = 8000\n    # key time points\n    pulse_region_start = 72 + 8 + first_constant_routine_duration\n    pulse_region_end = pulse_region_start + 8 + 16 + 8\n    pulse_start = pulse_region_start + 8 + 8 - pulse_duration / 2\n    pulse_end = pulse_start + pulse_duration\n    # first baseline day\n    if time &lt; 24:\n        return regular_lux\n    # second baseline day\n    elif time &gt;= 24 and time &lt; 48:\n        t = np.mod(time, 24)\n        if t &lt; 8:\n            return 0\n        elif t &gt;= 8 and t &lt; 24:\n            return regular_lux\n    # third baseline day\n    elif time &gt;= 48 and time &lt; 72:\n        t = np.mod(time, 24)\n        if t &lt; 8:\n            return 0\n        elif t &gt;= 8 and t &lt; 16:\n            return regular_lux\n        elif t &gt;= 16 and t &lt; 24:\n            return constant_routine_lux\n    # first constant routine\n    elif time &gt;= 72 and time &lt; 72 + 8 + first_constant_routine_duration:\n        if time &lt; 72 + 8:\n            return 0\n        else:\n            return constant_routine_lux\n    elif time &gt;= pulse_region_start and time &lt; pulse_region_end: \n        if time &lt; pulse_region_start + 8:\n            return 0\n        elif time &lt; pulse_start:\n            return constant_routine_lux\n        elif time &gt;= pulse_start and time &lt; pulse_end:\n            return pulse_lux\n        elif time &gt;= pulse_end and time &lt; pulse_region_end - 8:\n            return constant_routine_lux\n        elif time &gt;= pulse_region_end - 8 and time &lt; pulse_region_end:\n            return 0\n    # second constant routine\n    elif time &gt;= pulse_region_end and time &lt; pulse_region_end + second_constant_routine_duration:\n        return constant_routine_lux\n    else:\n        return 0\n\nground_truth_hilaire_12 = np.vectorize(ground_truth_hilaire_12, otypes=[float])\ntime = np.linspace(0.0, 300, 5000)\ntest_eq(hilaire_schedule(time), ground_truth_hilaire_12(time))\n# test error handling\ntest_fail(lambda: LightSchedule.Hilaire12(-1, 1), contains=\"constant_routine_duration must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Hilaire12(16, 1, regular_lux='a'), contains=\"regular_lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Hilaire12(16, 1, regular_lux=-1), contains=\"regular_lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Hilaire12(16, 1, constant_routine_lux='a'), contains=\"constant_routine_lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Hilaire12(16, 1, constant_routine_lux=-1), contains=\"constant_routine_lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Hilaire12(16, 1, pulse_duration='a'), contains=\"pulse_duration must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Hilaire12(16, 1, pulse_duration=-1), contains=\"pulse_duration must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Hilaire12(16, 1, pulse_lux='a'), contains=\"pulse_lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Hilaire12(16, 1, pulse_lux=-1), contains=\"pulse_lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Hilaire12(16, 'a'), contains=\"second_constant_routine_duration must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Hilaire12(16, -1), contains=\"second_constant_routine_duration must be a nonnegative float or int\")\n\n\n# test Chang14 light schedule\ndim_lux = 3.0\ntypical_indoor_lux = 90.0\nereader_lux = 32.0\nbook_lux = 1.0\nfirst_reading_condition = \"eReader\"\nschedule = LightSchedule.Chang14(\n    dim_lux=dim_lux, typical_indoor_lux=typical_indoor_lux,\n    ereader_lux=ereader_lux, book_lux=book_lux,\n    first_reading_condition=first_reading_condition\n)\n# First days\ndef ground_truth_first_day(time):\n    t = np.mod(time, 24)\n    if time &lt; 6.0:\n        return 0\n    elif t &gt;= 6.0 and t &lt; 12.0:\n        return typical_indoor_lux\n    elif t &gt;= 12.0 and t&lt;= 22.0:\n        return dim_lux\n    else:\n        return 0\nground_truth_first_day = np.vectorize(ground_truth_first_day, otypes=[float])\nfirst_days = [np.linspace(0, 24, 1000), np.linspace(0 + 6 * 24, 24 + 6 * 24, 1000)]\nfor i in range(2):\n    test_eq(schedule(first_days[i]), ground_truth_first_day(first_days[i]))\n# Second days\ndef ground_truth_second_day(time, reading_light):\n    t = np.mod(time, 24)\n    if time &lt; 6.0:\n        return 0\n    elif t &gt;= 6.0 and t &lt; 12.0:\n        return dim_lux\n    elif t &gt;= 12.0 and t &lt; 18.0:\n        return typical_indoor_lux\n    elif t &gt;= 18.0 and t &lt; 22.0:\n        return dim_lux + reading_light\n    else:\n        return 0\nground_truth_second_day = np.vectorize(ground_truth_second_day, otypes=[float])\nsecond_days = [np.linspace(24, 48, 1000), np.linspace(24 + 6 * 24, 48 + 6 * 24, 1000)]\nreading_lux = [ereader_lux, book_lux]\nfor i in range(2):\n    test_eq(schedule(second_days[i]), ground_truth_second_day(second_days[i], reading_lux[i]))\n# Reading days\ndef ground_truth_reading_days(time, reading_light):\n    t = np.mod(time, 24)\n    if time &lt; 6.0:\n        return 0\n    elif t &gt;= 6.0 and t &lt; 18.0:\n        return typical_indoor_lux\n    elif t &gt;= 18.0 and t &lt; 22.0:\n        return dim_lux + reading_light\n    else:\n        return 0\nground_truth_reading_days = np.vectorize(ground_truth_reading_days, otypes=[float])\nreading_days_ebook = [np.linspace(48 + i * 24, 72 + i * 24, 1000) for i in range(4)]\nfor i in range(4):\n    time = reading_days_ebook[i]\n    test_eq(schedule(time), ground_truth_reading_days(time, ereader_lux))\nreading_days_book = [np.linspace(48 + (i + 6) * 24, 72 + (i + 6) * 24, 1000) for i in range(4)]\nfor i in range(4):\n    time = reading_days_book[i]\n    test_eq(schedule(time), ground_truth_reading_days(time, book_lux))\n\n# test error handling\ntest_fail(lambda: LightSchedule.Chang14(dim_lux=-1), contains=\"dim_lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Chang14(typical_indoor_lux=-1), contains=\"typical_indoor_lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Chang14(ereader_lux=-1), contains=\"ereader_lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Chang14(book_lux=-1), contains=\"book_lux must be a nonnegative float or int\")\ntest_fail(lambda: LightSchedule.Chang14(first_reading_condition=-1), contains=\"first_reading_condition must be a string\")"
  },
  {
    "objectID": "test/test_metrics.html",
    "href": "test/test_metrics.html",
    "title": "Tests for the metrics module",
    "section": "",
    "text": "import numpy as np\nfrom fastcore.test import *\nfrom circadian.metrics import esri\nfrom circadian.lights import LightSchedule\n\n\nESRI\n\n# esri on darkness should be equal to initial_amplitude\ndt = 0.1\ntime = np.arange(0, 24*7, dt)\nlight_schedule = np.zeros_like(time)\nesri_time, esri_array = esri(time, light_schedule, esri_dt=12.0, initial_amplitude=0.1)\ntest_eq(np.all(np.isclose(esri_array, 0.1)), True)\n# esri of regular schedule low lux\nschedule = LightSchedule.Regular(lux=100)\nlight = schedule(time)\nesri_time, esri_array = esri(time, light, esri_dt=12.0)\nground_truth = 0.55 # close to this value\ntest_eq(np.isclose(np.mean(esri_array), ground_truth, atol=0.01), True)\n# esri of regular schedule high lux\nschedule = LightSchedule.Regular(lux=10000)\nlight = schedule(time)\nesri_time, esri_array = esri(time, light, esri_dt=12.0)\nground_truth = 0.89 # close to this value\ntest_eq(np.isclose(np.mean(esri_array), ground_truth, atol=0.01), True)\n# input validation\ntest_fail(lambda: esri(time=1, light_schedule=np.array([1, 2])), contains='time must be a numpy array')\ntest_fail(lambda: esri(time=np.array([1, 2]), light_schedule=1), contains='light_schedule must be a numpy array')\ntest_fail(lambda: esri(time=np.array([1, 2]), light_schedule=np.array([1, 2, 3])), contains='time and light_schedule must be the same length')\ntest_fail(lambda: esri(time=np.array([1, 2, 4]), light_schedule=np.array([1, 2, 3])), contains='time must have a fixed time resolution')\ntest_fail(lambda: esri(time=np.array([1, 2, 3]), light_schedule=np.array([1, 2, 3]), analysis_days='a'), contains='analysis_days must be an integer')\ntest_fail(lambda: esri(time=np.array([1, 2, 3]), light_schedule=np.array([1, 2, 3]), analysis_days=0), contains='analysis_days must be greater than 0')\ntest_fail(lambda: esri(time=np.array([1, 2, 3]), light_schedule=np.array([1, 2, 3]), esri_dt='a'), contains='esri_dt must be a float or an int')\ntest_fail(lambda: esri(time=np.array([1, 2, 3]), light_schedule=np.array([1, 2, 3]), esri_dt=0), contains='esri_dt must be greater than 0')\ntest_fail(lambda: esri(time=np.array([1, 2, 3]), light_schedule=np.array([1, 2, 3]), initial_amplitude='a'), contains='initial_amplitude must be a float')\ntest_fail(lambda: esri(time=np.array([1, 2, 3]), light_schedule=np.array([1, 2, 3]), initial_amplitude=-1), contains='initial_amplitude must be non-negative')\n\n\n# test that ESRI warns the users when ESRI is negative\ndt = 3.0\ntime = np.arange(0, 24*7, dt)\nschedule = LightSchedule.Regular()\nlight = schedule(time)\ntest_warns(lambda: esri(time, light, esri_dt=12.0))"
  },
  {
    "objectID": "api/phasetools.html",
    "href": "api/phasetools.html",
    "title": "Phase Tools",
    "section": "",
    "text": "The most popular technique for extracting phase information from time-series data is called cosinor analysis. The technique boils down to doing linear regression on cosine transformed data.\n\\[ y = A \\cos(x + \\beta) \\]\nor:\n\\[q(t,\\phi) = a_1 \\sin(\\omega t) + a_2 \\cos(\\omega t) \\]\nIn cosinor analysis the \\(\\omega\\) term (the frequency) is taken as a known quantity and the \\(a_{1,2}\\) terms are fit to minimize the least square error.\nThen the phase \\(\\phi\\) is given by \\(\\arg(a_2 + i a_1)\\)\n\n\n\n\n\n\n\n\n\nWe can find \\(a_{1,2}\\) directly from our data. First, lets define the terms we’re working with: \\(y\\) is the signal, and \\(t\\) represents the sampling times (same length as \\(y\\)). The matrix \\(S\\) is formed by taking the sin/cos of the time vectors and placing them in the columns \\(S = [sin(\\omega t); cos(\\omega t)]\\). Thus, we can write our system as:\n\\[ S a = y \\]\nwhere \\(a = [a_1, a_2]\\) are the two coefficients we want to solve for. This regression can be computed directly because the matrix \\(S\\) is orthogonal. This means that \\(S^T S = I\\), and we can solve the system with one matrix transpose multiplication.\n\\[\\begin{align}\nSa = y \\\\\nS^T S a = S^T y, S^T S = I \\\\\na = S^T y\n\\end{align}\\]\nSince \\(S^T\\) only has two columns we can write the matrix-vector product out for each component:\n\\[\\begin{align}\na_1 = \\frac{ \\sin(\\omega t) \\cdot y}  { || \\sin(\\omega t) ||^2 } \\\\\na_2 = \\frac { \\cos(\\omega t) \\cdot y } { || \\cos(\\omega t) ||^2 }\n\\end{align}\\]\nIn circadian this functionality is implemented via the function cosinor and we use it as follows:\n\na_coeffs = cosinor(x_sample, y_sample_noisy, 100.0)\nprint(f\"Recovered Cosinor Parameters {a_coeffs[0]:.4f} sin(omega t) + {a_coeffs[1]:.4f} cos(omega t)\")\nprint(f\"Phase Estimate: {cosinor_phase(a_coeffs):.4f} versus the true phase: {phi_true:.4f}\")\n\n\nplt.scatter(x_sample,y_sample_noisy, color='k', s=20, label='Noisy Measurements')\nplt.plot(x_sample, y_sample, ls = '--', color = 'k', label = 'True Signal')\nplt.plot(x_sample, a_coeffs[0]*np.sin(2*np.pi/100.0 *x_sample) + a_coeffs[1]*np.cos(2*np.pi/100.0 *x_sample), ls = '--', color = 'r', label = 'Cosinor Fit');\nplt.legend()\nplt.title('Cosinor Example Signal with Noise');\n\nRecovered Cosinor Parameters 0.8104 sin(omega t) + -0.2875 cos(omega t)\nPhase Estimate: 1.9117 versus the true phase: 2.0000\n\n\n\n\n\n\n\n\n\n\n\nOne of the main challenges with the cosinor method is that it assumes that the data is continuous. This is not always the case. For example, if you are measuring a signal at a fixed time interval, but the signal is not present at all times, then you will have gaps in your data.\nThe GOALs algorithm is a modification of the cosinor method that allows for gaps in the data and is implemented as cosinor_goals on circadian.\n\nphi_true = 2.0\nx_sample = np.hstack((np.arange(0, 20, 1), np.arange(40, 60, 1)))\ny_sample = f_signal_cosinor(x_sample, phi_true) \ny_sample_noisy = y_sample + np.random.normal(0, 0.5, x_sample.shape)\n\na_coeffs = cosinor_goals(x_sample, y_sample_noisy, 100.0)\nprint(f\"Recovered GOALS Cosinor Parameters {a_coeffs[0]:.4f} sin(omega t) + {a_coeffs[1]:.4f} cos(omega t)\")\nprint(f\"GOALS Phase Estimate: {cosinor_phase(a_coeffs):.4f} versus the true phase: {phi_true:.4f}\")\n\n\na_coeffs_plain = cosinor(x_sample, y_sample_noisy, 100.0)\nprint(f\"Recovered Cosinor Parameters {a_coeffs_plain[0]:.4f} sin(omega t) + {a_coeffs_plain[1]:.4f} cos(omega t)\")\nprint(f\"Regular Cosinor Phase Estimate: {cosinor_phase(a_coeffs_plain):.4f} versus the true phase: {phi_true:.4f}\")\n\nx_fill = np.arange(0, 100, 1)\ny_fill = f_signal_cosinor(x_fill, phi_true)\nplt.scatter(x_sample,y_sample_noisy, color='k', s=20, label='Noisy Measurements')\nplt.plot(x_fill, y_fill, ls = '--', color = 'k', label = 'True Signal')\nplt.plot(x_fill, a_coeffs[0]*np.sin(2*np.pi/100.0 *x_fill) + a_coeffs[1]*np.cos(2*np.pi/100.0 *x_fill), ls = '--', color = 'r', label = 'GOALs Cosinor Fit');\nplt.plot(x_fill, a_coeffs_plain[0]*np.sin(2*np.pi/100.0 *x_fill) + a_coeffs_plain[1]*np.cos(2*np.pi/100.0 *x_fill), ls = '--', color = 'b', label = 'Cosinor Fit');\nplt.legend()\nplt.title('Cosinor (GOALS) Example Signal with Noise');\n\nRecovered GOALS Cosinor Parameters 0.4250 sin(omega t) + -0.3013 cos(omega t)\nGOALS Phase Estimate: 2.1875 versus the true phase: 2.0000\nRecovered Cosinor Parameters 0.6239 sin(omega t) + -0.1410 cos(omega t)\nRegular Cosinor Phase Estimate: 1.7931 versus the true phase: 2.0000\n\n\n\n\n\n\n\n\n\n\nsource\n\n\n\n cosinor (t:&lt;built-infunctionarray&gt;, y:&lt;built-infunctionarray&gt;, tau:float)\n\nEstimate the phase of a signal using cosinor analysis.\n\n\n\n\nType\nDetails\n\n\n\n\nt\narray\ntime vector\n\n\ny\narray\nsignal vector\n\n\ntau\nfloat\nperiod of cosinor analysis\n\n\nReturns\nfloat\nphase estimate\n\n\n\n\nsource\n\n\n\n\n cosinor_phase (a:&lt;built-infunctionarray&gt;)\n\n\nsource\n\n\n\n\n cosinor_goals (t, y, tau:float)",
    "crumbs": [
      "API",
      "Phase Tools"
    ]
  },
  {
    "objectID": "api/phasetools.html#goals-cosinor-with-gaps",
    "href": "api/phasetools.html#goals-cosinor-with-gaps",
    "title": "Phase Tools",
    "section": "",
    "text": "One of the main challenges with the cosinor method is that it assumes that the data is continuous. This is not always the case. For example, if you are measuring a signal at a fixed time interval, but the signal is not present at all times, then you will have gaps in your data.\nThe GOALs algorithm is a modification of the cosinor method that allows for gaps in the data and is implemented as cosinor_goals on circadian.\n\nphi_true = 2.0\nx_sample = np.hstack((np.arange(0, 20, 1), np.arange(40, 60, 1)))\ny_sample = f_signal_cosinor(x_sample, phi_true) \ny_sample_noisy = y_sample + np.random.normal(0, 0.5, x_sample.shape)\n\na_coeffs = cosinor_goals(x_sample, y_sample_noisy, 100.0)\nprint(f\"Recovered GOALS Cosinor Parameters {a_coeffs[0]:.4f} sin(omega t) + {a_coeffs[1]:.4f} cos(omega t)\")\nprint(f\"GOALS Phase Estimate: {cosinor_phase(a_coeffs):.4f} versus the true phase: {phi_true:.4f}\")\n\n\na_coeffs_plain = cosinor(x_sample, y_sample_noisy, 100.0)\nprint(f\"Recovered Cosinor Parameters {a_coeffs_plain[0]:.4f} sin(omega t) + {a_coeffs_plain[1]:.4f} cos(omega t)\")\nprint(f\"Regular Cosinor Phase Estimate: {cosinor_phase(a_coeffs_plain):.4f} versus the true phase: {phi_true:.4f}\")\n\nx_fill = np.arange(0, 100, 1)\ny_fill = f_signal_cosinor(x_fill, phi_true)\nplt.scatter(x_sample,y_sample_noisy, color='k', s=20, label='Noisy Measurements')\nplt.plot(x_fill, y_fill, ls = '--', color = 'k', label = 'True Signal')\nplt.plot(x_fill, a_coeffs[0]*np.sin(2*np.pi/100.0 *x_fill) + a_coeffs[1]*np.cos(2*np.pi/100.0 *x_fill), ls = '--', color = 'r', label = 'GOALs Cosinor Fit');\nplt.plot(x_fill, a_coeffs_plain[0]*np.sin(2*np.pi/100.0 *x_fill) + a_coeffs_plain[1]*np.cos(2*np.pi/100.0 *x_fill), ls = '--', color = 'b', label = 'Cosinor Fit');\nplt.legend()\nplt.title('Cosinor (GOALS) Example Signal with Noise');\n\nRecovered GOALS Cosinor Parameters 0.4250 sin(omega t) + -0.3013 cos(omega t)\nGOALS Phase Estimate: 2.1875 versus the true phase: 2.0000\nRecovered Cosinor Parameters 0.6239 sin(omega t) + -0.1410 cos(omega t)\nRegular Cosinor Phase Estimate: 1.7931 versus the true phase: 2.0000\n\n\n\n\n\n\n\n\n\n\nsource\n\n\n\n cosinor (t:&lt;built-infunctionarray&gt;, y:&lt;built-infunctionarray&gt;, tau:float)\n\nEstimate the phase of a signal using cosinor analysis.\n\n\n\n\nType\nDetails\n\n\n\n\nt\narray\ntime vector\n\n\ny\narray\nsignal vector\n\n\ntau\nfloat\nperiod of cosinor analysis\n\n\nReturns\nfloat\nphase estimate\n\n\n\n\nsource\n\n\n\n\n cosinor_phase (a:&lt;built-infunctionarray&gt;)\n\n\nsource\n\n\n\n\n cosinor_goals (t, y, tau:float)",
    "crumbs": [
      "API",
      "Phase Tools"
    ]
  },
  {
    "objectID": "api/readers.html",
    "href": "api/readers.html",
    "title": "Readers",
    "section": "",
    "text": "Overview\nThe circadian.readers module contains several methods for working with wearable data such as step counts, heart rate, and sleep. It also defines a Pandas accessor called WearableData to standardize and validate wearable dataframes.\n\n\nLoading wearable data\nThe circadian.readers module provides functionality to import files in several formats, including raw CSV counts, JSON files, and data coming from Actiwatch readers in CSV format. For example, to load a CSV file with heart rate data we can do:\nfrom circadian.readers import load_csv\nfile_path = 'circadian/sample_data/hr_data.csv'\ndf_hr = load_csv(file_path, timestamp_col='timestamp')\n\n\n\n\n\n\n\n\n\nheartrate\ntimestamp\ndatetime\n\n\n\n\n0\n79.0\n4.688359e+07\n1971-06-27 15:13:12.693424232\n\n\n1\n80.0\n4.688329e+07\n1971-06-27 15:08:09.693448064\n\n\n2\n81.0\n4.688306e+07\n1971-06-27 15:04:20.692736632\n\n\n3\n80.0\n4.688273e+07\n1971-06-27 14:58:46.686474800\n\n\n4\n85.0\n4.688257e+07\n1971-06-27 14:56:08.187120912\n\n\n...\n...\n...\n...\n\n\n99995\n97.0\n3.271680e+07\n1971-01-14 15:59:56.779711960\n\n\n99996\n95.0\n3.271679e+07\n1971-01-14 15:59:49.779711960\n\n\n99997\n95.0\n3.271679e+07\n1971-01-14 15:59:48.779711960\n\n\n99998\n95.0\n3.271678e+07\n1971-01-14 15:59:43.779711960\n\n\n99999\n93.0\n3.271677e+07\n1971-01-14 15:59:34.779711960\n\n\n\n\n100000 rows × 3 columns\n\n\n\nby indicating which column contains the unix timestamp information, load_csv automatically generates a new column with the datetime information. If no timestamp column is provided, it is assumed that a column named ‘datetime’ (or ‘start’ and ‘end’) is present in the file. For data specified via time intervals, such as step counts, no new column is generated and the user can choose how to process the data. For example, to load a CSV file with step counts we can do:\nfile_path = 'circadian/sample_data/steps_data.csv'\ndf_steps = load_csv(file_path)\n\n\n\n\n\n\n\n\n\nstart\nend\nsteps\n\n\n\n\n0\n1970-01-01 00:00:00\n1970-01-01 00:01:00\n21.000000\n\n\n1\n1970-01-01 00:49:00\n1970-01-01 00:50:00\n8.183578\n\n\n2\n1970-01-01 00:50:00\n1970-01-01 00:51:00\n19.816422\n\n\n3\n1970-01-01 01:51:00\n1970-01-01 01:52:00\n0.571419\n\n\n4\n1970-01-01 01:52:00\n1970-01-01 01:53:00\n26.499032\n\n\n...\n...\n...\n...\n\n\n222765\n1971-06-27 14:24:00\n1971-06-27 14:25:00\n28.006870\n\n\n222766\n1971-06-27 14:25:00\n1971-06-27 14:26:00\n15.957981\n\n\n222767\n1971-06-27 14:26:00\n1971-06-27 14:27:00\n14.000000\n\n\n222768\n1971-06-27 14:37:00\n1971-06-27 14:38:00\n72.642453\n\n\n222769\n1971-06-27 14:38:00\n1971-06-27 14:39:00\n31.995192\n\n\n\n\n222770 rows × 3 columns\n\n\n\nAdditionally, we can import data in JSON format. For example, to load a JSON file with multiple streams of wearable data we can do:\nfile_path = 'circadian/sample_data/sample_data.json'\ndf_dict = load_json(file_path)\nprint(df_dict.keys())\n\n\ndict_keys(['wake', 'steps', 'heartrate'])\n\n\nwhere df_dict is a dictionary with the dataframes for each stream. The keys of the dictionary are the names of the streams. For example, to access the dataframe with the wake data we can do:\ndf_wake = df_dict['wake']\n\n\n\n\n\n\n\n\n\nstart\nend\nwake\n\n\n\n\n0\n1970-02-03 04:49:01.000000\n1970-02-03 09:01:00.000000\n0\n\n\n1\n1970-02-03 09:02:00.000000\n1970-02-03 11:25:00.000000\n0\n\n\n2\n1970-02-04 04:51:01.000000\n1970-02-04 12:35:00.000000\n0\n\n\n3\n1970-02-04 12:36:00.000000\n1970-02-04 12:37:00.000000\n0\n\n\n4\n1970-02-04 12:38:00.000000\n1970-02-04 12:39:00.000000\n0\n\n\n...\n...\n...\n...\n\n\n2750\n1971-06-27 07:38:31.105829\n1971-06-27 08:01:01.105829\n0\n\n\n2751\n1971-06-27 08:03:01.105829\n1971-06-27 08:55:31.105829\n0\n\n\n2752\n1971-06-27 09:05:31.105829\n1971-06-27 09:07:01.105829\n0\n\n\n2753\n1971-06-27 09:08:01.105829\n1971-06-27 12:06:01.105829\n0\n\n\n2754\n1971-06-27 12:08:01.105829\n1971-06-27 12:15:31.105829\n0\n\n\n\n\n2755 rows × 3 columns\n\n\n\nThe circadian.readers module only accepts specific column names for wearable data. The accepted column names are stored in VALID_WEARABLE_STREAMS:\n\n\n['steps', 'heartrate', 'wake', 'light_estimate', 'activity']\n\n\nFinally, we can import data from Actiwatch readers. For example, to load a CSV file with data from an Actiwatch reader we can do:\nfile_path = 'circadian/sample_data/sample_actiwatch.csv'\ndf_actiwatch = load_actiwatch(file_path)\n\n\n\n\n\n\n\n\n\nactivity\nlight_estimate\nwake\ndatetime\n\n\n\n\n0\n91.0\n318.16\n1.0\n2019-02-20 12:32:00\n\n\n1\n125.0\n285.38\n1.0\n2019-02-20 12:32:30\n\n\n2\n154.0\n312.05\n1.0\n2019-02-20 12:33:00\n\n\n3\n424.0\n294.61\n1.0\n2019-02-20 12:33:30\n\n\n4\n385.0\n285.06\n1.0\n2019-02-20 12:34:00\n\n\n...\n...\n...\n...\n...\n\n\n55646\n0.0\n5.02\n0.0\n2019-03-11 20:15:00\n\n\n55647\n56.0\n4.56\n1.0\n2019-03-11 20:15:30\n\n\n55648\n30.0\n2.85\n1.0\n2019-03-11 20:16:00\n\n\n55649\n9.0\n2.39\n0.0\n2019-03-11 20:16:30\n\n\n55650\n2.0\n2.20\nNaN\n2019-03-11 20:17:00\n\n\n\n\n55651 rows × 4 columns\n\n\n\nnote that load_actiwatch automatically generates a new column with the datetime information and standardizes column names.\n\n\nResampling wearable data\nThe circadian.readers module provides functionality to resample both data that is specified via time intervals or via timestamps. For example, to resample a dataframe with step counts we can do:\nname = 'steps'\nresample_freq = '1D'\nagg_method = 'sum'\nresampled_steps = resample_df(df_steps, name, resample_freq, agg_method)\n\n\n\n\n\n\n\n\n\ndatetime\nsteps\n\n\n\n\n0\n1970-01-01\n847.000000\n\n\n1\n1970-01-02\n1097.000000\n\n\n2\n1970-01-03\n1064.000000\n\n\n3\n1970-01-04\n2076.000000\n\n\n4\n1970-01-05\n2007.000000\n\n\n...\n...\n...\n\n\n538\n1971-06-23\n9372.098478\n\n\n539\n1971-06-24\n10137.802450\n\n\n540\n1971-06-25\n14977.306682\n\n\n541\n1971-06-26\n5644.161346\n\n\n542\n1971-06-27\n3823.642766\n\n\n\n\n543 rows × 2 columns\n\n\n\nwhere resample_freq is a string indicating the frequency of the resampling in Pandas offset aliases notation. Under name, the column to be resampled is specified and the agg_method parameter indicates how to aggregate the data.\n\n\nCombining wearable data\nWe can combine wearable data from different streams into a single dataframe. To achieve this we can use the combine_wearable_dataframes method which resamples and aggregates data to produce a dataframe with a single datetime index and columns for each stream. For example, to combine all the loaded dataframes from the previous section we would do:\ndf_dict = {\n    'heartrate': df_hr,\n    'steps': df_steps,\n    'wake': df_wake\n}\nresample_freq = '1D'\ncombined_data = combine_wearable_dataframes(df_dict, resample_freq)\n\n\n\n\n\n\n\n\n\ndatetime\nheartrate\nsteps\nwake\n\n\n\n\n0\n1970-01-04\n0.000000\n16188.000000\n0.0\n\n\n1\n1970-01-11\n0.000000\n19199.000000\n0.0\n\n\n2\n1970-01-18\n0.000000\n17888.000000\n0.0\n\n\n3\n1970-01-25\n0.000000\n31879.933210\n0.0\n\n\n4\n1970-02-01\n0.000000\n55148.103393\n0.0\n\n\n...\n...\n...\n...\n...\n\n\n73\n1971-05-30\n79.914844\n63334.731963\n0.0\n\n\n74\n1971-06-06\n97.080529\n96282.157729\n0.0\n\n\n75\n1971-06-13\n93.772603\n58306.829809\n0.0\n\n\n76\n1971-06-20\n99.018829\n75375.797207\n0.0\n\n\n77\n1971-06-27\n97.370401\n3823.642766\n0.0\n\n\n\n\n78 rows × 4 columns\n\n\n\nFor resampling, each wearable stream has a defaul aggregation method. The default methods are defined in the variable wearable_RESAMPLE_METHOD:\n\n\n{'steps': 'sum', 'wake': 'max', 'heartrate': 'mean', 'light_estimate': 'mean', 'activity': 'mean'}\n\n\n\n\nAPI Documentation\n\nsource\n\nWearableData\n\n WearableData (pandas_obj)\n\npd.DataFrame accessor implementing wearable-specific methods\n\nsource\n\n\nWearableData.is_valid\n\n WearableData.is_valid ()\n\n\nsource\n\n\nWearableData.add_metadata\n\n WearableData.add_metadata (metadata:Dict[str,str], inplace:bool=False)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmetadata\nDict\n\nmetadata containing data_id, subject_id, or other_info\n\n\ninplace\nbool\nFalse\nwhether to return a new dataframe or modify the current one\n\n\n\n\nsource\n\n\nWearableData.rename_columns\n\n WearableData.rename_columns (df, inplace:bool=False)\n\nStandardize column names by making them lowercase and replacing spaces with underscores\n\nsource\n\n\nload_json\n\n load_json (filepath:str, metadata:Dict[str,str]=None)\n\nCreate a dataframe from a json containing a single or multiple streams of wearable data\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfilepath\nstr\n\npath to file\n\n\nmetadata\nDict\nNone\nmetadata containing data_id, subject_id, or other_info\n\n\nReturns\nDict\n\ndictionary of wearable dataframes, one key:value pair per wearable data stream\n\n\n\n\nsource\n\n\nload_csv\n\n load_csv (filepath:str, metadata:Dict[str,str]=None,\n           timestamp_col:str=None, *args, **kwargs)\n\nCreate a dataframe from a csv containing wearable data\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfilepath\nstr\n\nfull path to csv file to be loaded\n\n\nmetadata\nDict\nNone\nmetadata containing data_id, subject_id, or other_info\n\n\ntimestamp_col\nstr\nNone\nname of the column to be used as timestamp. If None, it is assumed that a datetime column exists\n\n\nargs\nVAR_POSITIONAL\n\narguments to pass to pd.read_csv\n\n\nkwargs\nVAR_KEYWORD\n\n\n\n\n\n\nsource\n\n\nload_actiwatch\n\n load_actiwatch (filepath:str, metadata:Dict[str,str]=None, *args,\n                 **kwargs)\n\nCreate a dataframe from an actiwatch csv file\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfilepath\nstr\n\nfull path to csv file to be loaded\n\n\nmetadata\nDict\nNone\nmetadata containing data_id, subject_id, or other_info\n\n\nargs\nVAR_POSITIONAL\n\narguments to pass to pd.read_csv\n\n\nkwargs\nVAR_KEYWORD\n\n\n\n\nReturns\nDataFrame\n\ndataframe with the wearable data\n\n\n\n\nsource\n\n\nresample_df\n\n resample_df (df:pandas.core.frame.DataFrame, name:str, freq:str,\n              agg_method:str, initial_datetime:pandas._libs.tslibs.timesta\n              mps.Timestamp=None, final_datetime:pandas._libs.tslibs.times\n              tamps.Timestamp=None)\n\nResample a wearable dataframe. If data is specified in intervals, returns the density of the quantity per minute.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\ndataframe to be resampled\n\n\nname\nstr\n\nname of the wearable data to resample (one of steps, heartrate, wake, light_estimate, or activity)\n\n\nfreq\nstr\n\nfrequency to resample to. String must be a valid pandas frequency string (e.g. ‘1min’, ‘5min’, ‘1H’, ‘1D’). See https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases\n\n\nagg_method\nstr\n\naggregation method to use when resampling\n\n\ninitial_datetime\nTimestamp\nNone\ninitial datetime to use when resampling. If None, the minimum datetime in the dataframe is used\n\n\nfinal_datetime\nTimestamp\nNone\nfinal datetime to use when resampling. If None, the maximum datetime in the dataframe is used\n\n\nReturns\nDataFrame\n\nresampled dataframe\n\n\n\n\nsource\n\n\ncombine_wearable_dataframes\n\n combine_wearable_dataframes\n                              (df_dict:Dict[str,pandas.core.frame.DataFram\n                              e], resample_freq:str,\n                              metadata:Dict[str,str]=None)\n\nCombine a dictionary of wearable dataframes into a single dataframe with resampling\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf_dict\nDict\n\ndictionary of wearable dataframes\n\n\nresample_freq\nstr\n\nresampling frequency (e.g. ‘10min’ for 10 minutes, see Pandas Offset aliases: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)\n\n\nmetadata\nDict\nNone\nmetadata for the combined dataframe\n\n\nReturns\nDataFrame\n\ncombined wearable dataframe",
    "crumbs": [
      "API",
      "Readers"
    ]
  },
  {
    "objectID": "api/metrics.html",
    "href": "api/metrics.html",
    "title": "Metrics",
    "section": "",
    "text": "source\n\nesri\n\n esri (time:numpy.ndarray, light_schedule:numpy.ndarray,\n       analysis_days:int=4, esri_dt:float=1.0,\n       initial_amplitude:float=0.1, phase_at_midnight:float=1.65238233)\n\nCalculate the ESRI metric for a given light schedule. Follows the implementation from Moreno et al. 2023 ‘Validation of the Entrainment Signal Regularity Index and associations with children’s changes in BMI’\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntime\nndarray\n\ntime in hours to use for the simulation\n\n\nlight_schedule\nndarray\n\nlight schedule in lux\n\n\nanalysis_days\nint\n4\nnumber of days used to calculate ESRI\n\n\nesri_dt\nfloat\n1.0\ntime resolution of the ESRI calculation in hours\n\n\ninitial_amplitude\nfloat\n0.1\ninitial amplitude for the simulation. This is the ESRI value for constant darkness\n\n\nphase_at_midnight\nfloat\n1.65238233\nphase at midnight. Default value corresponds to a 8 hour darkness and 16 hour light schedule with wake at 8 am.\n\n\nReturns\nList\n\nlist with ESRI timepoints and ESRI values. Negative ESRI values are turned into NaNs\n\n\n\n\ndef sleep_metrics(\n    time: np.ndarray, # array of time values\n    sleep_state: np.ndarray, # array of sleep state values\n) -&gt; List[np.ndarray]:\n    \"Calculate sleep duration and mid-sleep time\"\n    if not isinstance(time, np.ndarray):\n        time = np.array(time)\n        raise ValueError(\"time must be a numpy array\")\n    if not isinstance(sleep_state, np.ndarray):\n        sleep_state = np.array(sleep_state)\n        raise ValueError(\"sleep_state must be a numpy array\")\n    if len(time) != len(sleep_state):\n        raise ValueError(\"time and sleep_state must have the same length\")\n\n    sleep_start_idxs = np.where(np.diff(sleep) == 1)[0]\n    sleep_end_idxs = np.where(np.diff(sleep) == -1)[0] \n    # trim any incomplete sleep windows\n    if sleep_start_idxs[0] &gt; sleep_end_idxs[0]:\n        sleep_end_idxs = sleep_end_idxs[1:]\n    if sleep_start_idxs[-1] &gt; sleep_end_idxs[-1]:\n        sleep_start_idxs = sleep_start_idxs[:-1]\n\n    sleep_duration = np.mean(time[sleep_end_idxs] - time[sleep_start_idxs])\n    sleep_midpoints = (time[sleep_start_idxs] + time[sleep_end_idxs]) / 2.0\n    mid_sleep_time = np.mean(np.mod(sleep_midpoints, 24.0))\n\n    return sleep_duration, mid_sleep_time",
    "crumbs": [
      "API",
      "Metrics"
    ]
  },
  {
    "objectID": "api/synthetic_data.html",
    "href": "api/synthetic_data.html",
    "title": "Synthetic Data",
    "section": "",
    "text": "This function generates an ‘activity’ schedule from an input LightSchedule.\nIt essentially corrupts the light pulse train based on three normal distributions. When the light pulse is on, the function draws from a high or low activity distribution based on a parameter representing how active the person is, and when it is off, the function draws from a sleep activity distribution.\nThere are 7 parameters for the method: * mu_l - mean low activity level * mu_h - mean high activity level * mu_s - mean sleep activity level * sigma_l - std of high activity level * sigma_h - std of high activity level * sigma_s - std of sleep activity - how active the person is in their sleep * active_level - [0, 1] value representing how active the person is. When close to 1, they have a higher probability of being in the high activity distribution at any point in time",
    "crumbs": [
      "API",
      "Synthetic Data"
    ]
  },
  {
    "objectID": "api/synthetic_data.html#generating-activity-from-light-schedules",
    "href": "api/synthetic_data.html#generating-activity-from-light-schedules",
    "title": "Synthetic Data",
    "section": "",
    "text": "This function generates an ‘activity’ schedule from an input LightSchedule.\nIt essentially corrupts the light pulse train based on three normal distributions. When the light pulse is on, the function draws from a high or low activity distribution based on a parameter representing how active the person is, and when it is off, the function draws from a sleep activity distribution.\nThere are 7 parameters for the method: * mu_l - mean low activity level * mu_h - mean high activity level * mu_s - mean sleep activity level * sigma_l - std of high activity level * sigma_h - std of high activity level * sigma_s - std of sleep activity - how active the person is in their sleep * active_level - [0, 1] value representing how active the person is. When close to 1, they have a higher probability of being in the high activity distribution at any point in time",
    "crumbs": [
      "API",
      "Synthetic Data"
    ]
  },
  {
    "objectID": "api/synthetic_data.html#examples",
    "href": "api/synthetic_data.html#examples",
    "title": "Synthetic Data",
    "section": "Examples",
    "text": "Examples\nThis section uses the Circadian package to generate the 4 light schedules: * Regular * Shift Work * Slam Shift * Social Jetlag\nthen passes each to the function to generate ‘activity’ schedules from them.\n\n# Activity levels.\nmu_l = 5    # Mean of low activity levels.\nmu_h = 25   # Mean of high activity levels.\nmu_s = 0    # Mean of sleep activity levels.\n\n# Activity uncertainty.\nsigma_l = 7.5   # Std of low activity levels.\nsigma_h = 30    # Std of high activity levels.\nsigma_s = 2     # Std of activity during sleep.\nsigma_t = 1.5   # Std of sleep onset/offset timing.\n\n# The person's activity level from 0 to 1.\nactive_level = 0.5\n\n# Number of days and samples of interest.\nnum_days = 12\nnum_samples = 60*24*num_days\n\n\n# Create the time, light and activity signals.\n\n# Time vector.\ntime = np.arange(0, 24*num_days, 1/60)\n\n# Light schedules.\nregular_light = LightSchedule.Regular()\nshift_light = LightSchedule.ShiftWork()\nslam_light = LightSchedule.SlamShift()\nsocial_jetlag = LightSchedule.SocialJetlag()\n\n# Create the activity signals.\nregular_activity = generate_activity_from_light(\n    time, regular_light,\n    mu_l, mu_h, mu_s, sigma_l, sigma_h, sigma_s,\n    active_level, \n)\nshift_activity = generate_activity_from_light(\n    time, shift_light,\n    mu_l, mu_h, mu_s, sigma_l, sigma_h, sigma_s,\n    active_level,\n)\nslam_activity = generate_activity_from_light(\n    time, slam_light,\n    mu_l, mu_h, mu_s, sigma_l, sigma_h, sigma_s,\n    active_level,\n)\nsocial_jetlag_activity = generate_activity_from_light(\n    time, social_jetlag,\n    mu_l, mu_h, mu_s, sigma_l, sigma_h, sigma_s,\n    active_level\n)",
    "crumbs": [
      "API",
      "Synthetic Data"
    ]
  },
  {
    "objectID": "api/synthetic_data.html#visualization",
    "href": "api/synthetic_data.html#visualization",
    "title": "Synthetic Data",
    "section": "Visualization",
    "text": "Visualization\nHere, we visualize the ‘activity’ schedules with their corresponding input light schedules.\n\nnrows, ncols = 2, 1\n\n\n# Regular plots.\nfig, ax = plt.subplots(nrows=nrows, ncols=ncols)\nregular_light.plot(\n    plot_start_time=0.0,\n    plot_end_time=24*num_days,\n    num_samples=num_samples,\n    ax=ax[0]\n)\nax[0].set_ylabel(\"Light (lux)\")\nax[0].set_title(\"Regular Light Schedule\")\nax[0].set_xticks(np.arange(min(time), max(time), 24))\nax[0].grid()\nax[1].plot(\n    time, regular_activity\n)\nax[1].set_ylabel(\"Activity (steps/min)\")\nax[1].set_xlabel(\"Time (hours)\")\nax[1].set_title(\"Regular Activity Schedule\")\nax[1].set_xticks(np.arange(min(time), max(time), 24))\nax[1].grid()\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n# Shift Work plots.\nfig, ax = plt.subplots(nrows=nrows, ncols=ncols)\nshift_light.plot(\n    plot_start_time=0.0,\n    plot_end_time=24*num_days,\n    num_samples=num_samples,\n    ax=ax[0]\n)\nax[0].set_ylabel(\"Light (lux)\")\nax[0].set_title(\"Shift Work Light Schedule\")\nax[0].set_xticks(np.arange(min(time), max(time), 24))\nax[0].grid()\nax[1].plot(\n    time, shift_activity\n)\nax[1].set_ylabel(\"Activity (steps/min)\")\nax[1].set_xlabel(\"Time (hours)\")\nax[1].set_title(\"Shift Work Activity Schedule\")\nax[1].set_xticks(np.arange(min(time), max(time), 24))\nax[1].grid()\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n# Slam Shift plots.\nfig, ax = plt.subplots(nrows=nrows, ncols=ncols)\nslam_light.plot(\n    plot_start_time=0.0,\n    plot_end_time=24*num_days,\n    num_samples=num_samples,\n    ax=ax[0]\n)\nax[0].set_ylabel(\"Light (lux)\")\nax[0].set_title(\"Slam Shift Light Schedule\")\nax[0].set_xticks(np.arange(min(time), max(time), 24))\nax[0].grid()\nax[1].plot(\n    time, slam_activity\n)\nax[1].set_ylabel(\"Activity (steps/min)\")\nax[1].set_xlabel(\"Time (hours)\")\nax[1].set_title(\"Slam Shift Activity Schedule\")\nax[1].set_xticks(np.arange(min(time), max(time), 24))\nax[1].grid()\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n# Social Jetlag plots.\nfig, ax = plt.subplots(nrows=nrows, ncols=ncols)\nsocial_jetlag.plot(\n    plot_start_time=0.0,\n    plot_end_time=24*num_days,\n    num_samples=num_samples,\n    ax=ax[0]\n)\nax[0].set_ylabel(\"Light (lux)\")\nax[0].set_title(\"Social Jetlag Light Schedule\")\nax[0].set_xticks(np.arange(min(time), max(time), 24))\nax[0].grid()\nax[1].plot(\n    time, social_jetlag_activity\n)\nax[1].set_ylabel(\"Activity (steps/min)\")\nax[1].set_xlabel(\"Time (hours)\")\nax[1].set_title(\"Social Jetlag Activity Schedule\")\nax[1].set_xticks(np.arange(min(time), max(time), 24))\nax[1].grid()\n\nplt.tight_layout()",
    "crumbs": [
      "API",
      "Synthetic Data"
    ]
  },
  {
    "objectID": "examples/esri_calculation.html",
    "href": "examples/esri_calculation.html",
    "title": "ESRI",
    "section": "",
    "text": "The Entrainment Signal Regularity Index (ESRI) is a metric of circadian health introduced by Moreno et al. 2023 in the article Validation of the Entrainment Signal Regularity Index and associations with children’s changes in BMI. This metric quantifies how much light schedules entrain circadian rhythms. The ESRI metric uses a decoupled Hannay19 model: both the coupling between individual oscillators (parameter K) and frequency heterogeneity (parameter gamma) are set to 0. To calculate ESRI, fixed windows of a given light schedule are simulated, and the final amplitude of the decoupled model is taken as the ESRI value. This amplitude is close to 1 for highly entraining and regular schedules, and close to 0 for non-entraining schedules, like a train of random pulses. For more details see the original article.\nThe interface for calculating ESRI is given by esri. For example, we can compare the metric for four different light schedules:\n\nA regular schedule with 8 hours of darkness and 16 hours of light\nA shift work schedule with 5 days on and 2 days off\nA random schedule created with pulses of random start times and durations\nA constant darkness schedule\n\nimport matplotlib.pyplot as plt\nfrom circadian.metrics import esri\nfrom circadian.lights import LightSchedule\n\ndt = 0.1 # hours\ndays = 14\ntime = np.arange(0, 24*days, dt)\nesri_dt = 2.0 # hours\n# regular schedule\nregular_schedule = LightSchedule.Regular(lux=1000)\nregular_light = regular_schedule(time)\nesri_time_regular, esri_array_regular = esri(time, regular_light, esri_dt=esri_dt)\n# shift work schedule\nshift_schedule = LightSchedule.ShiftWork(lux=1000)\nshift_light = shift_schedule(time)\nesri_time_shift, esri_array_shift = esri(time, shift_light, esri_dt=esri_dt)\n# irregular schedule\nn_pulses = 8\nschedule = LightSchedule(0.0)\nfor n in range(n_pulses):\n    start = np.random.uniform(0, 24*days)\n    lux = np.random.uniform(10.0, 1000.0)\n    duration = np.random.uniform(5.0, 16.0)\n    schedule += LightSchedule.from_pulse(lux, start, duration)\nirregular_light = schedule(time)\nesri_time_irregular, esri_array_irregular = esri(time, irregular_light, esri_dt=esri_dt)\n# darkness schedule\ndarkness_schedule = LightSchedule(0.0)\ndarkness = darkness_schedule(time)\nesri_time_darkness, esri_array_darkness = esri(time, darkness, esri_dt=esri_dt)\n\n\n\n\n\n\n\n\n\nThis result shows the ESRI value for each start time of the analysis window. The default window length is 4 days, and the default window step is 1 hour. That’s why ESRI is only calculated for half of our simulation time (8 days). In the following plot, we see that the overall ESRI value for a highly regular schedule is larger than for a random schedule, and that the ESRI value for constant darkness is 0.1 which matches the default starting amplitude for the model. Both the window length and default starting amplitude can be changed with the analysis_days and initial_amplitude parameters.",
    "crumbs": [
      "Examples",
      "ESRI"
    ]
  }
]